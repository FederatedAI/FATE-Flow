{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"fate_flow/","title":"Overall Design","text":""},{"location":"fate_flow/#1-logical-architecture","title":"1. Logical Architecture","text":"<ul> <li>DSL defined jobs</li> <li>Top-down vertical subtask flow scheduling, multi-participant joint subtask coordination</li> <li>Independent isolated task execution work processes</li> <li>Support for multiple types and versions of components</li> <li>Computational abstraction API</li> <li>Storage abstraction API</li> <li>Cross-party transfer abstraction API</li> </ul>"},{"location":"fate_flow/#2-service-architecture","title":"2. Service Architecture","text":""},{"location":"fate_flow/#21-fate","title":"2.1 FATE","text":""},{"location":"fate_flow/#22-fate-flow","title":"2.2 FATE Flow","text":""},{"location":"fate_flow/#3-scheduling-architecture","title":"3. Scheduling Architecture","text":""},{"location":"fate_flow/#31-a-new-scheduling-architecture-based-on-shared-state","title":"3.1 A new scheduling architecture based on shared-state","text":"<ul> <li>Stripping state (resources, jobs) and managers (schedulers, resource managers)</li> <li>Resource state and job state are persisted in MySQL and shared globally to provide reliable transactional operations</li> <li>Improve the high availability and scalability of managed services</li> <li>Jobs can be intervened to support restart, rerun, parallel control, resource isolation, etc.</li> </ul>"},{"location":"fate_flow/#32-state-driven-scheduling","title":"3.2 State-Driven Scheduling","text":"<ul> <li>Resource coordination</li> <li>Pull up the child process Executor to run the component</li> <li>Executor reports state to local Server and also to scheduler</li> <li>Multi-party task state calculation of federal task state</li> <li>Upstream and downstream task states compute job states</li> </ul>"},{"location":"fate_flow/#4-multiparty-resource-coordination","title":"4. Multiparty Resource Coordination","text":"<ul> <li>The total resource size of each engine is configured through the configuration file, and the system is subsequently interfaced</li> <li>The cores_per_node in the total resource size indicates the number of cpu cores per compute node, and nodes indicates the number of compute nodes.</li> <li>FATEFlow server reads the resource size configuration from the configuration file when it starts and registers the update to the database</li> <li>The resources are requested in Job dimension, and take effect when Job Conf is submitted, formula: task_parallelism*task_cores</li> <li>See separate section of the documentation for details</li> </ul>"},{"location":"fate_flow/#5-data-flow-tracking","title":"5. Data Flow Tracking","text":"<ul> <li>Definition</li> <li>metric type: metric type, such as auc, loss, ks, etc.</li> <li>metric namespace: custom metric namespace, e.g. train, predict</li> <li>metric name: custom metric name, e.g. auc0, hetero_lr_auc0</li> <li>metric data: metric data in key-value form</li> <li>metric meta: metric meta information in key-value form, support flexible drawing</li> <li>API</li> <li>log_metric_data(metric_namespace, metric_name, metrics)</li> <li>set_metric_meta(metric_namespace, metric_name, metric_meta)</li> <li>get_metric_data(metric_namespace, metric_name)</li> <li>get_metric_meta(metric_namespace, metric_name)</li> </ul>"},{"location":"fate_flow/#6-realtime-monitoring","title":"6. Realtime Monitoring","text":"<ul> <li>Job process survivability detection</li> <li>Job timeout detection</li> <li>Resource recovery detection</li> <li>Base engine session timeout detection</li> </ul>"},{"location":"fate_flow/#7-task-component-registry","title":"7. Task Component Registry","text":""},{"location":"fate_flow/#8-multi-party-federated-model-registry","title":"8. Multi-Party Federated Model Registry","text":"<ul> <li>Using Google Protocol Buffer as the model storage protocol, using cross-language sharing, each algorithmic model consists of two parts: ModelParam &amp; ModelMeta</li> <li>A Pipeline generates a series of algorithmic models</li> <li>The model named Pipeline stores Pipeline modeling DSL and online inference DSL</li> <li>Under federal learning, model consistency needs to be guaranteed for all participants, i.e., model binding</li> <li>model_key is the model identifier defined by the user when submitting the task</li> <li>The model IDs of the federated parties are the party identification information role, party_id, plus model_key</li> <li>The model version of the federated parties must be unique and consistent, and FATE-Flow directly sets it to job_id</li> </ul>"},{"location":"fate_flow/#9-data-access","title":"9. Data Access","text":"<ul> <li>Upload.</li> <li>External storage is imported directly to FATE Storage, creating a new DTable</li> <li> <p>When the job runs, Reader reads directly from Storage</p> </li> <li> <p>Table Bind.</p> </li> <li>Key the external storage address to a new DTable in FATE</li> <li>When the job is running, Reader reads data from external storage via Meta and transfers it to FATE Storage</li> <li>Connecting to the Big Data ecosystem: HDFS, Hive/MySQL</li> </ul> <p></p>"},{"location":"fate_flow/#10-multi-party-collaboration-authority-management","title":"10. Multi-Party Collaboration Authority Management","text":""},{"location":"quick_start/","title":"Quick Start","text":""},{"location":"quick_start/#1-environment-setup","title":"1. Environment Setup","text":"<p>You can choose one of the following three deployment modes based on your requirements:</p>"},{"location":"quick_start/#11-pypi-package-installation","title":"1.1 Pypi Package Installation","text":"<p>Note: This mode operates in a single-machine mode.</p>"},{"location":"quick_start/#111-installation","title":"1.1.1 Installation","text":"<ul> <li>Prepare and install conda environment.</li> <li>Create a virtual environment: <pre><code># FATE requires Python &gt;= 3.8\nconda create -n fate_env python=3.8\nconda activate fate_env\n</code></pre></li> <li>Install FATE Flow and related dependencies: <pre><code>pip install fate_client[fate,fate_flow]==2.0.0.b0\n</code></pre></li> </ul>"},{"location":"quick_start/#112-service-initialization","title":"1.1.2 Service Initialization","text":"<p><pre><code>fate_flow init --ip 127.0.0.1 --port 9380 --home $HOME_DIR\n</code></pre> - <code>ip</code>: The IP address where the service runs. - <code>port</code>: The HTTP port the service runs on. - <code>home</code>: The data storage directory, including data, models, logs, job configurations, and SQLite databases.</p>"},{"location":"quick_start/#113-service-startstop","title":"1.1.3 Service Start/Stop","text":"<pre><code>fate_flow status/start/stop/restart\n</code></pre>"},{"location":"quick_start/#12-standalone-deployment","title":"1.2 Standalone Deployment","text":"<p>Refer to Standalone Deployment.</p>"},{"location":"quick_start/#13-cluster-deployment","title":"1.3 Cluster Deployment","text":"<p>Refer to Allinone Deployment.</p>"},{"location":"quick_start/#2-user-guide","title":"2. User Guide","text":"<p>FATE provides client tools including SDK, CLI, and Pipeline. If you don't have FATE Client deployed in your environment, you can download it using <code>pip install fate_client</code>. The following operations are based on CLI.</p>"},{"location":"quick_start/#21-data-upload","title":"2.1 Data Upload","text":"<p>In version 2.0-beta, data uploading is a two-step process:</p> <ul> <li>upload: Uploads data to FATE-supported storage services.</li> <li>transformer: Transforms data into a DataFrame.</li> </ul>"},{"location":"quick_start/#211-upload","title":"2.1.1 upload","text":""},{"location":"quick_start/#2111-configuration-and-data","title":"2.1.1.1 Configuration and Data","text":"<ul> <li>Upload configuration can be found at examples-upload, and the data is located at upload-data.</li> <li>You can also use your own data and modify the \"meta\" information in the upload configuration.</li> </ul>"},{"location":"quick_start/#2112-upload-guest-data","title":"2.1.1.2 Upload Guest Data","text":"<p><pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre> - Record the returned \"name\" and \"namespace\" for use in the transformer phase.</p>"},{"location":"quick_start/#2113-upload-host-data","title":"2.1.1.3 Upload Host Data","text":"<p><pre><code>flow data upload -c examples/upload/upload_host.json\n</code></pre> - Record the returned \"name\" and \"namespace\" for use in the transformer phase.</p>"},{"location":"quick_start/#2114-upload-result","title":"2.1.1.4 Upload Result","text":"<p><pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"36491bc8-3fef-11ee-be05-16b977118319\",\n        \"namespace\": \"upload\"\n    },\n    \"job_id\": \"202308211451535620150\",\n    \"message\": \"success\"\n}\n</code></pre> Where \"namespace\" and \"name\" identify the data in FATE for future reference in the transformer phase.</p>"},{"location":"quick_start/#2115-data-query","title":"2.1.1.5 Data Query","text":"<p>Since upload is an asynchronous operation, you need to confirm if it was successful before proceeding to the next step. <pre><code>flow table query --namespace upload --name 36491bc8-3fef-11ee-be05-16b977118319\n</code></pre> If the returned code is 0, the upload was successful.</p>"},{"location":"quick_start/#212-transformer","title":"2.1.2 Transformer","text":""},{"location":"quick_start/#2121-configuration","title":"2.1.2.1 Configuration","text":"<ul> <li>Transformer configuration can be found at examples-transformer.</li> </ul>"},{"location":"quick_start/#2122-transform-guest-data","title":"2.1.2.2 Transform Guest Data","text":"<ul> <li>Configuration path: examples/transformer/transformer_guest.json</li> <li>Modify the \"namespace\" and \"name\" in the \"data_warehouse\" section to match the output from the guest data upload. <pre><code>flow data transformer -c examples/transformer/transformer_guest.json\n</code></pre></li> </ul>"},{"location":"quick_start/#2123-transform-host-data","title":"2.1.2.3 Transform Host Data","text":"<ul> <li>Configuration path: examples/transformer/transformer_host.json</li> <li>Modify the \"namespace\" and \"name\" in the \"data_warehouse\" section to match the output from the host data upload. <pre><code>flow data transformer -c examples/transformer/transformer_host.json\n</code></pre></li> </ul>"},{"location":"quick_start/#2124-transformer-result","title":"2.1.2.4 Transformer Result","text":"<p><pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\"\n    },\n    \"job_id\": \"202308211557455662860\",\n    \"message\": \"success\"\n}\n</code></pre> Where \"namespace\" and \"name\" identify the data in FATE for future modeling jobs.</p>"},{"location":"quick_start/#2125-check-if-data-upload-was-successful","title":"2.1.2.5 Check if Data Upload Was Successful","text":"<p>Since the transformer is also an asynchronous operation, you need to confirm if it was successful before proceeding. <pre><code>flow table query --namespace experiment --name breast_hetero_guest\n</code></pre> <pre><code>flow table query --namespace experiment --name breast_hetero_host\n</code></pre> If the returned code is 0, the upload was successful.</p>"},{"location":"quick_start/#22-starting-fate-jobs","title":"2.2 Starting FATE Jobs","text":""},{"location":"quick_start/#221-submitting-a-job","title":"2.2.1 Submitting a Job","text":"<p>Once your data is prepared, you can start submitting jobs to FATE Flow:</p> <ul> <li>The configuration for training jobs can be found in lr-train.</li> <li>The configuration for prediction jobs can be found in lr-predict. To use it, modify the \"dag.conf.model_warehouse\" to point to the output model of your training job.</li> <li>In the training and prediction job configurations, the site IDs are set to \"9998\" and \"9999.\" If your deployment environment is the cluster version, you need to replace them with the actual site IDs. For the standalone version, you can use the default configuration.</li> <li>If you want to use your own data, you can change the \"namespace\" and \"name\" of \"data_warehouse\" for both the guest and host in the configuration.</li> <li>To submit a job, use the following command: <pre><code>flow job submit -c examples/lr/train_lr.yaml \n</code></pre></li> <li>A successful submission will return the following result: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"model_id\": \"202308211911505128750\",\n        \"model_version\": \"0\"\n    },\n    \"job_id\": \"202308211911505128750\",\n    \"message\": \"success\"\n}\n</code></pre> The \"data\" section here contains the output model of the job.</li> </ul>"},{"location":"quick_start/#222-querying-a-job","title":"2.2.2 Querying a Job","text":"<p>While a job is running, you can check its status using the query command: <pre><code>flow job query -j $job_id\n</code></pre></p>"},{"location":"quick_start/#223-stopping-a-job","title":"2.2.3 Stopping a Job","text":"<p>During job execution, you can stop the current job using the stop command: <pre><code>flow job stop -j $job_id\n</code></pre></p>"},{"location":"quick_start/#224-rerunning-a-job","title":"2.2.4 Rerunning a Job","text":"<p>If a job fails during execution, you can rerun it using the rerun command: <pre><code>flow job rerun -j $job_id\n</code></pre></p>"},{"location":"quick_start/#23-obtaining-job-outputs","title":"2.3 Obtaining Job Outputs","text":"<p>Job outputs include data, models, and metrics.</p>"},{"location":"quick_start/#231-output-metrics","title":"2.3.1 Output Metrics","text":"<p>To query output metrics, use the following command: <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, if you used the training DAG from above, you can use <code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code> to query metrics. The query result will look like this: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"quick_start/#232-output-models","title":"2.3.2 Output Models","text":""},{"location":"quick_start/#2321-querying-models","title":"2.3.2.1 Querying Models","text":"<p>To query output models, use the following command: <pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, if you used the training DAG from above, you can use <code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code> to query models. The query result will be similar to this:</p> <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"model\": {\n                \"file\": \"202308211911505128750_host_9998_lr_0\",\n                \"namespace\": \"202308211911505128750_host_9998_lr_0\"\n            },\n            \"name\": \"HeteroLRHost_9998_0\",\n            \"namespace\": \"202308211911505128750_host_9998_lr_0\",\n            \"role\": \"host\",\n            \"party_id\": \"9998\",\n            \"work_mode\": 1\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre>"},{"location":"quick_start/#2322-downloading-models","title":"2.3.2.2 Downloading Models","text":"<p>To download models, use the following command: <pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> For example, if you used the training DAG from above, you can use <code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code> to download the model. The download result will be similar to this:</p> <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre>"},{"location":"quick_start/#233-output-data","title":"2.3.3 Output Data","text":""},{"location":"quick_start/#2331-querying-data-tables","title":"2.3.3.1 Querying Data Tables","text":"<p>To query output data tables, use the following command: <pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, if you used the training DAG from above, you can use <code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> to query data tables. The query result will be similar to this:</p> <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre>"},{"location":"quick_start/#2332-preview-data","title":"2.3.3.2 Preview Data","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> To preview output data using the above training DAG submission, you can use the following command: <code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code>.</p>"},{"location":"quick_start/#2333-download-data","title":"2.3.3.3 Download Data","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> To download output data using the above training DAG submission, you can use the following command: <code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code>.</p> <p>The download result will be as follows: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"quick_start/#3-more-documentation","title":"3. More Documentation","text":"<ul> <li>Restful-api</li> <li>CLI</li> <li>Pipeline</li> <li>FATE Quick Start</li> <li>FATE Algorithms</li> </ul>"},{"location":"system_conf/","title":"System Configuration","text":"<p>FATE Flow uses YAML to define system configurations, and the configuration file is located at: <code>conf/service_conf.yaml</code>. The specific configuration contents and their meanings are as follows:</p> Configuration Item Description Values party_id Local site ID For example, \"9999\", \"10000\" use_registry Whether to use a registry center; currently, only ZooKeeper mode is supported, and it requires correct ZooKeeper configuration. Note: If using high availability mode, ensure this configuration is set to true. true/false encrypt Encryption module See Encryption Module fateflow Configuration for the FATE Flow service, including ports, command channel service, and proxy See FateFlow Configuration database Configuration information for the database service See Database Configuration default_engines System's engine services, including computing, storage, and communication engines See Engine Configuration default_provider Component source information, including provider name, component version, and execution mode See Default Registered Algorithm Configuration federation Communication service pool See Communication Engine Pool computing Computing service pool See Computing Engine Pool storage Storage service pool See Storage Engine Pool hook_module Hook configuration, currently supports client authentication, site authentication, and authorization hooks See Hook Module Configuration authentication Authentication and authorization switches See Authentication Switch model_store Model storage configuration See Model Storage zookeeper ZooKeeper service configuration See ZooKeeper Configuration"},{"location":"system_conf/#encryption-module","title":"Encryption Module","text":"<p><pre><code>key_0:\n  module: fate_flow.hub.encrypt.password_encrypt#pwdecrypt\n  private_path: private_key.pem\n</code></pre> This encryption module is primarily used for encrypting passwords (e.g., MySQL passwords): - \"key_0\" is the key for the encryption module (you can customize the name), making it easier to reference in other configurations when multiple encryption modes coexist.   - module: The encryption module, formatted as \"encryption module\" + \"#\" + \"encryption function.\"   - private_path: The path to the encryption key. If you provide a relative path, its root directory is <code>fate_flow/conf/</code>.</p>"},{"location":"system_conf/#fateflow-configuration","title":"FateFlow Configuration","text":"<p><pre><code>host: 127.0.0.1\nhttp_port: 9380\ngrpc_port: 9360\nproxy_name: rollsite\nnginx:\n  host:\n  http_port:\n  grpc_port:\n</code></pre> - host: Host address. - http_port: HTTP port number. - grpc_port: gRPC port number. - proxy_name: Command channel service name, supporting osx/rollsite/nginx. Detailed configurations need to be set within Communication Engine Pool. - nginx: Proxy service configuration for load balancing.</p>"},{"location":"system_conf/#database-configuration","title":"Database Configuration","text":"<p><pre><code>engine: sqlite\ndecrypt_key:\nmysql:\n  name: fate_flow\n  user: fate\n  passwd: fate\n  host: 127.0.0.1\n  port: 3306\n  max_connections: 100\n  stale_timeout: 30\nsqlite:\n  path:\n</code></pre> - engine: Database engine name. If set to \"mysql\" here, update the detailed MySQL configuration. - decrypt_key: Encryption module, selected from Encryption Module. If not configured, it's considered to not use password encryption. If used, you need to set the \"passwd\" below to ciphertext and configure the key path in Encryption Module. - mysql: MySQL service configuration. If using password encryption functionality, set the \"passwd\" in this configuration to ciphertext and configure the key path in Encryption Module. - sqlite: SQLite file path, default path is <code>fate_flow/fate_flow_sqlite.db</code>.</p>"},{"location":"system_conf/#engine-configuration","title":"Engine Configuration","text":"<pre><code>default_engines:\n  computing: standalone\n  federation: standalone\n  storage: standalone\n</code></pre> <ul> <li>computing: Computing engine, supports \"standalone,\" \"eggroll,\" \"spark.\"</li> <li>federation: Communication engine, supports \"standalone,\" \"rollsite,\" \"osx,\" \"rabbitmq,\" \"pulsar.\"</li> <li>storage: Storage engine, supports \"standalone,\" \"eggroll,\" \"hdfs.\"</li> </ul>"},{"location":"system_conf/#default-registered-algorithm-configuration","title":"Default Registered Algorithm Configuration","text":"<ul> <li>name: Algorithm name.</li> <li>version: Algorithm version. If not configured, it uses the configuration in <code>fateflow.env</code>.</li> <li>device: Algorithm launch mode, local/docker/k8s, etc.</li> </ul>"},{"location":"system_conf/#communication-engine-pool","title":"Communication Engine Pool","text":""},{"location":"system_conf/#pulsar","title":"Pulsar","text":"<pre><code>pulsar:\n  host: 192.168.0.5\n  port: 6650\n  mng_port: 8080\n  cluster: standalone\n  tenant: fl-tenant\n  topic_ttl: 30\n  route_table:\n  mode: replication\n  max_message_size: 1048576\n</code></pre>"},{"location":"system_conf/#nginx","title":"Nginx:","text":"<pre><code>nginx:\n  host: 127.0.0.1\n  http_port: 9300\n  grpc_port: 9310\n  protocol: http\n</code></pre>"},{"location":"system_conf/#rabbitmq","title":"RabbitMQ","text":"<pre><code>nginx:\n  host: 127.0.0.1\n  http_port: 9300\n  grpc_port: 9310\n  protocol: http\n</code></pre>"},{"location":"system_conf/#rollsite","title":"Rollsite","text":"<pre><code>rollsite:\n  host: 127.0.0.1\n  port: 9370\n</code></pre>"},{"location":"system_conf/#osx","title":"OSx","text":"<pre><code>  host: 127.0.0.1\n  port: 9370\n</code></pre>"},{"location":"system_conf/#computing-engine-pool","title":"Computing Engine Pool","text":""},{"location":"system_conf/#standalone","title":"Standalone","text":"<p><pre><code>  cores: 32\n</code></pre> - cores: Total resources.</p>"},{"location":"system_conf/#eggroll","title":"Eggroll","text":"<p><pre><code>eggroll:\n  cores: 32\n  nodes: 2\n</code></pre> - cores: Total cluster resources. - nodes: Number of node managers in the cluster.</p>"},{"location":"system_conf/#spark","title":"Spark","text":"<p><pre><code>eggroll:\n  home: \n  cores: 32\n</code></pre> - home: Spark home directory. If not filled, \"pyspark\" will be used as the computing engine. - cores: Total resources.</p>"},{"location":"system_conf/#storage-engine-pool","title":"Storage Engine Pool","text":"<pre><code>  hdfs:\n    name_node: hdfs://fate-cluster\n</code></pre>"},{"location":"system_conf/#hook-module-configuration","title":"Hook Module Configuration","text":"<p><pre><code>hook_module:\n  client_authentication: fate_flow.hook.flow.client_authentication\n  site_authentication: fate_flow.hook.flow.site_authentication\n  permission: fate_flow.hook.flow.permission\n</code></pre> - client_authentication: Client authentication hook. - site_authentication: Site authentication hook. - permission: Permission authentication hook.</p>"},{"location":"system_conf/#authentication-switch","title":"Authentication Switch","text":"<pre><code>authentication:\n  client: false\n  site: false\n  permission: false\n</code></pre>"},{"location":"system_conf/#model-storage","title":"Model Storage","text":"<p><pre><code>model_store:\n  engine: file\n  decrypt_key:\n  file:\n    path:\n  mysql:\n    name: fate_flow\n    user: fate\n    passwd: fate\n    host: 127.0.0.1\n    port: 3306\n    max_connections: 100\n    stale_timeout: 30\n  tencent_cos:\n    Region:\n    SecretId:\n    SecretKey:\n    Bucket:\n</code></pre> - engine: Model storage engine, supports \"file,\" \"mysql\", and \"tencent_cos\". - decrypt_key: Encryption module, needs to be selected from Encryption Module. If not configured, it is assumed to not use password encryption. If used, you need to set the \"passwd\" below accordingly to ciphertext and configure the key path in Encryption Module. - file: Model storage directory, default location is <code>fate_flow/model</code>. - mysql: MySQL service configuration; if using password encryption functionality, you need to set the \"passwd\" in this configuration to ciphertext and configure the key path in Encryption Module. - tencent_cos: Tencent Cloud key configuration.</p>"},{"location":"system_conf/#zookeeper-configuration","title":"ZooKeeper Configuration","text":"<pre><code>zookeeper:\n  hosts:\n    - 127.0.0.1:2181\n  use_acl: true\n  user: fate\n  password: fate\n</code></pre>"},{"location":"mkdocs/","title":"Build","text":""},{"location":"mkdocs/#use-docker","title":"use docker","text":"<p>At repo root, execute</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs  \n</code></pre> <p>to serve docs in http://localhost:8000</p> <p>or</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs build\n</code></pre> <p>to build docs to <code>site</code> folder.</p>"},{"location":"mkdocs/#manually","title":"manually","text":"<p><code>mkdocs-material</code> and servel plugins are needed to build this docs</p> <p>Fisrt, create an python virtual environment</p> <p><pre><code>python3 -m venv \"fatedocs\"\nsource fatedocs/bin/activate\npip install -U pip\n</code></pre> And then install requirements</p> <pre><code>pip install -r doc/mkdocs/requirements.txt\n</code></pre> <p>Now, use</p> <pre><code>mkdocs serve\n</code></pre> <p>at repo root to serve docs or</p> <p>use </p> <pre><code>mkdocs build\n</code></pre> <p>at repo root to build docs to folder <code>site</code></p>"},{"location":"mkdocs/#develop-guide","title":"Develop guide","text":"<p>We use mkdocs-material to build our docs.  Servel markdown extensions are really useful to write pretty documents such as  admonitions and  content-tabs.</p> <p>Servel plugins are introdused to makes mkdocs-material much powerful:</p> <ul> <li> <p>mkdocstrings      automatic documentation from sources code. We mostly use this to automatic generate     <code>params api</code> for <code>federatedml</code>.</p> </li> <li> <p>awesome-pages     for powerful nav rule</p> </li> <li> <p>i18n     for multi-languege support</p> </li> <li> <p>mkdocs-jupyter     for jupyter format support</p> </li> <li> <p>mkdocs-simple-hooks     for simple plugin-in</p> </li> </ul>"},{"location":"mkdocs/docker/","title":"Image for build FATE's documents","text":"<p>This image is modified from mkdocs-meterial with some plugins embeded.</p> <p>Usage</p> <p>Mount the folder where your mkdocs.yml resides as a volume into /docs:</p> <ul> <li>Start development server on http://localhost:8000</li> </ul> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs\n</code></pre> <ul> <li>Build documentation</li> </ul> <pre><code>docker run --rm -it -v ${PWD}:/docs sagewei/mkdocs build\n</code></pre> <ul> <li>Deploy documentation to GitHub Pages</li> </ul> <pre><code>docker run --rm -it -v ~/.ssh:/root/.ssh -v ${PWD}:/docs sagewei0/mkdocs gh-deploy \n</code></pre>"},{"location":"mkdocs/theme/","title":"Index","text":"<p>Mostly copied from https://github.com/cirruslabs/cirrus-ci-docs/tree/master/theme</p>"},{"location":"swagger/","title":"API","text":""},{"location":"swagger/#swagger-api","title":"Swagger API","text":""},{"location":"zh/fate_flow/","title":"\u6574\u4f53\u8bbe\u8ba1","text":""},{"location":"zh/fate_flow/#1","title":"1. \u903b\u8f91\u67b6\u6784","text":"<ul> <li>DSL\u5b9a\u4e49\u4f5c\u4e1a</li> <li>\u81ea\u9876\u5411\u4e0b\u7684\u7eb5\u5411\u5b50\u4efb\u52a1\u6d41\u8c03\u5ea6\u3001\u591a\u53c2\u4e0e\u65b9\u8054\u5408\u5b50\u4efb\u52a1\u534f\u8c03</li> <li>\u72ec\u7acb\u9694\u79bb\u7684\u4efb\u52a1\u6267\u884c\u5de5\u4f5c\u8fdb\u7a0b</li> <li>\u652f\u6301\u591a\u7c7b\u578b\u591a\u7248\u672c\u7ec4\u4ef6</li> <li>\u8ba1\u7b97\u62bd\u8c61API</li> <li>\u5b58\u50a8\u62bd\u8c61API</li> <li>\u8de8\u65b9\u4f20\u8f93\u62bd\u8c61API</li> </ul>"},{"location":"zh/fate_flow/#2","title":"2. \u6574\u4f53\u67b6\u6784","text":""},{"location":"zh/fate_flow/#21-fate","title":"2.1 FATE\u6574\u4f53\u67b6\u6784","text":""},{"location":"zh/fate_flow/#22-fate-flow","title":"2.2 FATE Flow\u6574\u4f53\u67b6\u6784","text":""},{"location":"zh/fate_flow/#3","title":"3. \u8c03\u5ea6\u67b6\u6784","text":""},{"location":"zh/fate_flow/#31","title":"3.1 \u57fa\u4e8e\u5171\u4eab\u72b6\u6001\u7684\u5168\u65b0\u8c03\u5ea6\u67b6\u6784","text":"<ul> <li>\u5265\u79bb\u72b6\u6001(\u8d44\u6e90\u3001\u4f5c\u4e1a)\u4e0e\u7ba1\u7406\u5668(\u8c03\u5ea6\u5668\u3001\u8d44\u6e90\u7ba1\u7406\u5668)</li> <li>\u8d44\u6e90\u72b6\u6001\u4e0e\u4f5c\u4e1a\u72b6\u6001\u6301\u4e45\u5316\u5b58\u4e8eMySQL\uff0c\u5168\u5c40\u5171\u4eab\uff0c\u63d0\u4f9b\u53ef\u9760\u4e8b\u52a1\u6027\u64cd\u4f5c</li> <li>\u63d0\u9ad8\u7ba1\u7406\u670d\u52a1\u7684\u9ad8\u53ef\u7528\u4e0e\u6269\u5c55\u6027</li> <li>\u4f5c\u4e1a\u53ef\u4ecb\u5165\uff0c\u652f\u6301\u5b9e\u73b0\u5982\u91cd\u542f\u3001\u91cd\u8dd1\u3001\u5e76\u884c\u63a7\u5236\u3001\u8d44\u6e90\u9694\u79bb\u7b49</li> </ul>"},{"location":"zh/fate_flow/#32","title":"3.2 \u72b6\u6001\u9a71\u52a8\u8c03\u5ea6","text":"<ul> <li>\u8d44\u6e90\u534f\u8c03</li> <li>\u62c9\u8d77\u5b50\u8fdb\u7a0bExecutor\u8fd0\u884c\u7ec4\u4ef6</li> <li>Executor\u4e0a\u62a5\u72b6\u6001\u5230\u672c\u65b9Server\uff0c\u5e76\u4e14\u540c\u65f6\u4e0a\u62a5\u5230\u8c03\u5ea6\u65b9</li> <li>\u591a\u65b9\u4efb\u52a1\u72b6\u6001\u8ba1\u7b97\u8054\u90a6\u4efb\u52a1\u72b6\u6001</li> <li>\u4e0a\u4e0b\u6e38\u4efb\u52a1\u72b6\u6001\u8ba1\u7b97\u4f5c\u4e1a\u4f5c\u6001</li> </ul>"},{"location":"zh/fate_flow/#4","title":"4. \u591a\u65b9\u8d44\u6e90\u534f\u8c03","text":"<ul> <li>\u6bcf\u4e2a\u5f15\u64ce\u603b\u8d44\u6e90\u5927\u5c0f\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u914d\u7f6e\uff0c\u540e\u7eed\u5b9e\u73b0\u7cfb\u7edf\u5bf9\u63a5</li> <li>\u603b\u8d44\u6e90\u5927\u5c0f\u4e2d\u7684cores_per_node\u8868\u793a\u6bcf\u4e2a\u8ba1\u7b97\u8282\u70b9cpu\u6838\u6570\uff0cnodes\u8868\u793a\u8ba1\u7b97\u8282\u70b9\u4e2a\u6570</li> <li>FATEFlow server\u542f\u52a8\u65f6\u4ece\u914d\u7f6e\u6587\u4ef6\u8bfb\u53d6\u8d44\u6e90\u5927\u5c0f\u914d\u7f6e\uff0c\u5e76\u6ce8\u518c\u66f4\u65b0\u5230\u6570\u636e\u5e93</li> <li>\u4ee5Job\u7ef4\u5ea6\u7533\u8bf7\u8d44\u6e90\uff0cJob Conf\u63d0\u4ea4\u65f6\u751f\u6548\uff0c\u516c\u5f0f\uff1atask_parallelism*task_cores</li> <li>\u8be6\u7ec6\u8bf7\u770b\u6587\u6863\u5355\u72ec\u7ae0\u8282</li> </ul>"},{"location":"zh/fate_flow/#5","title":"5. \u6570\u636e\u6d41\u52a8\u8ffd\u8e2a","text":"<ul> <li>\u5b9a\u4e49</li> <li>metric type: \u6307\u6807\u7c7b\u578b\uff0c\u5982auc, loss, ks\u7b49\u7b49</li> <li>metric namespace: \u81ea\u5b9a\u4e49\u6307\u6807\u547d\u540d\u7a7a\u95f4\uff0c\u5982train, predict</li> <li>metric name: \u81ea\u5b9a\u4e49\u6307\u6807\u540d\u79f0\uff0c\u5982auc0\uff0chetero_lr_auc0</li> <li>metric data: key-value\u5f62\u5f0f\u7684\u6307\u6807\u6570\u636e</li> <li>metric meta: key-value\u5f62\u5f0f\u7684\u6307\u6807\u5143\u4fe1\u606f\uff0c\u652f\u6301\u7075\u6d3b\u753b\u56fe</li> <li>API</li> <li>log_metric_data(metric_namespace, metric_name, metrics)</li> <li>set_metric_meta(metric_namespace, metric_name, metric_meta)</li> <li>get_metric_data(metric_namespace, metric_name)</li> <li>get_metric_meta(metric_namespace, metric_name)</li> </ul>"},{"location":"zh/fate_flow/#6","title":"6. \u4f5c\u4e1a\u5b9e\u65f6\u76d1\u6d4b","text":"<ul> <li>\u5de5\u4f5c\u8fdb\u7a0b\u5b58\u6d3b\u6027\u68c0\u6d4b</li> <li>\u4f5c\u4e1a\u8d85\u65f6\u68c0\u6d4b</li> <li>\u8d44\u6e90\u56de\u6536\u68c0\u6d4b</li> <li>\u57fa\u7840\u5f15\u64ce\u4f1a\u8bdd\u8d85\u65f6\u68c0\u6d4b</li> </ul>"},{"location":"zh/fate_flow/#7","title":"7. \u4efb\u52a1\u7ec4\u4ef6\u4e2d\u5fc3","text":""},{"location":"zh/fate_flow/#8","title":"8. \u591a\u65b9\u8054\u5408\u6a21\u578b\u6ce8\u518c\u4e2d\u5fc3","text":"<ul> <li>\u4f7f\u7528Google Protocol Buffer\u4f5c\u4e3a\u6a21\u578b\u5b58\u50a8\u534f\u8bae\uff0c\u5229\u7528\u8de8\u8bed\u8a00\u5171\u4eab\uff0c\u6bcf\u4e2a\u7b97\u6cd5\u6a21\u578b\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1aModelParam &amp; ModelMeta</li> <li>\u4e00\u4e2aPipeline\u4ea7\u751f\u4e00\u7cfb\u5217\u7b97\u6cd5\u6a21\u578b</li> <li>\u547d\u540d\u4e3aPipeline\u7684\u6a21\u578b\u5b58\u50a8Pipeline\u5efa\u6a21DSL\u53ca\u5728\u7ebf\u63a8\u7406DSL</li> <li>\u8054\u90a6\u5b66\u4e60\u4e0b\uff0c\u9700\u8981\u4fdd\u8bc1\u6240\u6709\u53c2\u4e0e\u65b9\u6a21\u578b\u4e00\u81f4\u6027\uff0c\u5373\u6a21\u578b\u7ed1\u5b9a</li> <li>model_key\u4e3a\u7528\u6237\u63d0\u4ea4\u4efb\u52a1\u65f6\u5b9a\u4e49\u7684\u6a21\u578b\u6807\u8bc6</li> <li>\u8054\u90a6\u5404\u65b9\u7684\u6a21\u578bID\u7531\u672c\u65b9\u6807\u8bc6\u4fe1\u606frole\u3001party_id\uff0c\u52a0model_key</li> <li>\u8054\u90a6\u5404\u65b9\u7684\u6a21\u578b\u7248\u672c\u5fc5\u987b\u552f\u4e00\u4e14\u4fdd\u6301\u4e00\u81f4\uff0cFATE-Flow\u76f4\u63a5\u8bbe\u7f6e\u4e3ajob_id</li> </ul>"},{"location":"zh/fate_flow/#9","title":"9. \u6570\u636e\u63a5\u5165","text":"<ul> <li>Upload\uff1a</li> <li>\u5916\u90e8\u5b58\u50a8\u76f4\u63a5\u5bfc\u5165\u5230FATE Storage\uff0c\u521b\u5efa\u4e00\u4e2a\u65b0\u7684DTable</li> <li> <p>\u4f5c\u4e1a\u8fd0\u884c\u65f6\uff0cReader\u76f4\u63a5\u4eceStorage\u8bfb\u53d6</p> </li> <li> <p>Table Bind\uff1a</p> </li> <li>\u5916\u90e8\u5b58\u50a8\u5730\u5740\u5173\u952e\u5230FATE\u4e00\u4e2a\u65b0\u7684DTable</li> <li>\u4f5c\u4e1a\u8fd0\u884c\u65f6\uff0cReader\u901a\u8fc7Meta\u4ece\u5916\u90e8\u5b58\u50a8\u8bfb\u53d6\u6570\u636e\u5e76\u8f6c\u5b58\u5230FATE Storage</li> <li>\u6253\u901a\u5927\u6570\u636e\u751f\u6001\uff1aHDFS\uff0cHive/MySQL</li> </ul> <p></p>"},{"location":"zh/fate_flow/#10","title":"10. \u591a\u65b9\u5408\u4f5c\u6743\u9650\u7ba1\u7406","text":""},{"location":"zh/quick_start/","title":"\u5feb\u901f\u5165\u95e8","text":""},{"location":"zh/quick_start/#1","title":"1. \u73af\u5883\u90e8\u7f72","text":"<p>\u4ee5\u4e0b\u4e09\u79cd\u6a21\u5f0f\u53ef\u6839\u636e\u9700\u6c42\u81ea\u884c\u9009\u62e9\u4e00\u79cd</p>"},{"location":"zh/quick_start/#11-pypi","title":"1.1 Pypi\u5305\u5b89\u88c5","text":"<p>\u8bf4\u660e\uff1a\u6b64\u65b9\u5f0f\u7684\u8fd0\u884c\u6a21\u5f0f\u4e3a\u5355\u673a\u6a21\u5f0f</p>"},{"location":"zh/quick_start/#111","title":"1.1.1 \u5b89\u88c5","text":"<ul> <li>conda\u73af\u5883\u51c6\u5907\u53ca\u5b89\u88c5</li> <li>\u521b\u5efa\u865a\u62df\u73af\u5883 <pre><code># fate\u7684\u8fd0\u884c\u73af\u5883\u4e3apython&gt;=3.8\nconda create -n fate_env python=3.8\nconda activate fate_env\n</code></pre></li> <li>\u5b89\u88c5fate flow\u53ca\u76f8\u5173\u4f9d\u8d56 <pre><code>pip install fate_client[fate,fate_flow]==2.0.0.b0\n</code></pre></li> </ul>"},{"location":"zh/quick_start/#112","title":"1.1.2 \u670d\u52a1\u521d\u59cb\u5316","text":"<p><pre><code>fate_flow init --ip 127.0.0.1 --port 9380 --home $HOME_DIR\n</code></pre> - ip: \u670d\u52a1\u8fd0\u884cip - port\uff1a\u670d\u52a1\u8fd0\u884c\u65f6\u7684http\u7aef\u53e3 - home: \u6570\u636e\u5b58\u50a8\u76ee\u5f55\u3002\u4e3b\u8981\u5305\u62ec\uff1a\u6570\u636e/\u6a21\u578b/\u65e5\u5fd7/\u4f5c\u4e1a\u914d\u7f6e/sqlite.db\u7b49\u5185\u5bb9</p>"},{"location":"zh/quick_start/#113","title":"1.1.3 \u670d\u52a1\u542f\u505c","text":"<pre><code>fate_flow status/start/stop/restart\n</code></pre>"},{"location":"zh/quick_start/#12","title":"1.2 \u5355\u673a\u7248\u90e8\u7f72","text":"<p>\u53c2\u8003\u5355\u673a\u7248\u90e8\u7f72</p>"},{"location":"zh/quick_start/#13","title":"1.3 \u96c6\u7fa4\u90e8\u7f72","text":"<p>\u53c2\u8003allinone\u90e8\u7f72</p>"},{"location":"zh/quick_start/#2","title":"2. \u4f7f\u7528\u6307\u5357","text":"<p>fate\u63d0\u4f9b\u7684\u5ba2\u6237\u7aef\u5305\u62ecSDK\u3001CLI\u548cPipeline\uff0c\u82e5\u4f60\u7684\u73af\u5883\u4e2d\u6ca1\u6709\u90e8\u7f72FATE Client,\u53ef\u4ee5\u4f7f\u7528<code>pip install fate_client</code>\u4e0b\u8f7d\uff0c\u4ee5\u4e0b\u7684\u4f7f\u7528\u64cd\u4f5c\u5747\u57fa\u4e8ecli\u7f16\u5199\u3002</p>"},{"location":"zh/quick_start/#21","title":"2.1 \u6570\u636e\u4e0a\u4f20","text":"<p>\u57282.0-beta\u7248\u672c\u4e2d\uff0c\u6570\u636e\u4e0a\u4f20\u5206\u4e3a\u4e24\u6b65\uff1a - upload: \u5c06\u6570\u636e\u4e0a\u4f20\u5230FATE\u652f\u6301\u5b58\u50a8\u670d\u52a1\u4e2d  - transformer: \u5c06\u6570\u636e\u8f6c\u5316\u6210dataframe</p>"},{"location":"zh/quick_start/#2111","title":"2.1.1.1 \u914d\u7f6e\u53ca\u6570\u636e","text":"<ul> <li>\u4e0a\u4f20\u914d\u7f6e\u4f4d\u4e8eexamples-upload\uff0c\u4e0a\u4f20\u6570\u636e\u4f4d\u4e8eupload-data</li> <li>\u4f60\u4e5f\u53ef\u4ee5\u4f7f\u7528\u81ea\u5df1\u7684\u6570\u636e\uff0c\u5e76\u4fee\u6539upload\u914d\u7f6e\u4e2d\u7684\"meta\"\u4fe1\u606f\u3002</li> </ul>"},{"location":"zh/quick_start/#2112-guest","title":"2.1.1.2 \u4e0a\u4f20guest\u65b9\u6570\u636e","text":"<p><pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre> - \u9700\u8981\u8bb0\u5f55\u8fd4\u56de\u7684name\u548cnamespace\uff0c\u4f5c\u4e3atransformer\u7684\u53c2\u6570\u3002</p>"},{"location":"zh/quick_start/#2113-host","title":"2.1.1.3 \u4e0a\u4f20host\u65b9\u6570\u636e","text":"<p><pre><code>flow data upload -c examples/upload/upload_host.json\n</code></pre> - \u9700\u8981\u8bb0\u5f55\u8fd4\u56de\u7684name\u548cnamespace\uff0c\u4f5c\u4e3atransformer\u7684\u53c2\u6570\u3002</p>"},{"location":"zh/quick_start/#2114","title":"2.1.1.4 \u4e0a\u4f20\u7ed3\u679c","text":"<p><pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"36491bc8-3fef-11ee-be05-16b977118319\",\n        \"namespace\": \"upload\"\n    },\n    \"job_id\": \"202308211451535620150\",\n    \"message\": \"success\"\n}\n</code></pre> \u5176\u4e2d\"namespace\"\u548c\"name\"\u662f\u8fd9\u4efd\u6570\u636e\u5728fate\u4e2d\u7684\u6807\u8bc6\uff0c\u4ee5\u4fbf\u4e0b\u9762\u540e\u7eedtransformer\u9636\u6bb5\u4f7f\u7528\u65f6\u53ef\u76f4\u63a5\u5f15\u7528\u3002</p>"},{"location":"zh/quick_start/#2115","title":"2.1.1.5 \u6570\u636e\u67e5\u8be2","text":"<p>\u56e0\u4e3aupload\u4e3a\u5f02\u6b65\u64cd\u4f5c\uff0c\u9700\u8981\u786e\u8ba4\u662f\u5426\u4e0a\u4f20\u6210\u529f\u624d\u53ef\u8fdb\u884c\u540e\u7eed\u64cd\u4f5c\u3002 <pre><code>flow table query --namespace upload --name 36491bc8-3fef-11ee-be05-16b977118319\n</code></pre> \u4e0a\u4f20\u6210\u529f\u4fe1\u606f\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"count\": 569,\n        \"data_type\": \"table\",\n        \"engine\": \"standalone\",\n        \"meta\": {\n            \"delimiter\": \",\",\n            \"dtype\": \"'float32\",\n            \"header\": \"extend_sid,id,x0,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19\",\n            \"input_format\": \"dense\",\n            \"label_type\": \"int\",\n            \"match_id_name\": \"id\",\n            \"match_id_range\": 0,\n            \"sample_id_name\": \"extend_sid\",\n            \"tag_value_delimiter\": \":\",\n            \"tag_with_value\": false,\n            \"weight_type\": \"float32\"\n        },\n        \"name\": \"36491bc8-3fef-11ee-be05-16b977118319\",\n        \"namespace\": \"upload\",\n        \"path\": \"xxx\",\n        \"source\": {\n            \"component\": \"upload\",\n            \"output_artifact_key\": \"data\",\n            \"output_index\": null,\n            \"party_task_id\": \"\",\n            \"task_id\": \"\",\n            \"task_name\": \"upload\"\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre> \u82e5\u8fd4\u56de\u7684code\u4e3a0\u5373\u4e3a\u4e0a\u4f20\u6210\u529f\u3002</p>"},{"location":"zh/quick_start/#212-transformer","title":"2.1.2 transformer","text":""},{"location":"zh/quick_start/#2121","title":"2.1.2.1 \u914d\u7f6e","text":"<ul> <li>transformer\u914d\u7f6e\u4f4d\u4e8eexamples-transformer</li> </ul>"},{"location":"zh/quick_start/#2122-transformer-guest","title":"2.1.2.2 transformer guest","text":"<ul> <li>\u914d\u7f6e\u8def\u5f84\u4f4d\u4e8e\uff1a examples/transformer/transformer_guest.json</li> <li>\u4fee\u6539\u914d\u7f6e\u4e2d\"data_warehouse\"\u7684\"namespace\"\u548c\"name\"\uff1a\u4e0a\u9762upload guest\u9636\u6bb5\u7684\u8f93\u51fa <pre><code>flow data transformer -c examples/transformer/transformer_guest.json\n</code></pre></li> </ul>"},{"location":"zh/quick_start/#2123-transformer-host","title":"2.1.2.3 transformer host","text":"<ul> <li>\u914d\u7f6e\u8def\u5f84\u4f4d\u4e8e\uff1a examples/transformer/transformer_host.json</li> <li>\u4fee\u6539\u914d\u7f6e\u4e2d\"data_warehouse\"\u7684\"namespace\"\u548c\"name\"\uff1a\u4e0a\u9762upload host\u9636\u6bb5\u7684\u8f93\u51fa <pre><code>flow data transformer -c examples/transformer/transformer_host.json\n</code></pre></li> </ul>"},{"location":"zh/quick_start/#2124-transformer","title":"2.1.2.4 transformer\u7ed3\u679c","text":"<p><pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\"\n    },\n    \"job_id\": \"202308211557455662860\",\n    \"message\": \"success\"\n}\n</code></pre> \u5176\u4e2d\"namespace\"\u548c\"name\"\u662f\u8fd9\u4efd\u6570\u636e\u5728fate\u4e2d\u7684\u6807\u8bc6\uff0c\u540e\u7eed\u5efa\u6a21\u4f5c\u4e1a\u4e2d\u4f7f\u7528\u3002</p>"},{"location":"zh/quick_start/#2125","title":"2.1.2.5 \u67e5\u770b\u6570\u636e\u662f\u5426\u4e0a\u4f20\u6210\u529f","text":"<p>\u56e0\u4e3atransformer\u4e5f\u662f\u5f02\u6b65\u64cd\u4f5c\uff0c\u9700\u8981\u786e\u8ba4\u662f\u5426\u4e0a\u4f20\u6210\u529f\u624d\u53ef\u8fdb\u884c\u540e\u7eed\u64cd\u4f5c\u3002 <pre><code>flow table query --namespace experiment  --name breast_hetero_guest\n</code></pre> <pre><code>flow table query --namespace experiment  --name breast_hetero_host\n</code></pre> \u82e5\u8fd4\u56de\u7684code\u4e3a0\u5373\u4e3a\u4e0a\u4f20\u6210\u529f\u3002</p>"},{"location":"zh/quick_start/#22-fate","title":"2.2 \u5f00\u59cbFATE\u4f5c\u4e1a","text":""},{"location":"zh/quick_start/#221","title":"2.2.1 \u63d0\u4ea4\u4f5c\u4e1a","text":"<p>\u5f53\u4f60\u7684\u6570\u636e\u51c6\u5907\u597d\u540e\uff0c\u53ef\u4ee5\u5f00\u59cb\u63d0\u4ea4\u4f5c\u4e1a\u7ed9FATE Flow\uff1a - \u8bad\u7ec3job\u914d\u7f6eexample\u4f4d\u4e8elr-train; - \u9884\u6d4bjob\u914d\u7f6eexample\u4f4d\u4e8elr-predict;\u9884\u6d4b\u4efb\u52a1\u9700\u8981\u4fee\u6539\"dag.conf.model_warehouse\"\u6210\u8bad\u7ec3\u4f5c\u4e1a\u7684\u8f93\u51fa\u6a21\u578b\u3002 - \u8bad\u7ec3\u548c\u9884\u6d4bjob\u914d\u7f6e\u4e2d\u7ad9\u70b9id\u4e3a\"9998\"\u548c\"9999\"\u3002\u5982\u679c\u4f60\u7684\u90e8\u7f72\u73af\u5883\u4e3a\u96c6\u7fa4\u7248\uff0c\u9700\u8981\u66ff\u6362\u6210\u771f\u5b9e\u7684\u7ad9\u70b9id\uff1b\u5355\u673a\u7248\u53ef\u4f7f\u7528\u9ed8\u8ba4\u914d\u7f6e\u3002 - \u5982\u679c\u60f3\u8981\u4f7f\u7528\u81ea\u5df1\u7684\u6570\u636e\uff0c\u53ef\u4ee5\u66f4\u6539\u914d\u7f6e\u4e2dguest\u548chost\u7684data_warehouse\u7684namespace\u548cname - \u63d0\u4ea4\u4f5c\u4e1a\u7684\u547d\u4ee4\u4e3a: <pre><code>flow job submit -c examples/lr/train_lr.yaml \n</code></pre> - \u63d0\u4ea4\u6210\u529f\u8fd4\u56de\u7ed3\u679c: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"model_id\": \"202308211911505128750\",\n        \"model_version\": \"0\"\n    },\n    \"job_id\": \"202308211911505128750\",\n    \"message\": \"success\"\n}\n</code></pre> \u8fd9\u91cc\u7684\"data\"\u5185\u5bb9\u5373\u4e3a\u8be5\u4f5c\u4e1a\u7684\u8f93\u51fa\u6a21\u578b\u3002</p>"},{"location":"zh/quick_start/#222","title":"2.2.2 \u67e5\u8be2\u4f5c\u4e1a","text":"<p>\u5728\u4f5c\u4e1a\u7684\u8fd0\u884c\u8fc7\u7a0b\u65f6\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u67e5\u8be2\u547d\u4ee4\u83b7\u53d6\u4f5c\u4e1a\u7684\u8fd0\u884c\u72b6\u6001 <pre><code>flow job query -j $job_id\n</code></pre></p>"},{"location":"zh/quick_start/#223","title":"2.2.3 \u505c\u6b62\u4f5c\u4e1a","text":"<p>\u5728\u4f5c\u4e1a\u7684\u8fd0\u884c\u8fc7\u7a0b\u65f6\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u505c\u6b62\u4f5c\u4e1a\u547d\u4ee4\u6765\u7ec8\u6b62\u5f53\u524d\u4f5c\u4e1a <pre><code>flow job stop -j $job_id\n</code></pre></p>"},{"location":"zh/quick_start/#224","title":"2.2.4 \u91cd\u8dd1\u4f5c\u4e1a","text":"<p>\u5728\u4f5c\u4e1a\u7684\u8fd0\u884c\u8fc7\u7a0b\u65f6\uff0c\u5982\u679c\u8fd0\u884c\u5931\u8d25\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u91cd\u8dd1\u547d\u4ee4\u6765\u91cd\u8dd1\u5f53\u524d\u4f5c\u4e1a <pre><code>flow job rerun -j $job_id\n</code></pre></p>"},{"location":"zh/quick_start/#23","title":"2.3 \u83b7\u53d6\u4f5c\u4e1a\u8f93\u51fa\u7ed3\u679c","text":"<p>\u4f5c\u4e1a\u7684\u8f93\u51fa\u5305\u62ec\u6570\u636e\u3001\u6a21\u578b\u548c\u6307\u6807</p>"},{"location":"zh/quick_start/#231","title":"2.3.1 \u8f93\u51fa\u6307\u6807","text":"<p>\u67e5\u8be2\u8f93\u51fa\u6307\u6807\u547d\u4ee4\uff1a <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code>\u67e5\u8be2\u3002 \u67e5\u8be2\u7ed3\u679c\u5982\u4e0b: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"zh/quick_start/#232","title":"2.3.2 \u8f93\u51fa\u6a21\u578b","text":""},{"location":"zh/quick_start/#2321","title":"2.3.2.1 \u67e5\u8be2\u6a21\u578b","text":"<p><pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code>\u67e5\u8be2\u3002 \u67e5\u8be2\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"output_model\": {\n            \"data\": {\n                \"estimator\": {\n                    \"end_epoch\": 10,\n                    \"is_converged\": false,\n                    \"lr_scheduler\": {\n                        \"lr_params\": {\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100\n                        },\n                        \"lr_scheduler\": {\n                            \"_get_lr_called_within_step\": false,\n                            \"_last_lr\": [\n                                0.07269999999999996\n                            ],\n                            \"_step_count\": 10,\n                            \"base_lrs\": [\n                                0.1\n                            ],\n                            \"end_factor\": 1.0,\n                            \"last_epoch\": 9,\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100,\n                            \"verbose\": false\n                        },\n                        \"method\": \"linear\"\n                    },\n                    \"optimizer\": {\n                        \"alpha\": 0.001,\n                        \"l1_penalty\": false,\n                        \"l2_penalty\": true,\n                        \"method\": \"sgd\",\n                        \"model_parameter\": [\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ]\n                        ],\n                        \"model_parameter_dtype\": \"float32\",\n                        \"optim_param\": {\n                            \"lr\": 0.1\n                        },\n                        \"optimizer\": {\n                            \"param_groups\": [\n                                {\n                                    \"dampening\": 0,\n                                    \"differentiable\": false,\n                                    \"foreach\": null,\n                                    \"initial_lr\": 0.1,\n                                    \"lr\": 0.07269999999999996,\n                                    \"maximize\": false,\n                                    \"momentum\": 0,\n                                    \"nesterov\": false,\n                                    \"params\": [\n                                        0\n                                    ],\n                                    \"weight_decay\": 0\n                                }\n                            ],\n                            \"state\": {}\n                        }\n                    },\n                    \"param\": {\n                        \"coef_\": [\n                            [\n                                -0.10828543454408646\n                            ],\n                            [\n                                -0.07341302931308746\n                            ],\n                            [\n                                -0.10850320011377335\n                            ],\n                            [\n                                -0.10066638141870499\n                            ],\n                            [\n                                -0.04595951363444328\n                            ],\n                            [\n                                -0.07001449167728424\n                            ],\n                            [\n                                -0.08949052542448044\n                            ],\n                            [\n                                -0.10958756506443024\n                            ],\n                            [\n                                -0.04012322425842285\n                            ],\n                            [\n                                0.02270071767270565\n                            ],\n                            [\n                                -0.07198350876569748\n                            ],\n                            [\n                                0.00548586156219244\n                            ],\n                            [\n                                -0.06599288433790207\n                            ],\n                            [\n                                -0.06410090625286102\n                            ],\n                            [\n                                0.016374297440052032\n                            ],\n                            [\n                                -0.01607361063361168\n                            ],\n                            [\n                                -0.011447405442595482\n                            ],\n                            [\n                                -0.04352564364671707\n                            ],\n                            [\n                                0.013161249458789825\n                            ],\n                            [\n                                0.013506329618394375\n                            ]\n                        ],\n                        \"dtype\": \"float32\",\n                        \"intercept_\": null\n                    }\n                }\n            },\n            \"meta\": {\n                \"batch_size\": null,\n                \"epochs\": 10,\n                \"init_param\": {\n                    \"fill_val\": 0.0,\n                    \"fit_intercept\": false,\n                    \"method\": \"zeros\",\n                    \"random_state\": null\n                },\n                \"label_count\": false,\n                \"learning_rate_param\": {\n                    \"method\": \"linear\",\n                    \"scheduler_params\": {\n                        \"start_factor\": 0.7,\n                        \"total_iters\": 100\n                    }\n                },\n                \"optimizer_param\": {\n                    \"alpha\": 0.001,\n                    \"method\": \"sgd\",\n                    \"optimizer_params\": {\n                        \"lr\": 0.1\n                    },\n                    \"penalty\": \"l2\"\n                },\n                \"ovr\": false\n            }\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"zh/quick_start/#2322","title":"2.3.2.2 \u4e0b\u8f7d\u6a21\u578b","text":"<p><pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code>\u4e0b\u8f7d\u3002 \u4e0b\u8f7d\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre></p>"},{"location":"zh/quick_start/#233","title":"2.3.3 \u8f93\u51fa\u6570\u636e","text":""},{"location":"zh/quick_start/#2331","title":"2.3.3.1 \u67e5\u8be2\u6570\u636e\u8868","text":"<p><pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code>\u67e5\u8be2\u3002 \u67e5\u8be2\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"zh/quick_start/#2332","title":"2.3.3.2 \u9884\u89c8\u6570\u636e","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code>\u9884\u89c8\u8f93\u51fa\u6570\u636e\u3002</p>"},{"location":"zh/quick_start/#2333","title":"2.3.3.3 \u4e0b\u8f7d\u6570\u636e","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code>\u4e0b\u8f7d\u8f93\u51fa\u6570\u636e\u3002 \u4e0b\u8f7d\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"zh/quick_start/#3","title":"3.\u66f4\u591a\u6587\u6863","text":"<ul> <li>Restful-api</li> <li>CLI</li> <li>Pipeline</li> <li>FATE\u5feb\u901f\u5f00\u59cb</li> <li>FATE\u7b97\u6cd5</li> </ul>"},{"location":"zh/system_conf/","title":"\u7cfb\u7edf\u914d\u7f6e\u63cf\u8ff0\u6587\u6863","text":"<p>FATE Flow\u4f7f\u7528yaml\u5b9a\u4e49\u7cfb\u7edf\u914d\u7f6e\uff0c\u914d\u7f6e\u8def\u5f84\u4f4d\u4e8e: conf/service_conf.yaml, \u5177\u4f53\u914d\u7f6e\u5185\u5bb9\u53ca\u5176\u542b\u4e49\u5982\u4e0b\uff1a</p> \u914d\u7f6e\u9879 \u8bf4\u660e \u503c party_id \u672c\u65b9\u7ad9\u70b9id \u5982: \"9999\", \"10000 use_registry \u662f\u5426\u4f7f\u7528\u6ce8\u518c\u4e2d\u5fc3\uff0c\u5f53\u524d\u4ec5\u652f\u6301zookeeper\u6a21\u5f0f\uff0c\u9700\u8981\u4fdd\u8bc1zookeeper\u7684\u914d\u7f6e\u6b63\u786e\uff1b\u6ce8\uff1a\u82e5\u4f7f\u7528\u9ad8\u53ef\u7528\u6a21\u5f0f\uff0c\u9700\u4fdd\u8bc1\u8be5\u914d\u7f6e\u8bbe\u7f6e\u4e3atrue true/false encrypt \u52a0\u5bc6\u6a21\u5757 \u89c1\u52a0\u5bc6\u6a21\u5757 fateflow FATE Flow\u670d\u52a1\u7684\u914d\u7f6e\uff0c\u4e3b\u8981\u5305\u62ec\u7aef\u53e3\u3001\u547d\u4ee4\u901a\u9053\u670d\u52a1\u3001\u4ee3\u7406\u7b49 \u89c1FateFlow\u914d\u7f6e database \u6570\u636e\u5e93\u670d\u52a1\u7684\u914d\u7f6e\u4fe1\u606f \u89c1\u6570\u636e\u5e93\u914d\u7f6e default_engines \u7cfb\u7edf\u7684\u5f15\u64ce\u670d\u52a1\uff0c\u4e3b\u8981\u5305\u62ec\u8ba1\u7b97\u3001\u5b58\u50a8\u548c\u901a\u4fe1\u5f15\u64ce \u89c1\u5f15\u64ce\u914d\u7f6e default_provider \u7ec4\u4ef6\u7684\u6765\u6e90\u4fe1\u606f\uff0c\u4e3b\u8981\u5305\u62ec\u63d0\u4f9b\u65b9\u540d\u79f0\u3001\u7ec4\u4ef6\u7248\u672c\u548c\u8fd0\u884c\u6a21\u5f0f \u89c1\u9ed8\u8ba4\u6ce8\u518c\u7b97\u6cd5\u914d\u7f6e federation \u901a\u4fe1\u670d\u52a1\u6c60 \u89c1\u901a\u4fe1\u5f15\u64ce\u6c60 computing \u8ba1\u7b97\u670d\u52a1\u6c60 \u89c1\u8ba1\u7b97\u5f15\u64ce\u6c60 storage \u5b58\u50a8\u670d\u52a1\u6c60 \u89c1\u5b58\u50a8\u5f15\u64ce\u6c60 hook_module \u94a9\u5b50\u914d\u7f6e\uff0c\u5f53\u524d\u652f\u6301\u5ba2\u6237\u7aef\u8ba4\u8bc1\u3001\u7ad9\u70b9\u7aef\u8ba4\u8bc1\u4ee5\u53ca\u9274\u6743\u94a9\u5b50 \u89c1\u94a9\u5b50\u6a21\u5757\u914d\u7f6e authentication \u8ba4\u8bc1&amp;&amp;\u9274\u6743\u5f00\u5173 \u89c1\u8ba4\u8bc1\u5f00\u5173 model_store \u6a21\u578b\u5b58\u50a8\u914d\u7f6e \u89c1\u6a21\u578b\u5b58\u50a8 zookeeper zookeeper\u670d\u52a1\u7684\u914d\u7f6e \u89c1zookeeper\u914d\u7f6e"},{"location":"zh/system_conf/#_2","title":"\u52a0\u5bc6\u6a21\u5757","text":"<p><pre><code>key_0:\n  module: fate_flow.hub.encrypt.password_encrypt#pwdecrypt\n  private_path: private_key.pem\n</code></pre> \u8be5\u52a0\u5bc6\u6a21\u5757\u4e3b\u8981\u7528\u4e8e\u5bc6\u7801(\u5982mysql\u5bc6\u7801)\u7b49\u5185\u5bb9\u52a0\u5bc6\uff1a - \u5176\u4e2d\"key_0\"\u4e3a\u52a0\u5bc6\u6a21\u5757\u7684key(\u53ef\u4ee5\u81ea\u5b9a\u4e49\u540d\u5b57)\uff0c\u4fbf\u4e8e\u5176\u5b83\u914d\u7f6e\u4e2d\u76f4\u63a5\u5f15\u7528\uff0c\u591a\u5957\u52a0\u5bc6\u6a21\u5f0f\u5171\u5b58\u3002   - module: \u52a0\u5bc6\u6a21\u5757\uff0c\u62fc\u63a5\u89c4\u5219\u4e3a\uff1a\u52a0\u5bc6\u6a21\u5757 + \"#\" + \u52a0\u5bc6\u51fd\u6570\u3002   - private_path\uff1a\u5bc6\u94a5\u8def\u5f84\u3002\u5982\u586b\u76f8\u5bf9\u8def\u5f84\uff0c\u5176\u6839\u76ee\u5f55\u4f4d\u4e8efate_flow/conf/</p>"},{"location":"zh/system_conf/#fateflow","title":"FateFlow\u914d\u7f6e","text":"<p><pre><code>host: 127.0.0.1\nhttp_port: 9380\ngrpc_port: 9360\nproxy_name: rollsite\nnginx:\n  host:\n  http_port:\n  grpc_port:\n</code></pre> - host: \u4e3b\u673a\u5730\u5740; - http_port\uff1ahttp\u7aef\u53e3\u53f7; - grpc_port: grpc\u7aef\u53e3\u53f7; - proxy_name: \u547d\u4ee4\u901a\u9053\u670d\u52a1\u540d\uff0c\u652f\u6301osx/rollsite/nginx\u3002\u8be6\u7ec6\u914d\u7f6e\u9700\u8981\u5728\u901a\u4fe1\u5f15\u64ce\u6c60 \u91cc\u9762\u914d\u7f6e; - nginx: \u4ee3\u7406\u670d\u52a1\u914d\u7f6e\uff0c\u7528\u4e8e\u8d1f\u8f7d\u5747\u8861\u3002</p>"},{"location":"zh/system_conf/#_3","title":"\u6570\u636e\u5e93\u914d\u7f6e","text":"<p><pre><code>engine: sqlite\ndecrypt_key:\nmysql:\n  name: fate_flow\n  user: fate\n  passwd: fate\n  host: 127.0.0.1\n  port: 3306\n  max_connections: 100\n  stale_timeout: 30\nsqlite:\n  path:\n</code></pre> - engine: \u6570\u636e\u5e93\u5f15\u64ce\u540d\u5b57\uff0c\u5982\u8fd9\u91cc\u586b\"mysql\"\uff0c\u5219\u9700\u8981\u66f4\u65b0mysql\u7684\u914d\u7f6e\u8be6\u7ec6\u914d\u7f6e\u3002 - decrypt_key: \u52a0\u5bc6\u6a21\u5757,\u9700\u8981\u4ece\u52a0\u5bc6\u6a21\u5757\u4e2d\u9009\u62e9\u3002 \u82e5\u4e0d\u914d\u7f6e\uff0c\u89c6\u4e3a\u4e0d\u4f7f\u7528\u5bc6\u7801\u52a0\u5bc6\uff1b\u82e5\u4f7f\u7528\uff0c\u5219\u9700\u8981\u5c06\u4e0b\u9762\u7684passwd\u76f8\u5e94\u8bbe\u7f6e\u4e3a\u5bc6\u6587\u3002 - mysql: mysql\u670d\u52a1\u914d\u7f6e\uff1b\u82e5\u4f7f\u7528\u5bc6\u7801\u52a0\u5bc6\u529f\u80fd\uff0c\u9700\u8981\u5c06\u6b64\u914d\u7f6e\u4e2d\u7684\"passwd\"\u8bbe\u7f6e\u4e3a\u5bc6\u6587\uff0c\u5e76\u5728\u52a0\u5bc6\u6a21\u5757\u4e2d\u914d\u7f6e\u5bc6\u94a5\u8def\u5f84 - sqlite: sqlite\u6587\u4ef6\u8def\u5f84\uff0c\u9ed8\u8ba4\u8def\u5f84\u4e3afate_flow/fate_flow_sqlite.db</p>"},{"location":"zh/system_conf/#_4","title":"\u5f15\u64ce\u914d\u7f6e","text":"<pre><code>default_engines:\n  computing: standalone\n  federation: standalone\n  storage: standalone\n</code></pre> <ul> <li>computing: \u8ba1\u7b97\u5f15\u64ce\uff0c\u652f\u6301\"standalone\"\u3001\"eggroll\"\u3001\"spark\"</li> <li>federation: \u901a\u4fe1\u5f15\u64ce\uff0c\u652f\u6301\"standalone\"\u3001\"rollsite\"\u3001\"osx\"\u3001\"rabbitmq\"\u3001\"pulsar\"</li> <li>storage: \u5b58\u50a8\u5f15\u64ce\uff0c\u652f\u6301\"standalone\"\u3001\"eggroll\"\u3001\"hdfs\"</li> </ul>"},{"location":"zh/system_conf/#_5","title":"\u9ed8\u8ba4\u6ce8\u518c\u7b97\u6cd5\u914d\u7f6e","text":"<ul> <li>name: \u7b97\u6cd5\u540d\u79f0</li> <li>version: \u7b97\u6cd5\u7248\u672c\uff0c\u82e5\u4e0d\u914d\u7f6e\uff0c\u5219\u4f7f\u7528fateflow.env\u4e2d\u7684\u914d\u7f6e</li> <li>device: \u7b97\u6cd5\u542f\u52a8\u65b9\u5f0f, local/docker/k8s\u7b49</li> </ul>"},{"location":"zh/system_conf/#_6","title":"\u901a\u4fe1\u5f15\u64ce\u6c60","text":""},{"location":"zh/system_conf/#pulsar","title":"pulsar","text":"<pre><code>pulsar:\n  host: 192.168.0.5\n  port: 6650\n  mng_port: 8080\n  cluster: standalone\n  tenant: fl-tenant\n  topic_ttl: 30\n  # default conf/pulsar_route_table.yaml\n  route_table:\n  # mode: replication / client, default: replication\n  mode: replication\n  max_message_size: 1048576\n</code></pre>"},{"location":"zh/system_conf/#nginx","title":"nginx:","text":"<pre><code>nginx:\n  host: 127.0.0.1\n  http_port: 9300\n  grpc_port: 9310\n  # http or grpc\n  protocol: http\n</code></pre>"},{"location":"zh/system_conf/#rabbitmq","title":"rabbitmq","text":"<pre><code>nginx:\n  host: 127.0.0.1\n  http_port: 9300\n  grpc_port: 9310\n  # http or grpc\n  protocol: http\n</code></pre>"},{"location":"zh/system_conf/#rollsite","title":"rollsite","text":"<pre><code>rollsite:\n  host: 127.0.0.1\n  port: 9370\n</code></pre>"},{"location":"zh/system_conf/#osx","title":"osx","text":"<pre><code>  host: 127.0.0.1\n  port: 9370\n</code></pre>"},{"location":"zh/system_conf/#_7","title":"\u8ba1\u7b97\u5f15\u64ce\u6c60","text":""},{"location":"zh/system_conf/#standalone","title":"standalone","text":"<p><pre><code>  cores: 32\n</code></pre> - cores: \u8d44\u6e90\u603b\u6570</p>"},{"location":"zh/system_conf/#eggroll","title":"eggroll","text":"<p><pre><code>eggroll:\n  cores: 32\n  nodes: 2\n</code></pre> - cores: \u96c6\u7fa4\u8d44\u6e90\u603b\u6570 - nodes: \u96c6\u7fa4node-manager\u6570\u91cf</p>"},{"location":"zh/system_conf/#spark","title":"spark","text":"<p><pre><code>eggroll:\n  home: \n  cores: 32\n</code></pre> - home: spark home\u76ee\u5f55\uff0c\u5982\u679c\u4e0d\u586b\uff0c\u5c06\u4f7f\u7528\"pyspark\"\u4f5c\u4e3a\u8ba1\u7b97\u5f15\u64ce\u3002 - cores: \u8d44\u6e90\u603b\u6570</p>"},{"location":"zh/system_conf/#_8","title":"\u5b58\u50a8\u5f15\u64ce\u6c60","text":"<pre><code>  hdfs:\n    name_node: hdfs://fate-cluster\n</code></pre>"},{"location":"zh/system_conf/#_9","title":"\u94a9\u5b50\u6a21\u5757\u914d\u7f6e","text":"<p><pre><code>hook_module:\n  client_authentication: fate_flow.hook.flow.client_authentication\n  site_authentication: fate_flow.hook.flow.site_authentication\n  permission: fate_flow.hook.flow.permission\n</code></pre> - client_authentication: \u5ba2\u6237\u7aef\u8ba4\u8bc1\u94a9\u5b50 - site_authentication: \u7ad9\u70b9\u8ba4\u8bc1\u94a9\u5b50 - permission: \u6743\u9650\u8ba4\u8bc1\u94a9\u5b50</p>"},{"location":"zh/system_conf/#_10","title":"\u8ba4\u8bc1\u5f00\u5173","text":"<pre><code>authentication:\n  client: false\n  site: false\n  permission: false\n</code></pre>"},{"location":"zh/system_conf/#_11","title":"\u6a21\u578b\u5b58\u50a8","text":"<p><pre><code>model_store:\n  engine: file\n  decrypt_key:\n  file:\n    path:\n  mysql:\n    name: fate_flow\n    user: fate\n    passwd: fate\n    host: 127.0.0.1\n    port: 3306\n    max_connections: 100\n    stale_timeout: 30\n  tencent_cos:\n    Region:\n    SecretId:\n    SecretKey:\n    Bucket:\n</code></pre> - engine: \u6a21\u578b\u5b58\u50a8\u5f15\u64ce\uff0c\u652f\u6301\"file\"\u3001\"mysql\"\u548c\"tencent_cos\"\u3002 - decrypt_key: \u52a0\u5bc6\u6a21\u5757,\u9700\u8981\u4ece\u52a0\u5bc6\u6a21\u5757\u4e2d\u9009\u62e9\u3002 \u82e5\u4e0d\u914d\u7f6e\uff0c\u89c6\u4e3a\u4e0d\u4f7f\u7528\u5bc6\u7801\u52a0\u5bc6\uff1b\u82e5\u4f7f\u7528\uff0c\u5219\u9700\u8981\u5c06\u4e0b\u9762\u7684passwd\u76f8\u5e94\u8bbe\u7f6e\u4e3a\u5bc6\u6587\u3002 - file: \u6a21\u578b\u5b58\u50a8\u76ee\u5f55\uff0c\u9ed8\u8ba4\u4f4d\u4e8e\uff1a fate_flow/model - mysql: mysql\u670d\u52a1\u914d\u7f6e\uff1b\u82e5\u4f7f\u7528\u5bc6\u7801\u52a0\u5bc6\u529f\u80fd\uff0c\u9700\u8981\u5c06\u6b64\u914d\u7f6e\u4e2d\u7684\"passwd\"\u8bbe\u7f6e\u4e3a\u5bc6\u6587\uff0c\u5e76\u5728\u52a0\u5bc6\u6a21\u5757\u4e2d\u914d\u7f6e\u5bc6\u94a5\u8def\u5f84 - tencent_cos: \u817e\u8baf\u4e91\u5bc6\u94a5\u914d\u7f6e</p>"},{"location":"zh/system_conf/#zookeeper","title":"zookeeper\u914d\u7f6e","text":"<pre><code>zookeeper:\n  hosts:\n    - 127.0.0.1:2181\n  use_acl: true\n  user: fate\n  password: fate\n</code></pre>"},{"location":"fate_flow/","title":"Overall Design","text":""},{"location":"fate_flow/#1-logical-architecture","title":"1. Logical Architecture","text":"<ul> <li>DSL defined jobs</li> <li>Top-down vertical subtask flow scheduling, multi-participant joint subtask coordination</li> <li>Independent isolated task execution work processes</li> <li>Support for multiple types and versions of components</li> <li>Computational abstraction API</li> <li>Storage abstraction API</li> <li>Cross-party transfer abstraction API</li> </ul>"},{"location":"fate_flow/#2-service-architecture","title":"2. Service Architecture","text":""},{"location":"fate_flow/#21-fate","title":"2.1 FATE","text":""},{"location":"fate_flow/#22-fate-flow","title":"2.2 FATE Flow","text":""},{"location":"fate_flow/#3-scheduling-architecture","title":"3. Scheduling Architecture","text":""},{"location":"fate_flow/#31-a-new-scheduling-architecture-based-on-shared-state","title":"3.1 A new scheduling architecture based on shared-state","text":"<ul> <li>Stripping state (resources, jobs) and managers (schedulers, resource managers)</li> <li>Resource state and job state are persisted in MySQL and shared globally to provide reliable transactional operations</li> <li>Improve the high availability and scalability of managed services</li> <li>Jobs can be intervened to support restart, rerun, parallel control, resource isolation, etc.</li> </ul>"},{"location":"fate_flow/#32-state-driven-scheduling","title":"3.2 State-Driven Scheduling","text":"<ul> <li>Resource coordination</li> <li>Pull up the child process Executor to run the component</li> <li>Executor reports state to local Server and also to scheduler</li> <li>Multi-party task state calculation of federal task state</li> <li>Upstream and downstream task states compute job states</li> </ul>"},{"location":"fate_flow/#4-multiparty-resource-coordination","title":"4. Multiparty Resource Coordination","text":"<ul> <li>The total resource size of each engine is configured through the configuration file, and the system is subsequently interfaced</li> <li>The cores_per_node in the total resource size indicates the number of cpu cores per compute node, and nodes indicates the number of compute nodes.</li> <li>FATEFlow server reads the resource size configuration from the configuration file when it starts and registers the update to the database</li> <li>The resources are requested in Job dimension, and take effect when Job Conf is submitted, formula: task_parallelism*task_cores</li> <li>See separate section of the documentation for details</li> </ul>"},{"location":"fate_flow/#5-data-flow-tracking","title":"5. Data Flow Tracking","text":"<ul> <li>Definition</li> <li>metric type: metric type, such as auc, loss, ks, etc.</li> <li>metric namespace: custom metric namespace, e.g. train, predict</li> <li>metric name: custom metric name, e.g. auc0, hetero_lr_auc0</li> <li>metric data: metric data in key-value form</li> <li>metric meta: metric meta information in key-value form, support flexible drawing</li> <li>API</li> <li>log_metric_data(metric_namespace, metric_name, metrics)</li> <li>set_metric_meta(metric_namespace, metric_name, metric_meta)</li> <li>get_metric_data(metric_namespace, metric_name)</li> <li>get_metric_meta(metric_namespace, metric_name)</li> </ul>"},{"location":"fate_flow/#6-realtime-monitoring","title":"6. Realtime Monitoring","text":"<ul> <li>Job process survivability detection</li> <li>Job timeout detection</li> <li>Resource recovery detection</li> <li>Base engine session timeout detection</li> </ul>"},{"location":"fate_flow/#7-task-component-registry","title":"7. Task Component Registry","text":""},{"location":"fate_flow/#8-multi-party-federated-model-registry","title":"8. Multi-Party Federated Model Registry","text":"<ul> <li>Using Google Protocol Buffer as the model storage protocol, using cross-language sharing, each algorithmic model consists of two parts: ModelParam &amp; ModelMeta</li> <li>A Pipeline generates a series of algorithmic models</li> <li>The model named Pipeline stores Pipeline modeling DSL and online inference DSL</li> <li>Under federal learning, model consistency needs to be guaranteed for all participants, i.e., model binding</li> <li>model_key is the model identifier defined by the user when submitting the task</li> <li>The model IDs of the federated parties are the party identification information role, party_id, plus model_key</li> <li>The model version of the federated parties must be unique and consistent, and FATE-Flow directly sets it to job_id</li> </ul>"},{"location":"fate_flow/#9-data-access","title":"9. Data Access","text":"<ul> <li>Upload.</li> <li>External storage is imported directly to FATE Storage, creating a new DTable</li> <li> <p>When the job runs, Reader reads directly from Storage</p> </li> <li> <p>Table Bind.</p> </li> <li>Key the external storage address to a new DTable in FATE</li> <li>When the job is running, Reader reads data from external storage via Meta and transfers it to FATE Storage</li> <li>Connecting to the Big Data ecosystem: HDFS, Hive/MySQL</li> </ul> <p></p>"},{"location":"fate_flow/#10-multi-party-collaboration-authority-management","title":"10. Multi-Party Collaboration Authority Management","text":""},{"location":"quick_start/","title":"Quick Start","text":""},{"location":"quick_start/#1-environment-setup","title":"1. Environment Setup","text":"<p>You can choose one of the following three deployment modes based on your requirements:</p>"},{"location":"quick_start/#11-pypi-package-installation","title":"1.1 Pypi Package Installation","text":"<p>Note: This mode operates in a single-machine mode.</p>"},{"location":"quick_start/#111-installation","title":"1.1.1 Installation","text":"<ul> <li>Prepare and install conda environment.</li> <li>Create a virtual environment: <pre><code># FATE requires Python &gt;= 3.8\nconda create -n fate_env python=3.8\nconda activate fate_env\n</code></pre></li> <li>Install FATE Flow and related dependencies: <pre><code>pip install fate_client[fate,fate_flow]==2.0.0.b0\n</code></pre></li> </ul>"},{"location":"quick_start/#112-service-initialization","title":"1.1.2 Service Initialization","text":"<p><pre><code>fate_flow init --ip 127.0.0.1 --port 9380 --home $HOME_DIR\n</code></pre> - <code>ip</code>: The IP address where the service runs. - <code>port</code>: The HTTP port the service runs on. - <code>home</code>: The data storage directory, including data, models, logs, job configurations, and SQLite databases.</p>"},{"location":"quick_start/#113-service-startstop","title":"1.1.3 Service Start/Stop","text":"<pre><code>fate_flow status/start/stop/restart\n</code></pre>"},{"location":"quick_start/#12-standalone-deployment","title":"1.2 Standalone Deployment","text":"<p>Refer to Standalone Deployment.</p>"},{"location":"quick_start/#13-cluster-deployment","title":"1.3 Cluster Deployment","text":"<p>Refer to Allinone Deployment.</p>"},{"location":"quick_start/#2-user-guide","title":"2. User Guide","text":"<p>FATE provides client tools including SDK, CLI, and Pipeline. If you don't have FATE Client deployed in your environment, you can download it using <code>pip install fate_client</code>. The following operations are based on CLI.</p>"},{"location":"quick_start/#21-data-upload","title":"2.1 Data Upload","text":"<p>In version 2.0-beta, data uploading is a two-step process:</p> <ul> <li>upload: Uploads data to FATE-supported storage services.</li> <li>transformer: Transforms data into a DataFrame.</li> </ul>"},{"location":"quick_start/#211-upload","title":"2.1.1 upload","text":""},{"location":"quick_start/#2111-configuration-and-data","title":"2.1.1.1 Configuration and Data","text":"<ul> <li>Upload configuration can be found at examples-upload, and the data is located at upload-data.</li> <li>You can also use your own data and modify the \"meta\" information in the upload configuration.</li> </ul>"},{"location":"quick_start/#2112-upload-guest-data","title":"2.1.1.2 Upload Guest Data","text":"<p><pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre> - Record the returned \"name\" and \"namespace\" for use in the transformer phase.</p>"},{"location":"quick_start/#2113-upload-host-data","title":"2.1.1.3 Upload Host Data","text":"<p><pre><code>flow data upload -c examples/upload/upload_host.json\n</code></pre> - Record the returned \"name\" and \"namespace\" for use in the transformer phase.</p>"},{"location":"quick_start/#2114-upload-result","title":"2.1.1.4 Upload Result","text":"<p><pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"36491bc8-3fef-11ee-be05-16b977118319\",\n        \"namespace\": \"upload\"\n    },\n    \"job_id\": \"202308211451535620150\",\n    \"message\": \"success\"\n}\n</code></pre> Where \"namespace\" and \"name\" identify the data in FATE for future reference in the transformer phase.</p>"},{"location":"quick_start/#2115-data-query","title":"2.1.1.5 Data Query","text":"<p>Since upload is an asynchronous operation, you need to confirm if it was successful before proceeding to the next step. <pre><code>flow table query --namespace upload --name 36491bc8-3fef-11ee-be05-16b977118319\n</code></pre> If the returned code is 0, the upload was successful.</p>"},{"location":"quick_start/#212-transformer","title":"2.1.2 Transformer","text":""},{"location":"quick_start/#2121-configuration","title":"2.1.2.1 Configuration","text":"<ul> <li>Transformer configuration can be found at examples-transformer.</li> </ul>"},{"location":"quick_start/#2122-transform-guest-data","title":"2.1.2.2 Transform Guest Data","text":"<ul> <li>Configuration path: examples/transformer/transformer_guest.json</li> <li>Modify the \"namespace\" and \"name\" in the \"data_warehouse\" section to match the output from the guest data upload. <pre><code>flow data transformer -c examples/transformer/transformer_guest.json\n</code></pre></li> </ul>"},{"location":"quick_start/#2123-transform-host-data","title":"2.1.2.3 Transform Host Data","text":"<ul> <li>Configuration path: examples/transformer/transformer_host.json</li> <li>Modify the \"namespace\" and \"name\" in the \"data_warehouse\" section to match the output from the host data upload. <pre><code>flow data transformer -c examples/transformer/transformer_host.json\n</code></pre></li> </ul>"},{"location":"quick_start/#2124-transformer-result","title":"2.1.2.4 Transformer Result","text":"<p><pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\"\n    },\n    \"job_id\": \"202308211557455662860\",\n    \"message\": \"success\"\n}\n</code></pre> Where \"namespace\" and \"name\" identify the data in FATE for future modeling jobs.</p>"},{"location":"quick_start/#2125-check-if-data-upload-was-successful","title":"2.1.2.5 Check if Data Upload Was Successful","text":"<p>Since the transformer is also an asynchronous operation, you need to confirm if it was successful before proceeding. <pre><code>flow table query --namespace experiment --name breast_hetero_guest\n</code></pre> <pre><code>flow table query --namespace experiment --name breast_hetero_host\n</code></pre> If the returned code is 0, the upload was successful.</p>"},{"location":"quick_start/#22-starting-fate-jobs","title":"2.2 Starting FATE Jobs","text":""},{"location":"quick_start/#221-submitting-a-job","title":"2.2.1 Submitting a Job","text":"<p>Once your data is prepared, you can start submitting jobs to FATE Flow:</p> <ul> <li>The configuration for training jobs can be found in lr-train.</li> <li>The configuration for prediction jobs can be found in lr-predict. To use it, modify the \"dag.conf.model_warehouse\" to point to the output model of your training job.</li> <li>In the training and prediction job configurations, the site IDs are set to \"9998\" and \"9999.\" If your deployment environment is the cluster version, you need to replace them with the actual site IDs. For the standalone version, you can use the default configuration.</li> <li>If you want to use your own data, you can change the \"namespace\" and \"name\" of \"data_warehouse\" for both the guest and host in the configuration.</li> <li>To submit a job, use the following command: <pre><code>flow job submit -c examples/lr/train_lr.yaml \n</code></pre></li> <li>A successful submission will return the following result: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"model_id\": \"202308211911505128750\",\n        \"model_version\": \"0\"\n    },\n    \"job_id\": \"202308211911505128750\",\n    \"message\": \"success\"\n}\n</code></pre> The \"data\" section here contains the output model of the job.</li> </ul>"},{"location":"quick_start/#222-querying-a-job","title":"2.2.2 Querying a Job","text":"<p>While a job is running, you can check its status using the query command: <pre><code>flow job query -j $job_id\n</code></pre></p>"},{"location":"quick_start/#223-stopping-a-job","title":"2.2.3 Stopping a Job","text":"<p>During job execution, you can stop the current job using the stop command: <pre><code>flow job stop -j $job_id\n</code></pre></p>"},{"location":"quick_start/#224-rerunning-a-job","title":"2.2.4 Rerunning a Job","text":"<p>If a job fails during execution, you can rerun it using the rerun command: <pre><code>flow job rerun -j $job_id\n</code></pre></p>"},{"location":"quick_start/#23-obtaining-job-outputs","title":"2.3 Obtaining Job Outputs","text":"<p>Job outputs include data, models, and metrics.</p>"},{"location":"quick_start/#231-output-metrics","title":"2.3.1 Output Metrics","text":"<p>To query output metrics, use the following command: <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, if you used the training DAG from above, you can use <code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code> to query metrics. The query result will look like this: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"quick_start/#232-output-models","title":"2.3.2 Output Models","text":""},{"location":"quick_start/#2321-querying-models","title":"2.3.2.1 Querying Models","text":"<p>To query output models, use the following command: <pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, if you used the training DAG from above, you can use <code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code> to query models. The query result will be similar to this:</p> <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"model\": {\n                \"file\": \"202308211911505128750_host_9998_lr_0\",\n                \"namespace\": \"202308211911505128750_host_9998_lr_0\"\n            },\n            \"name\": \"HeteroLRHost_9998_0\",\n            \"namespace\": \"202308211911505128750_host_9998_lr_0\",\n            \"role\": \"host\",\n            \"party_id\": \"9998\",\n            \"work_mode\": 1\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre>"},{"location":"quick_start/#2322-downloading-models","title":"2.3.2.2 Downloading Models","text":"<p>To download models, use the following command: <pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> For example, if you used the training DAG from above, you can use <code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code> to download the model. The download result will be similar to this:</p> <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre>"},{"location":"quick_start/#233-output-data","title":"2.3.3 Output Data","text":""},{"location":"quick_start/#2331-querying-data-tables","title":"2.3.3.1 Querying Data Tables","text":"<p>To query output data tables, use the following command: <pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, if you used the training DAG from above, you can use <code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> to query data tables. The query result will be similar to this:</p> <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre>"},{"location":"quick_start/#2332-preview-data","title":"2.3.3.2 Preview Data","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> To preview output data using the above training DAG submission, you can use the following command: <code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code>.</p>"},{"location":"quick_start/#2333-download-data","title":"2.3.3.3 Download Data","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> To download output data using the above training DAG submission, you can use the following command: <code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code>.</p> <p>The download result will be as follows: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"quick_start/#3-more-documentation","title":"3. More Documentation","text":"<ul> <li>Restful-api</li> <li>CLI</li> <li>Pipeline</li> <li>FATE Quick Start</li> <li>FATE Algorithms</li> </ul>"},{"location":"system_conf/","title":"System Configuration","text":"<p>FATE Flow uses YAML to define system configurations, and the configuration file is located at: <code>conf/service_conf.yaml</code>. The specific configuration contents and their meanings are as follows:</p> Configuration Item Description Values party_id Local site ID For example, \"9999\", \"10000\" use_registry Whether to use a registry center; currently, only ZooKeeper mode is supported, and it requires correct ZooKeeper configuration. Note: If using high availability mode, ensure this configuration is set to true. true/false encrypt Encryption module See Encryption Module fateflow Configuration for the FATE Flow service, including ports, command channel service, and proxy See FateFlow Configuration database Configuration information for the database service See Database Configuration default_engines System's engine services, including computing, storage, and communication engines See Engine Configuration default_provider Component source information, including provider name, component version, and execution mode See Default Registered Algorithm Configuration federation Communication service pool See Communication Engine Pool computing Computing service pool See Computing Engine Pool storage Storage service pool See Storage Engine Pool hook_module Hook configuration, currently supports client authentication, site authentication, and authorization hooks See Hook Module Configuration authentication Authentication and authorization switches See Authentication Switch model_store Model storage configuration See Model Storage zookeeper ZooKeeper service configuration See ZooKeeper Configuration"},{"location":"system_conf/#encryption-module","title":"Encryption Module","text":"<p><pre><code>key_0:\n  module: fate_flow.hub.encrypt.password_encrypt#pwdecrypt\n  private_path: private_key.pem\n</code></pre> This encryption module is primarily used for encrypting passwords (e.g., MySQL passwords): - \"key_0\" is the key for the encryption module (you can customize the name), making it easier to reference in other configurations when multiple encryption modes coexist.   - module: The encryption module, formatted as \"encryption module\" + \"#\" + \"encryption function.\"   - private_path: The path to the encryption key. If you provide a relative path, its root directory is <code>fate_flow/conf/</code>.</p>"},{"location":"system_conf/#fateflow-configuration","title":"FateFlow Configuration","text":"<p><pre><code>host: 127.0.0.1\nhttp_port: 9380\ngrpc_port: 9360\nproxy_name: rollsite\nnginx:\n  host:\n  http_port:\n  grpc_port:\n</code></pre> - host: Host address. - http_port: HTTP port number. - grpc_port: gRPC port number. - proxy_name: Command channel service name, supporting osx/rollsite/nginx. Detailed configurations need to be set within Communication Engine Pool. - nginx: Proxy service configuration for load balancing.</p>"},{"location":"system_conf/#database-configuration","title":"Database Configuration","text":"<p><pre><code>engine: sqlite\ndecrypt_key:\nmysql:\n  name: fate_flow\n  user: fate\n  passwd: fate\n  host: 127.0.0.1\n  port: 3306\n  max_connections: 100\n  stale_timeout: 30\nsqlite:\n  path:\n</code></pre> - engine: Database engine name. If set to \"mysql\" here, update the detailed MySQL configuration. - decrypt_key: Encryption module, selected from Encryption Module. If not configured, it's considered to not use password encryption. If used, you need to set the \"passwd\" below to ciphertext and configure the key path in Encryption Module. - mysql: MySQL service configuration. If using password encryption functionality, set the \"passwd\" in this configuration to ciphertext and configure the key path in Encryption Module. - sqlite: SQLite file path, default path is <code>fate_flow/fate_flow_sqlite.db</code>.</p>"},{"location":"system_conf/#engine-configuration","title":"Engine Configuration","text":"<pre><code>default_engines:\n  computing: standalone\n  federation: standalone\n  storage: standalone\n</code></pre> <ul> <li>computing: Computing engine, supports \"standalone,\" \"eggroll,\" \"spark.\"</li> <li>federation: Communication engine, supports \"standalone,\" \"rollsite,\" \"osx,\" \"rabbitmq,\" \"pulsar.\"</li> <li>storage: Storage engine, supports \"standalone,\" \"eggroll,\" \"hdfs.\"</li> </ul>"},{"location":"system_conf/#default-registered-algorithm-configuration","title":"Default Registered Algorithm Configuration","text":"<ul> <li>name: Algorithm name.</li> <li>version: Algorithm version. If not configured, it uses the configuration in <code>fateflow.env</code>.</li> <li>device: Algorithm launch mode, local/docker/k8s, etc.</li> </ul>"},{"location":"system_conf/#communication-engine-pool","title":"Communication Engine Pool","text":""},{"location":"system_conf/#pulsar","title":"Pulsar","text":"<pre><code>pulsar:\n  host: 192.168.0.5\n  port: 6650\n  mng_port: 8080\n  cluster: standalone\n  tenant: fl-tenant\n  topic_ttl: 30\n  route_table:\n  mode: replication\n  max_message_size: 1048576\n</code></pre>"},{"location":"system_conf/#nginx","title":"Nginx:","text":"<pre><code>nginx:\n  host: 127.0.0.1\n  http_port: 9300\n  grpc_port: 9310\n  protocol: http\n</code></pre>"},{"location":"system_conf/#rabbitmq","title":"RabbitMQ","text":"<pre><code>nginx:\n  host: 127.0.0.1\n  http_port: 9300\n  grpc_port: 9310\n  protocol: http\n</code></pre>"},{"location":"system_conf/#rollsite","title":"Rollsite","text":"<pre><code>rollsite:\n  host: 127.0.0.1\n  port: 9370\n</code></pre>"},{"location":"system_conf/#osx","title":"OSx","text":"<pre><code>  host: 127.0.0.1\n  port: 9370\n</code></pre>"},{"location":"system_conf/#computing-engine-pool","title":"Computing Engine Pool","text":""},{"location":"system_conf/#standalone","title":"Standalone","text":"<p><pre><code>  cores: 32\n</code></pre> - cores: Total resources.</p>"},{"location":"system_conf/#eggroll","title":"Eggroll","text":"<p><pre><code>eggroll:\n  cores: 32\n  nodes: 2\n</code></pre> - cores: Total cluster resources. - nodes: Number of node managers in the cluster.</p>"},{"location":"system_conf/#spark","title":"Spark","text":"<p><pre><code>eggroll:\n  home: \n  cores: 32\n</code></pre> - home: Spark home directory. If not filled, \"pyspark\" will be used as the computing engine. - cores: Total resources.</p>"},{"location":"system_conf/#storage-engine-pool","title":"Storage Engine Pool","text":"<pre><code>  hdfs:\n    name_node: hdfs://fate-cluster\n</code></pre>"},{"location":"system_conf/#hook-module-configuration","title":"Hook Module Configuration","text":"<p><pre><code>hook_module:\n  client_authentication: fate_flow.hook.flow.client_authentication\n  site_authentication: fate_flow.hook.flow.site_authentication\n  permission: fate_flow.hook.flow.permission\n</code></pre> - client_authentication: Client authentication hook. - site_authentication: Site authentication hook. - permission: Permission authentication hook.</p>"},{"location":"system_conf/#authentication-switch","title":"Authentication Switch","text":"<pre><code>authentication:\n  client: false\n  site: false\n  permission: false\n</code></pre>"},{"location":"system_conf/#model-storage","title":"Model Storage","text":"<p><pre><code>model_store:\n  engine: file\n  decrypt_key:\n  file:\n    path:\n  mysql:\n    name: fate_flow\n    user: fate\n    passwd: fate\n    host: 127.0.0.1\n    port: 3306\n    max_connections: 100\n    stale_timeout: 30\n  tencent_cos:\n    Region:\n    SecretId:\n    SecretKey:\n    Bucket:\n</code></pre> - engine: Model storage engine, supports \"file,\" \"mysql\", and \"tencent_cos\". - decrypt_key: Encryption module, needs to be selected from Encryption Module. If not configured, it is assumed to not use password encryption. If used, you need to set the \"passwd\" below accordingly to ciphertext and configure the key path in Encryption Module. - file: Model storage directory, default location is <code>fate_flow/model</code>. - mysql: MySQL service configuration; if using password encryption functionality, you need to set the \"passwd\" in this configuration to ciphertext and configure the key path in Encryption Module. - tencent_cos: Tencent Cloud key configuration.</p>"},{"location":"system_conf/#zookeeper-configuration","title":"ZooKeeper Configuration","text":"<pre><code>zookeeper:\n  hosts:\n    - 127.0.0.1:2181\n  use_acl: true\n  user: fate\n  password: fate\n</code></pre>"},{"location":"mkdocs/","title":"Build","text":""},{"location":"mkdocs/#use-docker","title":"use docker","text":"<p>At repo root, execute</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs  \n</code></pre> <p>to serve docs in http://localhost:8000</p> <p>or</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs build\n</code></pre> <p>to build docs to <code>site</code> folder.</p>"},{"location":"mkdocs/#manually","title":"manually","text":"<p><code>mkdocs-material</code> and servel plugins are needed to build this docs</p> <p>Fisrt, create an python virtual environment</p> <p><pre><code>python3 -m venv \"fatedocs\"\nsource fatedocs/bin/activate\npip install -U pip\n</code></pre> And then install requirements</p> <pre><code>pip install -r doc/mkdocs/requirements.txt\n</code></pre> <p>Now, use</p> <pre><code>mkdocs serve\n</code></pre> <p>at repo root to serve docs or</p> <p>use </p> <pre><code>mkdocs build\n</code></pre> <p>at repo root to build docs to folder <code>site</code></p>"},{"location":"mkdocs/#develop-guide","title":"Develop guide","text":"<p>We use mkdocs-material to build our docs.  Servel markdown extensions are really useful to write pretty documents such as  admonitions and  content-tabs.</p> <p>Servel plugins are introdused to makes mkdocs-material much powerful:</p> <ul> <li> <p>mkdocstrings      automatic documentation from sources code. We mostly use this to automatic generate     <code>params api</code> for <code>federatedml</code>.</p> </li> <li> <p>awesome-pages     for powerful nav rule</p> </li> <li> <p>i18n     for multi-languege support</p> </li> <li> <p>mkdocs-jupyter     for jupyter format support</p> </li> <li> <p>mkdocs-simple-hooks     for simple plugin-in</p> </li> </ul>"},{"location":"mkdocs/docker/","title":"Image for build FATE's documents","text":"<p>This image is modified from mkdocs-meterial with some plugins embeded.</p> <p>Usage</p> <p>Mount the folder where your mkdocs.yml resides as a volume into /docs:</p> <ul> <li>Start development server on http://localhost:8000</li> </ul> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs\n</code></pre> <ul> <li>Build documentation</li> </ul> <pre><code>docker run --rm -it -v ${PWD}:/docs sagewei/mkdocs build\n</code></pre> <ul> <li>Deploy documentation to GitHub Pages</li> </ul> <pre><code>docker run --rm -it -v ~/.ssh:/root/.ssh -v ${PWD}:/docs sagewei0/mkdocs gh-deploy \n</code></pre>"},{"location":"mkdocs/theme/","title":"Index","text":"<p>Mostly copied from https://github.com/cirruslabs/cirrus-ci-docs/tree/master/theme</p>"},{"location":"swagger/","title":"API","text":""},{"location":"swagger/#swagger-api","title":"Swagger API","text":""}]}