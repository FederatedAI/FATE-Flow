{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"bfia_access/","title":"BFIA Integration Guide","text":"<p>The BFIA protocol, organized by the Beijing Financial Technology Industry Alliance and led by China UnionPay, is an API interface specification established jointly by over 60 units, including major financial institutions, telecom operators, internet companies, technology firms, testing agencies, and research institutes. FATE 2.0 has adapted this protocol across various layers like Pipeline, Scheduling, Communication, and more. This document will guide how to perform federated learning with FATE framework using the BFIA protocol.</p>"},{"location":"bfia_access/#1-pipeline","title":"1. Pipeline","text":"<p>The pipeline constructs a unified client for FATE's interoperation, generating a DAG configuration based on the FATE 2.0 protocol. The pipeline doesn't directly call the BFIA protocol API; instead, it utilizes the FATE protocol API and transforms it into BFIA protocol execution within the FATE Flow through an adapter pattern.</p>"},{"location":"bfia_access/#11-fate-algorithm","title":"1.1 FATE Algorithm","text":"<pre><code>from fate_client.pipeline import FateFlowPipeline\nfrom fate_client.pipeline.components.fate import CoordinatedLR, PSI\nfrom fate_client.pipeline.interface.channel import DataWarehouseChannel\n\n\nguest = \"JG0100001100000010\"\nhost = \"JG0100001100000010\"\narbiter = \"JG0100001100000010\"\npipeline = FateFlowPipeline().set_parties(guest=guest, host=host, arbiter=arbiter)\npipeline.set_site_role(\"guest\")\npipeline.set_site_party_id(guest)\n\npsi_0 = PSI(\"psi_0\",\n        input_data=[DataWarehouseChannel(dataset_id=\"experiment#breast_hetero_guest\", parties=dict(guest=guest)),\n                    DataWarehouseChannel(dataset_id=\"experiment#breast_hetero_host\", parties=dict(host=host))])\nlr_0 = CoordinatedLR(\"lr_0\",\n                 epochs=10,\n                 batch_size=300,\n                 optimizer={\"method\": \"SGD\", \"optimizer_params\": {\"lr\": 0.1}, \"penalty\": \"l2\", \"alpha\": 0.001},\n                 init_param={\"fit_intercept\": True, \"method\": \"zeros\"},\n                 train_data=psi_0.outputs[\"output_data\"],\n                 learning_rate_scheduler={\"method\": \"linear\", \"scheduler_params\": {\"start_factor\": 0.7,\n                                                                                   \"total_iters\": 100}})\n\npipeline.add_tasks([psi_0, lr_0])\n\npipeline.protocol_kind = \"bfia\"\npipeline.conf.set(\n\"extra\",\ndict(initiator={'party_id': guest, 'role': 'guest'})\n)\npipeline.guest.conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.hosts[0].conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.compile()\npipeline.fit()\n</code></pre>"},{"location":"bfia_access/#12-unionpay-algorithm","title":"1.2 UnionPay Algorithm","text":"<pre><code>from fate_client.pipeline import FateFlowPipeline\nfrom fate_client.pipeline.adapters.bfia.components.unionpay.intersection import Intersection\nfrom fate_client.pipeline.adapters.bfia.components.unionpay.hetero_lr import HeteroLR\nfrom fate_client.pipeline.interface import DataWarehouseChannel\n\n\npipeline = FateFlowPipeline().set_parties(\n    guest=\"JG0100001100000010\",\n    host=\"JG0100001100000010\",\n    arbiter=\"JG0100001100000010\"\n)\npipeline.set_site_role(\"guest\")\npipeline.set_site_party_id(\"JG0100001100000010\")\n\nintersection_0 = Intersection(\n    \"intersect_rsa_1\",\n    id=\"id\",\n    intersect_method=\"rsa\",\n    only_output_key=False,\n    rsa_params=dict(\n        final_hash_method=\"sha256\",\n        hash_method=\"sha256\",\n        key_length=2048\n    ),\n    sync_intersect_ids=True,\n    connect_engine=\"mesh\",\n    train_data=[\n        DataWarehouseChannel(dataset_id=\"testspace#test_guest\", parties=dict(guest=\"JG0100001100000010\")),\n        DataWarehouseChannel(dataset_id=\"testspace#test_host\", parties=dict(host=\"JG0100001100000010\"))\n    ]\n)\n\nhetero_lr_0 = HeteroLR(\n    \"hetero_logistic_regression_1\",\n    id=\"id\",\n    label=\"y\",\n    batch_size=-1,\n    penalty=\"L2\",\n    early_stop=\"diff\",\n    tol=0.0001,\n    max_iter=2,\n    alpha=0.01,\n    optimizer=\"nesterov_momentum_sgd\",\n    init_param={\"init_method\":\"zeros\"},\n    learning_rate=0.15,\n    connect_engine=\"mesh\",\n    train_data=intersection_0.outputs[\"train_data\"]\n)\n\npipeline.add_task(intersection_0)\npipeline.add_task(hetero_lr_0)\npipeline.conf.set(\n    \"extra\",\n    dict(initiator={'party_id': 'JG0100001100000010', 'role': 'guest'})\n)\n\npipeline.protocol_kind = \"bfia\"\npipeline.guest.conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.hosts[0].conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.compile()\npipeline.fit()\n</code></pre>"},{"location":"bfia_access/#13-other-bfia-protocol-algorithms","title":"1.3 Other BFIA Protocol Algorithms","text":""},{"location":"bfia_access/#131-pipeline-adaptation-development","title":"1.3.1 Pipeline Adaptation Development:","text":"<p>To integrate other algorithms, follow these steps: - Component Description File: Place the algorithm component description file in pipeline-component-define - Component Definition: Place the algorithm component definition file in pipeline-component</p>"},{"location":"bfia_access/#2-scheduling","title":"2. Scheduling","text":""},{"location":"bfia_access/#21-modifying-configurations","title":"2.1 Modifying Configurations","text":"<ul> <li>Modify Route-Table.</li> <li>Update local-site-settings</li> <li><code>LOCAL_SITE_ID</code>: ID of the local site.</li> <li><code>STORAGE_ADDRESS</code>: S3 storage address.</li> <li><code>TRANSPORT</code>: Communication engine address used by the local algorithm.</li> <li><code>CONTAINER_LOG_PATH</code>: Local path for container logs.</li> <li><code>CALLBACK_ADDRESS</code>: Address for scheduling service used by the algorithm for callbacks.</li> </ul>"},{"location":"bfia_access/#22-registering-algorithms","title":"2.2 Registering Algorithms","text":"<pre><code>{\n  \"name\": \"unionpay\",\n  \"device\": \"docker\",\n  \"version\": \"2.0.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"unionpay:2.0.0\"\n  },\n  \"protocol\": \"bfia\",\n  \"components_description\": {}\n}\n</code></pre> <p>Registration Configuration Explanation: - <code>name</code>: Name of the provider/vendor. - <code>device</code>: Mode of algorithm execution, currently supporting \"docker\". - <code>version</code>: Algorithm version. - <code>metadata</code>: Image information. - <code>protocol</code>: Protocol used by the algorithm. - <code>components_description</code>: Description of algorithm components, reference BFIA Algorithm Self-description</p>"},{"location":"bfia_access/#221-registering-fate-algorithms","title":"2.2.1 Registering FATE Algorithms","text":"<p><pre><code>flow provider register -c examples/bfia/fate/register/fate_components.json\n</code></pre> - Configuration reference: fate_components.json</p>"},{"location":"bfia_access/#222-registering-unionpay-algorithms","title":"2.2.2 Registering UnionPay Algorithms","text":"<p><pre><code>flow provider register -c examples/bfia/unionpay/register/unionpay_components.json\n</code></pre> - Configuration reference: unionpay_components.json</p>"},{"location":"bfia_access/#223-registering-other-algorithms","title":"2.2.3 Registering Other Algorithms","text":"<p>You can use the above configuration to register algorithm images from other vendors into the FATE Flow service. They will be automatically loaded and run as containers during execution.</p>"},{"location":"bfia_access/#3-usage","title":"3. Usage","text":"<ul> <li>Modify configurations as outlined in section 2.1.</li> <li>Register corresponding algorithms as described in section 2.2.</li> </ul>"},{"location":"bfia_access/#31-using-fate-algorithm-images","title":"3.1 Using FATE Algorithm Images","text":""},{"location":"bfia_access/#311-data-upload","title":"3.1.1 Data Upload","text":""},{"location":"bfia_access/#3111-upload","title":"3.1.1.1 Upload","text":"<ul> <li>Install FATE Flow and Flow Cli <pre><code>pip install fate_flow==2.0.0\npip install fate_client==2.0.0\n</code></pre></li> <li>Upload data to s3 storage <pre><code>import os\nimport tempfile\n\nfrom fate_flow.adapter.bfia.container.wraps.wraps import DataIo\nfrom fate_flow.components.components.upload import Upload, UploadParam\nfrom fate_flow.entity.spec.dag import Metadata\n\n\ndef upload_data(s3_address, namespace, name, file, meta, head=True, partitions=16, extend_sid=True, storage_engine=\"standalone\"):\n    upload_object = Upload()\n    params = {\n        'name': name,\n        'namespace': namespace,\n        'file': file,\n        'storage_engine': storage_engine,\n        'head': head,\n        'partitions': partitions,\n        'extend_sid': extend_sid,\n        'meta': meta\n    }\n    params = UploadParam(**params)\n\n    with tempfile.TemporaryDirectory() as data_home:\n        os.environ[\"STANDALONE_DATA_HOME\"] = data_home\n        data_meta = upload_object.run(params).get(\"data_meta\")\n\n        metadata = Metadata(metadata=dict(options=dict(partitions=partitions), schema=data_meta))\n        data_path = os.path.join(data_home, namespace, name)\n        engine = DataIo(s3_address)\n        engine.upload_to_s3(data_path, name=name, namespace=namespace, metadata=metadata.dict())\n\n\nif __name__ == \"__main__\":\n    s3_address = \"s3://127.0.0.1:9000?username=admin&amp;password=12345678\"\n    file = 'examples/data/breast_hetero_guest.csv'\n    namespace = \"upload\"\n    name = \"guest\"\n\n\n    meta = {\n        \"delimiter\": \",\",\n        \"label_name\": \"y\",\n        \"match_id_name\": \"id\"\n    }\n    upload_data(s3_address=s3_address, namespace=namespace, name=name, file=file, meta=meta)\n</code></pre> Modify the parameters <code>s3_address</code>, <code>file</code>, <code>namespace</code>, <code>name</code>, <code>meta</code> in the above code with actual values, where: <pre><code>s3_address: s3 storage address\nfile: local path of the data\nnamespace: FATE table namespace\nname: FATE table name\nmeta: Data metadata\n</code></pre></li> </ul>"},{"location":"bfia_access/#3112-dataframe-transformer","title":"3.1.1.2 dataframe-transformer","text":"<p>Explanation: The upload process stores data in the s3 storage. FATE algorithms depend on dataframe-format datasets. FATE provides the <code>dataframe-transformer</code> component for data conversion. In the BFIA protocol, the input parameter for data is <code>dataset_id</code>, which FATE adapts as <code>$namespace + '#' + $name</code> - Configuration: dataframe-transformer - Replace <code>JG0100001100000010</code> in the configuration with the actual site ID - Modify <code>dataset_id</code> to <code>$namespace + '#' + $name</code>, where namespace and name are the parameters set for upload. <pre><code>dag:\n  tasks:\n    transformer_0:\n      inputs:\n        data:\n          table:\n            data_warehouse:\n              dataset_id: upload#guest\n</code></pre> - The output data table is defined in dag.tasks.transformer_0.parameters and can be customized. <pre><code>dag:\n  tasks:\n    transformer_0:\n      parameters:\n        name: breast_hetero_guest\n        namespace: experiment\n</code></pre> - Submit the <code>dataframe-transformer</code> component: <code>flow job submit -c examples/bfia/fate/job/dataframe_transformer.yaml</code></p>"},{"location":"bfia_access/#312-running-fate-algorithm-components","title":"3.1.2 Running FATE Algorithm Components","text":"<p>Jobs can be submitted via CLI, pipelines, or the BFIA's restful-api</p> <ul> <li>Submitting jobs via CLI:</li> <li>Configuration: psi-lr, psi-sbt</li> <li>Command: <code>flow job submit -c examples/bfia/fate/job/psi_lr.yaml</code></li> <li>Submitting jobs via pipelines: psi-lr, psi-sbt</li> <li>Using the restful-api: psi-lr, psi-sbt</li> </ul>"},{"location":"bfia_access/#32-using-algorithm-images-from-other-vendors","title":"3.2 Using Algorithm Images from Other Vendors","text":""},{"location":"bfia_access/#321-data-upload","title":"3.2.1 Data Upload","text":"<p>Each vendor provides its own data upload interface.</p>"},{"location":"bfia_access/#322-running-algorithm-components-from-other-vendors-unionpay-example","title":"3.2.2 Running Algorithm Components from Other Vendors (UnionPay example)","text":"<p>Jobs can be submitted via CLI, pipelines, or the BFIA's restful-api</p> <ul> <li>Submitting jobs via CLI:</li> <li>Configuration: psi-lr, psi-sbt</li> <li>Command: <code>flow job submit -c examples/bfia/unionpay/job/psi_lr.yaml</code></li> <li>Submitting jobs via pipelines: psi-lr, psi-sbt</li> <li>restful-api: psi-lr\u3001psi-sbt</li> </ul>"},{"location":"data_access/","title":"FATE Data Access Guide","text":""},{"location":"data_access/#1-upload-process","title":"1. Upload Process","text":"<p>The process diagram for data upload is as follows:</p> <p> - The client uploads data to the server. - The server encapsulates the upload parameters into a DAG job configuration, including two components: 'upload' and 'dataframe-transformer,' then calls the submit interface to submit the job. - The 'upload' component stores data into the FATE storage service. - The 'transformer' component converts the data output from the 'upload' component into a dataframe and stores it into the FATE storage service. - Metadata about the data is stored in the database.</p>"},{"location":"data_access/#2-data-upload-methods","title":"2. Data Upload Methods","text":"<p>Note: FATE provides clients including SDK, CLI, and Pipeline. If you haven't deployed the FATE Client in your environment, you can use <code>pip install fate_client</code> to download it. The following operations are CLI-based.</p>"},{"location":"data_access/#21-upload-scenario-explanation","title":"2.1 Upload Scenario Explanation","text":"<ul> <li>Client-server separation: Installed client and server are on different machines.</li> <li>Client-server non-separation: Installed client and server are on the same machine. Difference: In scenarios where the client and server are not separated, the step \"the client uploads data to the server\" in the above process can be omitted to improve data upload efficiency in scenarios with large data volumes. There are differences in interfaces and parameters between the two scenarios, and you can choose the corresponding scenario for data upload.</li> </ul>"},{"location":"data_access/#22-data-upload","title":"2.2 Data Upload","text":""},{"location":"data_access/#221-configuration-and-data-preparation","title":"2.2.1 Configuration and Data Preparation","text":"<ul> <li>Upload configuration is located in examples-upload <pre><code>{\n  \"file\": \"examples/data/breast_hetero_guest.csv\",\n  \"head\": true,\n  \"partitions\": 16,\n  \"extend_sid\": true,\n  \"meta\": {\n    \"delimiter\": \",\",\n    \"label_name\": \"y\",\n    \"match_id_name\": \"id\"\n  },\n  \"namespace\": \"experiment\",\n  \"name\": \"breast_hetero_guest\"\n}\n</code></pre></li> <li>file: File path</li> <li>head: Whether the data contains a header: true/false</li> <li>partitions: Number of data storage partitions</li> <li>extend_sid: Whether to generate an 'sid' column</li> <li>meta: Metadata about the data</li> <li>namespace &amp;&amp; name: Reference to data in the FATE storage table</li> <li>Uploaded data is located in upload-data</li> <li>You can also use your own data and modify the \"meta\" information in the upload configuration.</li> </ul>"},{"location":"data_access/#222-data-upload-commands","title":"2.2.2 Data Upload Commands","text":""},{"location":"data_access/#client-server-non-separation","title":"Client-Server Non-Separation","text":"<p><pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre> Note: Ensure that the file path in the configuration exists on the server.</p>"},{"location":"data_access/#client-server-separation","title":"Client-Server Separation","text":"<pre><code>flow data upload-file -c examples/upload/upload_guest.json\n</code></pre>"},{"location":"data_access/#223-upload-results","title":"2.2.3 Upload Results","text":"<pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\"\n    },\n    \"job_id\": \"202312281606030428210\",\n    \"message\": \"success\"\n}\n</code></pre>"},{"location":"data_access/#224-data-query","title":"2.2.4 Data Query","text":"<p>Since the entire upload is an asynchronous operation, it's necessary to confirm successful upload before performing subsequent operations. <pre><code>flow table query --namespace experiment --name breast_hetero_guest\n</code></pre> - Successful data upload returns: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"count\": 569,\n        \"data_type\": \"dataframe\",\n        \"engine\": \"standalone\",\n        \"meta\": {},\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\",\n        \"path\": \"xxx\",\n        \"source\": {\n            \"component\": \"dataframe_transformer\",\n            \"output_artifact_key\": \"dataframe_output\",\n            \"output_index\": null,\n            \"party_task_id\": \"202312281606030428210_transformer_0_0_local_0\",\n            \"task_id\": \"202312281606030428210_transformer_0\",\n            \"task_name\": \"transformer_0\"\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"data_access/#3-data-binding","title":"3. Data Binding","text":"<p>For specific algorithms that may require particular datasets, FATE Flow provides a data binding interface to make the data available for use in FATE.</p> <pre><code>flow table bind --namespace bind_data --name breast_hetero_guest --path /data/projects/fate/fate_flow/data/xxx\n</code></pre>"},{"location":"data_access/#4-data-query","title":"4. Data Query","text":"<p>For uploaded or bound data tables, you can use the query interface to retrieve brief information about the data.</p> <pre><code>flow table query --namespace experiment --name breast_hetero_guest\n</code></pre>"},{"location":"data_access/#5-data-cleaning","title":"5. Data Cleaning","text":"<p>You can use delete cli to clean data tables that already exist in FATE.</p> <pre><code>flow table delete --namespace experiment --name breast_hetero_guest\n</code></pre>"},{"location":"fate_access/","title":"FATE 2.0 Version Interconnection Guide","text":""},{"location":"fate_access/#1-fate-flow-integration-guide","title":"1. FATE Flow Integration Guide","text":"<ul> <li>Description: This section provides guidance on integrating heterogeneous scheduling platforms with the FATE scheduling platform's FATE Flow.</li> <li>Scenario: This side is the system to be integrated, and the partner is the FATE site.</li> </ul>"},{"location":"fate_access/#11-interfaces","title":"1.1 Interfaces","text":"<p> FATE Flow interfaces are divided into 4 categories: - 1.responsible for receiving requests from upper-level systems, such as submitting, stopping, and querying jobs; - 2.responsible for receiving requests from the scheduling layer, such as starting and stopping tasks; - 3.responsible for receiving requests from algorithm containers, such as task status, input reporting, etc.; - 4.responsible for receiving requests from the platform layer and distributing them to the interfaces of the participating parties.</p>"},{"location":"fate_access/#111-api-1","title":"1.1.1 api-1","text":"<p>Description: Since it is about integrating with the upper-level system and does not involve interaction between schedulers, this interface is optional and can be customized without constraints.</p>"},{"location":"fate_access/#112-api-2","title":"1.1.2 api-2","text":"<p>Refer to interface implementation - <code>/v2/partner/job/create</code>: Create a job - <code>/v2/partner/job/start</code>: Start a job - <code>/v2/partner/job/status/update</code>: Update job status - <code>/v2/partner/job/update</code>: Update job (e.g., progress information) - <code>/v2/partner/job/resource/apply</code>: Apply for job resources - <code>/v2/partner/job/resource/return</code>: Return job resources - <code>/v2/partner/job/stop</code>: Stop job - <code>/v2/partner/task/resource/apply</code>: Apply for task resources - <code>/v2/partner/task/resource/return</code>: Return task resources - <code>/v2/partner/task/start</code>: Start task - <code>/v2/partner/task/collect</code>: Scheduler collects task status - <code>/v2/partner/task/status/update</code>: Update task status - <code>/v2/partner/task/stop</code>: Stop task - <code>/v2/partner/task/rerun</code>: Rerun task</p>"},{"location":"fate_access/#113-api-3","title":"1.1.3 api-3","text":"<p>Refer to interface implementation - <code>/v2/worker/task/status</code>: Status report - <code>/v2/worker/model/save</code>: Save model - <code>/v2/worker/model/download</code>: Download model - <code>/v2/worker/data/tracking/query</code>: Query data - <code>/v2/worker/data/tracking/save</code>: Record data - <code>/v2/worker/metric/save/&lt;execution_id&gt;</code>: Record metrics</p>"},{"location":"fate_access/#114-api-4","title":"1.1.4 api-4","text":"<p>Refer to interface implementation - <code>/v2/scheduler/job/create</code>: Create a job - <code>/v2/scheduler/job/stop</code>: Stop a job - <code>/v2/scheduler/task/report</code>: Task report (e.g., status) - <code>/v2/scheduler/job/rerun</code>: Rerun a job</p>"},{"location":"fate_access/#12-scheduler","title":"1.2 Scheduler","text":"<p>The scheduler mainly consists of two parts: scheduling logic and scheduling interface. In the case of interconnection in a heterogeneous scenario, a unified scheduling process and interface are indispensable. In the case mentioned above, when using FATE Flow as the scheduling party in connection with other vendors, the implementation of the scheduler can be ignored.</p>"},{"location":"fate_access/#121-approach","title":"1.2.1 Approach","text":"<p>The core of scheduling is the scheduling process, which defines the lifecycle of a job. In version 1.x of FATE, the scheduler and the initiator logic are bound, meaning the coordination scheduling of jobs from multiple parties is done at the initiator. This has a disadvantage: suppose companies A, B, and C each have the need to initiate tasks, their scheduling layers need to implement the scheduler based on the same scheduling logic, and the cost of interconnection is high. In version 2.0, the initiator and scheduler logic in the scheduling module are decoupled, and the scheduler can be specified in the job configuration. In the above case, as long as any one of A, B, or C companies implements the scheduler, or directly uses FATE as the scheduler, other vendors only need to implement the scheduler client interface to meet the requirements, greatly reducing the cost of interconnection.</p> <p></p> <p>P represents the scheduling client interface, S represents the scheduler interface</p> <p>To illustrate this scheduling mode with an example: Suppose A wants to create a job with C, and FATE Flow is the scheduler. First, A requests the FATE-Flow S (create-job) interface. After receiving the request, FATE Flow obtains participant information (A, C) through job configuration, and then distributes it to the P (create-job) interface of each participant.</p>"},{"location":"fate_access/#122-scheduling-logic","title":"1.2.2 Scheduling Logic","text":"<p>It manages the lifecycle of jobs, including when to start and stop jobs, when to start and stop tasks, DAG parsing, and component runtime dependencies, etc. FATE Flow's scheduling process is divided into two modes based on task status acquisition: callback and poll. Among them, the callback mode is for the participants to actively report task status to the scheduler, and the poll mode is for the scheduler to pull task status from the participants at regular intervals. The scheduling process diagrams for the two modes are as follows:</p> <p></p> <p>Callback Mode</p> <p></p> <p>Poll Mode</p>"},{"location":"fate_access/#123-scheduling-interface","title":"1.2.3 Scheduling Interface","text":"<p>Responsible for receiving requests from the platform layer and distributing them to the interfaces of various participants api-2, such as creating jobs, stopping jobs, etc. Interfaces see api-4</p>"},{"location":"fate_access/#2-algorithm-integration-guide","title":"2 Algorithm Integration Guide","text":"<p>In previous versions of FATE, algorithms ran as local processes started by the scheduling service, and there were shortcomings in terms of scalability, making it difficult to meet the needs of interconnection. In version 2.0, the \"algorithm container\" is used to run algorithms, implementing heterogeneous algorithm scheduling functionality through a standardized algorithm image construction and loading mechanism.</p> <p></p>"},{"location":"fate_access/#21-fate-algorithm-containerization-solution","title":"2.1 FATE Algorithm Containerization Solution","text":"<ul> <li>Pre-processing: Input processing for data, models, algorithm parameters, etc., will call the platform-layer interface api-3 to obtain relevant dependencies.</li> <li>Component runtime: Algorithm component logic.</li> <li>Post-processing: Output content processing for algorithm components, will call the platform-layer interface api-3 to upload the output to the platform. </li> </ul>"},{"location":"fate_access/#22-integration","title":"2.2 Integration","text":""},{"location":"fate_access/#221-algorithm-parameters","title":"2.2.1 Algorithm Parameters","text":"<p>FATE Flow will pass parameters to the algorithm container in the form of environment variables, with the key being \"CONFIG\" and the parameter value being a JSON string. The content is as follows: <pre><code>component: psi\ncomputing_partitions: 8\nconf:\n  computing:\n    metadata:\n      computing_id: 202402271112016150790_psi_0_0_host_9998\n      host\uff1a127.0.0.1\n      port:4670\n    type: standalone/eggroll/spark\n  device:\n    metadata: {}\n    type: CPU\n  federation:\n    metadata:\n      federation_id: 202402271112016150790_psi_0_0\n      parties:\n        local:\n          partyid: '9998'\n          role: host\n        parties:\n        - partyid: '9999'\n          role: guest\n        - partyid: '9998'\n          role: host\n      osx_config:\n        host: 127.0.01\n        port: 9370\n    type: osx\n  logger:\n    config:\n  storage: standalone/eggroll/hdfs\nengine_run:\n  cores: 4\ninput_artifacts:\n  data:\n    input_data:\n      output_artifact_key: output_data\n      output_artifact_type_alias: null\n      parties:\n      - party_id:\n        - '9998'\n        role: host\n      producer_task: reader_0\n  model: null\njob_id: '202402271112016150790'\nlauncher_conf: {}\nlauncher_name: default\nmlmd:\n  metadata:\n    api_version: v2\n    host: 127.0.0.1\n    port: 9380\n    protocol: http\n  type: flow\nmodel_id: '202402271112016150790'\nmodel_version: '0'\nparameters: {}\nparty_id: '9998'\nparty_task_id: 202402271112016150790_psi_0_0_host_9998\nprovider_name: fate\nrole: host\nstage: default\ntask_id: 202402271112016150790_psi_0\ntask_name: psi_0\ntask_version: '0'\n</code></pre> Here are the key configurations: - <code>component</code>: The name of the algorithm. When multiple algorithms are packaged in the same image, this parameter is used to identify them. - <code>conf.computing</code>: Configuration for the computing engine. - <code>conf.federation</code>: Configuration for the communication engine. - <code>conf.storage</code>: Configuration for the storage engine, supporting standalone/eggroll and hdfs. - <code>mlmd</code>: Platform-layer interface used for recording the output of the algorithm. The interface is api-3. - <code>input_artifacts</code>: Input dependencies, including data, models, etc. - <code>parameters</code>: Algorithm parameters. The entry point for starting the algorithm needs to be specified with CMD when building the image, and the algorithm should call the status reporting interface in api-3 upon completion.</p>"},{"location":"fate_access/#222-registering-algorithm-image","title":"2.2.2 Registering Algorithm Image","text":"<p><pre><code>flow provider register -c examples/provider/register_image.json\n</code></pre> Where <code>register_image.json</code> looks like this: <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"docker\",\n  \"version\": \"2.1.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"federatedai/fate:2.1.0\"\n  }\n}\n</code></pre></p>"},{"location":"fate_access/#223-using-algorithm-image","title":"2.2.3 Using Algorithm Image","text":"<p>After registration, in the DAG of the job configuration, you can specify the provider to run this FATE algorithm image, as shown below: <pre><code>dag:\n  conf:\n    task:\n      provider: fate:2.1.0@docker\n</code></pre> Alternatively, you can specify this image for a specific algorithm. For details, refer to the provider guide.</p>"},{"location":"fate_flow/","title":"Overall Design","text":""},{"location":"fate_flow/#1-design-architecture-diagram","title":"1. Design Architecture Diagram","text":"<p> - Application Layer Interface: Used by higher-level components like fate-board, fate-client, etc. - Interconnect Layer Interface: Divided into Scheduler Interface and Participant Interface. Scheduler Interface receives scheduling commands like create, stop, etc., and sends them to participants. Participant Interface is used by each participant to receive commands like create, run, stop, etc., and execute them. - Base Interface: Receives status reports from algorithm containers, etc. - Scheduler: Federated scheduling logic, interprets DSL dependencies, and runs related jobs and tasks. - Algorithm Container: Environment for algorithm execution. FATE Flow supports running algorithms in local processes or in algorithm containers, with similar execution modes. - Platform Resource Pool: Abstract computation, communication, storage APIs.</p>"},{"location":"fate_flow/#2-overall-architecture","title":"2. Overall Architecture","text":""},{"location":"fate_flow/#21-fate-overall-architecture","title":"2.1 FATE Overall Architecture","text":""},{"location":"fate_flow/#22-fate-flow-functional-architecture","title":"2.2 FATE Flow Functional Architecture","text":""},{"location":"fate_flow/#23-fate-flow-cluster-architecture","title":"2.3 FATE Flow Cluster Architecture","text":""},{"location":"fate_flow/#3-scheduling-architecture","title":"3. Scheduling Architecture","text":""},{"location":"fate_flow/#31-state-based-scheduling-architecture","title":"3.1 State-Based Scheduling Architecture","text":"<ul> <li>Separation of states (resources, jobs) and managers (scheduler, resource manager)</li> <li>Persistent storage of resource and job states in MySQL, globally shared, providing reliable transactional operations</li> <li>Improved high availability and scalability of management services</li> <li>Intervention in jobs, supporting actions like restarts, reruns, parallel control, resource isolation, etc.</li> </ul>"},{"location":"fate_flow/#32-state-driven-scheduling","title":"3.2 State-Driven Scheduling","text":"<ul> <li>North-south state reporting/querying</li> <li>East-west multi-party task state computation for federated task states</li> <li>Upstream and downstream task state computation for job states</li> </ul>"},{"location":"fate_flow/#321-callback-mode","title":"3.2.1 Callback Mode","text":"<p>Scheduler creates jobs and tasks, and each participant actively callbacks the state of jobs or tasks.</p> <p></p>"},{"location":"fate_flow/#322-polling-mode","title":"3.2.2 Polling Mode","text":"<p>Scheduler not only creates jobs and tasks but also polls the state of jobs or tasks from the participants during the scheduling process.</p> <p></p>"},{"location":"fate_flow/#34-algorithm-component-scheduling","title":"3.4 Algorithm Component Scheduling","text":"<ul> <li>Pre-processing: Handling inputs such as data, models, algorithm parameters</li> <li>Component execution: Logic of algorithm components</li> <li>Post-processing: Handling outputs of algorithm components</li> </ul>"},{"location":"fate_flow/#4-multi-party-resource-coordination","title":"4. Multi-Party Resource Coordination","text":"<ul> <li>Total resource size for each engine is configured via a configuration file, subsequent system integration to be implemented</li> <li>The cores within the total resource size represent the number of CPU cores per computing node</li> <li>FATEFlow server reads resource size configuration from the configuration file upon startup and registers updates to the database</li> <li>Resources are allocated at the Job level, becoming effective upon Job Conf submission</li> </ul>"},{"location":"fate_flow/#5-real-time-job-monitoring","title":"5. Real-time Job Monitoring","text":"<ul> <li>Work process liveness detection</li> <li>Job timeout detection</li> <li>Resource recovery detection</li> <li>Basic engine session timeout detection</li> </ul>"},{"location":"fate_flow/#6-task-component-center","title":"6. Task Component Center","text":""},{"location":"fate_flow/#7-data-access","title":"7. Data Access","text":""},{"location":"job_scheduling/","title":"Multi-Party Joint Operation","text":""},{"location":"job_scheduling/#1-introduction","title":"1. Introduction","text":"<p>This primarily introduces how to define federated learning jobs using <code>FATE Flow</code>.</p>"},{"location":"job_scheduling/#2-dag-definition","title":"2. DAG Definition","text":"<p>FATE 2.0 uses a brand new DAG to define a job, including the upstream and downstream dependencies of each component.</p>"},{"location":"job_scheduling/#3-job-functional-configuration","title":"3. Job Functional Configuration","text":""},{"location":"job_scheduling/#31-prediction","title":"3.1 Prediction","text":"<p><pre><code>dag:\n  conf:\n    model_warehouse:                        \n      model_id: '202307171452088269870'      \n      model_version: '0'                    \n</code></pre> In <code>dag.conf.model_warehouse</code>, define the model information that the prediction task relies on. This model will be used for prediction in the algorithm.</p>"},{"location":"job_scheduling/#32-job-inheritance","title":"3.2 Job Inheritance","text":"<p><pre><code>dag:\n  conf:\n    inheritance:                  \n      job_id: \"202307041704214920920\"  \n      task_list: [\"reader_0\"]         \n</code></pre> In <code>job.conf.inheritance</code>, fill in the job and algorithm component names that need to be inherited. The newly started job will directly reuse the outputs of these components.</p>"},{"location":"job_scheduling/#33-specifying-the-scheduler-party","title":"3.3 Specifying the Scheduler Party","text":"<p><pre><code>dag:\n  conf:\n    scheduler_party_id: \"9999\"   \n</code></pre> In <code>job.conf.scheduler_party_id</code>, you can specify scheduler party information. If not specified, the initiator acts as the scheduler.</p>"},{"location":"job_scheduling/#34-specifying-job-priority","title":"3.4 Specifying Job Priority","text":"<p><pre><code>dag:\n  conf:\n    priority: 2\n</code></pre> In <code>job.conf.priority</code>, specify the scheduling weight of the task. The higher the value, the higher the priority.</p>"},{"location":"job_scheduling/#35-automatic-retry-on-failure","title":"3.5 Automatic Retry on Failure","text":"<p><pre><code>dag:\n  conf:\n    auto_retries: 2\n</code></pre> In <code>job.conf.auto_retries</code>, specify the number of retries if a task fails. Default is 0.</p>"},{"location":"job_scheduling/#36-resource-allocation","title":"3.6 Resource Allocation","text":"<p><pre><code>dag:\n  conf:\n    cores: 4\n  task:\n    engine_run:\n      cores: 2\n</code></pre> - Here, <code>dag.conf.cores</code> represents the allocated resources for the entire job (<code>job_cores</code>), and <code>dag.conf.engine_run.cores</code> represents the allocated resources for the task (<code>task_cores</code>). If a job is started with this configuration, its maximum parallelism will be 2. - Task parallelism = job_cores / task_cores</p>"},{"location":"job_scheduling/#37-task-timeout","title":"3.7 Task Timeout","text":"<p><pre><code>dag:\n  task:\n    timeout: 3600 # s\n</code></pre> In <code>dag.task.timeout</code>, specify the task's timeout. When a task is in the 'running' state after reaching the timeout, it triggers an automatic job kill operation.</p>"},{"location":"job_scheduling/#38-task-provider","title":"3.8 Task Provider","text":"<p><pre><code>dag:\n  task:\n    provider: fate:2.0.1@local\n</code></pre> In <code>dag.task.provider</code>, specify the algorithm provider, version number, and execution mode for the task.</p>"},{"location":"job_scheduling/#4-input","title":"4. Input","text":"<p>Description: Upstream input, divided into two input types: data and models.</p>"},{"location":"job_scheduling/#41-data-input","title":"4.1 Data Input","text":"<ul> <li> <p>As parameter input to a component <pre><code>dag:\n  party_tasks:\n    guest_9999:\n      tasks:\n        reader_0:\n          parameters:\n            name: breast_hetero_guest\n            namespace: experiment\n    host_9998:\n      tasks:\n        reader_0:\n          parameters:\n            name: breast_hetero_host\n            namespace: experiment\n</code></pre> The <code>reader</code> component supports directly passing a FATE data table as job-level data input.</p> </li> <li> <p>Input of one component from another component's output <pre><code>dag:\n  tasks:\n    binning_0:\n      component_ref: hetero_feature_binning\n      inputs:\n        data:\n          train_data:\n            task_output_artifact:\n              output_artifact_key: train_output_data\n              producer_task: scale_0\n</code></pre> <code>binning_0</code> depends on the output data of <code>scale_0</code>.</p> </li> </ul>"},{"location":"job_scheduling/#42-model-input","title":"4.2 Model Input","text":"<ul> <li>Model Warehouse <pre><code>dag:\n  conf:\n    model_warehouse:                        \n      model_id: '202307171452088269870'      \n      model_version: '0'  \n  tasks:\n    selection_0:\n      component_ref: hetero_feature_selection\n      dependent_tasks:\n      - scale_0\n        model:\n          input_model:\n            model_warehouse:\n              output_artifact_key: train_output_model\n              producer_task: selection_0\n</code></pre></li> </ul>"},{"location":"job_scheduling/#5-output","title":"5. Output","text":"<p>The job's output includes data, models, and metrics.</p>"},{"location":"job_scheduling/#51-metric-output","title":"5.1 Metric Output","text":""},{"location":"job_scheduling/#querying-metrics","title":"Querying Metrics","text":"<p>Querying output metrics command: <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code> - Input content as follows: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"job_scheduling/#52-model-output","title":"5.2 Model Output","text":""},{"location":"job_scheduling/#querying-models","title":"Querying Models","text":"<p><pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code> - Query result as follows: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"output_model\": {\n            \"data\": {\n                \"estimator\": {\n                    \"end_epoch\": 10,\n                    \"is_converged\": false,\n                    \"lr_scheduler\": {\n                        \"lr_params\": {\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100\n                        },\n                        \"lr_scheduler\": {\n                            \"_get_lr_called_within_step\": false,\n                            \"_last_lr\": [\n                                0.07269999999999996\n                            ],\n                            \"_step_count\": 10,\n                            \"base_lrs\": [\n                                0.1\n                            ],\n                            \"end_factor\": 1.0,\n                            \"last_epoch\": 9,\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100,\n                            \"verbose\": false\n                        },\n                        \"method\": \"linear\"\n                    },\n                    \"optimizer\": {\n                        \"alpha\": 0.001,\n                        \"l1_penalty\": false,\n                        \"l2_penalty\": true,\n                        \"method\": \"sgd\",\n                        \"model_parameter\": [\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ]\n                        ],\n                        \"model_parameter_dtype\": \"float32\",\n                        \"optim_param\": {\n                            \"lr\": 0.1\n                        },\n                        \"optimizer\": {\n                            \"param_groups\": [\n                                {\n                                    \"dampening\": 0,\n                                    \"differentiable\": false,\n                                    \"foreach\": null,\n                                    \"initial_lr\": 0.1,\n                                    \"lr\": 0.07269999999999996,\n                                    \"maximize\": false,\n                                    \"momentum\": 0,\n                                    \"nesterov\": false,\n                                    \"params\": [\n                                        0\n                                    ],\n                                    \"weight_decay\": 0\n                                }\n                            ],\n                            \"state\": {}\n                        }\n                    },\n                    \"param\": {\n                        \"coef_\": [\n                            [\n                                -0.10828543454408646\n                            ],\n                            [\n                                -0.07341302931308746\n                            ],\n                            [\n                                -0.10850320011377335\n                            ],\n                            [\n                                -0.10066638141870499\n                            ],\n                            [\n                                -0.04595951363444328\n                            ],\n                            [\n                                -0.07001449167728424\n                            ],\n                            [\n                                -0.08949052542448044\n                            ],\n                            [\n                                -0.10958756506443024\n                            ],\n                            [\n                                -0.04012322425842285\n                            ],\n                            [\n                                0.02270071767270565\n                            ],\n                            [\n                                -0.07198350876569748\n                            ],\n                            [\n                                0.00548586156219244\n                            ],\n                            [\n                                -0.06599288433790207\n                            ],\n                            [\n                                -0.06410090625286102\n                            ],\n                            [\n                                0.016374297440052032\n                            ],\n                            [\n                                -0.01607361063361168\n                            ],\n                            [\n                                -0.011447405442595482\n                            ],\n                            [\n                                -0.04352564364671707\n                            ],\n                            [\n                                0.013161249458789825\n                            ],\n                            [\n                                0.013506329618394375\n                            ]\n                        ],\n                        \"dtype\": \"float32\",\n                        \"intercept_\": null\n                    }\n                }\n            },\n            \"meta\": {\n                \"batch_size\": null,\n                \"epochs\": 10,\n                \"init_param\": {\n                    \"fill_val\": 0.0,\n                    \"fit_intercept\": false,\n                    \"method\": \"zeros\",\n                    \"random_state\": null\n                },\n                \"label_count\": false,\n                \"learning_rate_param\": {\n                    \"method\": \"linear\",\n                    \"scheduler_params\": {\n                        \"start_factor\": 0.7,\n                        \"total_iters\": 100\n                    }\n                },\n                \"optimizer_param\": {\n                    \"alpha\": 0.001,\n                    \"method\": \"sgd\",\n                    \"optimizer_params\": {\n                        \"lr\": 0.1\n                    },\n                    \"penalty\": \"l2\"\n                },\n                \"ovr\": false\n            }\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"job_scheduling/#downloading-models","title":"Downloading Models","text":"<p><pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> - <code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code> - Download result: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"Download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre></p>"},{"location":"job_scheduling/#53-output-data","title":"5.3 Output Data","text":""},{"location":"job_scheduling/#querying-data-tables","title":"Querying Data Tables","text":"<p><pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> - Query result: <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"job_scheduling/#previewing-data","title":"Previewing Data","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code></p>"},{"location":"job_scheduling/#downloading-data","title":"Downloading Data","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> - <code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code> - Result: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"Download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"provider_register/","title":"Component Registry","text":""},{"location":"provider_register/#1-introduction","title":"1. Introduction","text":"<p>FATE Flow has designed an algorithm component registry module to support multiple algorithm vendors, versions, and various execution modes.</p>"},{"location":"provider_register/#2-provider","title":"2. Provider","text":"<p>Definition: <code>$name:$version@device</code>, such as <code>fate:2.0.0@local</code> - name: Algorithm provider vendor - version: Algorithm version - device: Algorithm execution mode, e.g., docker, k8s, local, etc.</p>"},{"location":"provider_register/#21-registration","title":"2.1 Registration","text":"<ul> <li>Registration command:</li> </ul> <pre><code>flow provider register -c examples/provider/register.json\n</code></pre> <ul> <li> <p>Registering a local algorithm package requires providing the algorithm package path (<code>path</code>) and optionally the Python environment path (if not provided, the system environment will be used). <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"local\",\n  \"version\": \"2.0.1\",\n  \"metadata\": {\n    \"path\": \"/Users/tonly/FATE/python\",\n    \"venv\": \"/Users/tonly/opt/anaconda3/envs/fate3.8/bin/python\"\n  }\n}\n</code></pre></p> </li> <li> <p>Registering a docker-based algorithm image: <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"docker\",\n  \"version\": \"2.0.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"federatedai/fate:2.0.0\"\n  },\n  \"protocol\": \"bfia\",\n  \"components_description\": {}\n}\n</code></pre></p> </li> </ul>"},{"location":"provider_register/#22-querying","title":"2.2 Querying","text":"<ul> <li> <p>Command: <pre><code>flow provider register --name fate --version 2.0.1 --device local\n</code></pre></p> </li> <li> <p>Output: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"create_time\": 1703762542058,\n            \"device\": \"local\",\n            \"metadata\": {\n                \"path\": \"/Users/tonly/FATE/python\",\n                \"venv\": \"/Users/tonly/opt/anaconda3/envs/fate3.8/bin/python\"\n            },\n            \"name\": \"fate\",\n            \"provider_name\": \"fate:2.0.1@local\",\n            \"update_time\": 1703762542058,\n            \"version\": \"2.0.1\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p> </li> </ul>"},{"location":"provider_register/#23-deletion","title":"2.3 Deletion","text":"<p>Used for deleting a registered algorithm. - Command: <pre><code>flow provider delete --name fate --version 2.0.1 --device local\n</code></pre></p> <ul> <li>Output: <pre><code>{\n    \"code\": 0,\n    \"data\": true,\n    \"message\": \"success\"\n}\n</code></pre></li> </ul>"},{"location":"provider_register/#3-component-registry-and-discovery-mechanism","title":"3. Component Registry and Discovery Mechanism","text":"<ul> <li>Registering algorithms</li> <li>Task configuration carrying the provider parameter, see the configuration methods below</li> </ul>"},{"location":"provider_register/#4-configuration-methods","title":"4. Configuration Methods","text":""},{"location":"provider_register/#41-global-job-configuration","title":"4.1 Global Job Configuration","text":"<p><pre><code>dag:\n  conf:\n    task:\n      provider: fate:2.0.1@local\n</code></pre> All tasks under the job inherit this provider.</p>"},{"location":"provider_register/#42-global-party-task-configuration","title":"4.2 Global Party Task Configuration","text":"<p><pre><code>dag:\n  party_tasks:\n    guest_9999:\n      parties:\n      - party_id:\n        - '9999'\n        role: guest\n      conf:\n        provider: fate:2.0.1@local\n</code></pre> All tasks under guest 9999 inherit this provider.</p>"},{"location":"provider_register/#43-global-task-configuration","title":"4.3 Global Task Configuration","text":"<p><pre><code>dag:\n  tasks:\n    reader_0:\n      conf:\n        provider: fate:2.0.1@local\n      component_ref: reader\n</code></pre> All reader components across all parties inherit this provider.</p>"},{"location":"provider_register/#44-specified-task-configuration","title":"4.4 Specified Task Configuration","text":"<p><pre><code>dag:\n  party_tasks:\n    guest_9999:\n      parties:\n      - party_id:\n        - '9999'\n        role: guest\n      tasks:\n        reader_0:\n          conf:\n            provider: fate:2.0.1@local\n</code></pre> The reader component under guest 9999 specifically inherits this provider.</p>"},{"location":"quick_start/","title":"Quick Start","text":""},{"location":"quick_start/#1-environment-setup","title":"1. Environment Setup","text":"<p>You can choose from the following three deployment modes based on your requirements:</p>"},{"location":"quick_start/#11-pypi-package-installation","title":"1.1 Pypi Package Installation","text":"<p>Explanation: This mode operates in a single-machine environment.</p>"},{"location":"quick_start/#111-installation","title":"1.1.1 Installation","text":"<ul> <li>Prepare and install conda environment.</li> <li>Create a virtual environment: <pre><code># FATE requires python&gt;=3.8\nconda create -n fate_env python=3.8\nconda activate fate_env\n</code></pre></li> <li>Install FATE Flow and related dependencies: <pre><code>pip install fate_client[fate,fate_flow]==2.0.0\n</code></pre></li> </ul>"},{"location":"quick_start/#112-service-initialization","title":"1.1.2 Service Initialization","text":"<p><pre><code>fate_flow init --ip 127.0.0.1 --port 9380 --home $HOME_DIR\n</code></pre> - ip: Service running IP - port: HTTP port for the service - home: Data storage directory, including data/models/logs/job configurations/sqlite.db, etc.</p>"},{"location":"quick_start/#113-service-startstop","title":"1.1.3 Service Start/Stop","text":"<pre><code>fate_flow status/start/stop/restart\n</code></pre>"},{"location":"quick_start/#12-standalone-deployment","title":"1.2 Standalone Deployment","text":"<p>Refer to Standalone Deployment</p>"},{"location":"quick_start/#13-cluster-deployment","title":"1.3 Cluster Deployment","text":"<p>Refer to Allinone Deployment</p>"},{"location":"quick_start/#2-user-guide","title":"2. User Guide","text":"<p>FATE provides a client package including SDK, CLI, and Pipeline. If FATE Client isn't deployed in your environment, you can download it using <code>pip install fate_client</code>. The following operations are CLI-based.</p>"},{"location":"quick_start/#21-data-upload","title":"2.1 Data Upload","text":"<p>For detailed data operation guides, refer to Data Access Guide</p>"},{"location":"quick_start/#211-configuration-and-data","title":"2.1.1 Configuration and Data","text":"<ul> <li>Upload Configuration: examples-upload</li> <li>Upload Data: upload-data</li> </ul>"},{"location":"quick_start/#212-upload-guest-data","title":"2.1.2 Upload Guest Data","text":"<pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre>"},{"location":"quick_start/#213-upload-host-data","title":"2.1.3 Upload Host Data","text":"<pre><code>flow data upload -c examples/upload/upload_host.json\n</code></pre>"},{"location":"quick_start/#22-starting-a-fate-job","title":"2.2 Starting a FATE Job","text":""},{"location":"quick_start/#221-submitting-a-job","title":"2.2.1 Submitting a Job","text":"<p>Once your data is prepared, you can submit a job to FATE Flow: - Job configuration examples are in lr-train. - Site IDs in the job configuration are \"9998\" and \"9999\". Replace them with real site IDs for cluster deployments; default configuration can be used for standalone deployments. - If you want to use your data, modify the parameters in the reader within the configuration. - Command to submit a job: <pre><code>flow job submit -c examples/lr/train_lr.yaml \n</code></pre> - Successful submission returns: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"model_id\": \"202308211911505128750\",\n        \"model_version\": \"0\"\n    },\n    \"job_id\": \"202308211911505128750\",\n    \"message\": \"success\"\n}\n</code></pre> The \"data\" here contains the output of the job, i.e., the model.</p>"},{"location":"quick_start/#222-querying-a-job","title":"2.2.2 Querying a Job","text":"<p>During job execution, you can query the job status using the query command: <pre><code>flow job query -j $job_id\n</code></pre></p>"},{"location":"quick_start/#223-stopping-a-job","title":"2.2.3 Stopping a Job","text":"<p>While the job is running, you can stop it using the stop job command: <pre><code>flow job stop -j $job_id\n</code></pre></p>"},{"location":"quick_start/#224-rerunning-a-job","title":"2.2.4 Rerunning a Job","text":"<p>If a job fails during execution, you can rerun it using the rerun command: <pre><code>flow job rerun -j $job_id\n</code></pre></p>"},{"location":"quick_start/#23-fetching-job-output","title":"2.3 Fetching Job Output","text":"<p>Job output includes data, models, and metrics.</p>"},{"location":"quick_start/#231-output-metrics","title":"2.3.1 Output Metrics","text":"<p>Querying output metrics command: <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, with the previously submitted training DAG task, you can use <code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code> to query. The result looks like this: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"quick_start/#232-output-models","title":"2.3.2 Output Models","text":""},{"location":"quick_start/#2321-querying-models","title":"2.3.2.1 Querying Models","text":"<p><pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For instance, with the previously submitted training DAG task, you can use <code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code> to query. The query result looks like this: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"output_model\": {\n            \"data\": {\n                \"estimator\": {\n                    \"end_epoch\": 10,\n                    \"is_converged\": false,\n                    \"lr_scheduler\": {\n                        \"lr_params\": {\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100\n                        },\n                        \"lr_scheduler\": {\n                            \"_get_lr_called_within_step\": false,\n                            \"_last_lr\": [\n                                0.07269999999999996\n                            ],\n                            \"_step_count\": 10,\n                            \"base_lrs\": [\n                                0.1\n                            ],\n                            \"end_factor\": 1.0,\n                            \"last_epoch\": 9,\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100,\n                            \"verbose\": false\n                        },\n                        \"method\": \"linear\"\n                    },\n                    \"optimizer\": {\n                        \"alpha\": 0.001,\n                        \"l1_penalty\": false,\n                        \"l2_penalty\": true,\n                        \"method\": \"sgd\",\n                        \"model_parameter\": [\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ]\n                        ],\n                        \"model_parameter_dtype\": \"float32\",\n                        \"optim_param\": {\n                            \"lr\": 0.1\n                        },\n                        \"optimizer\": {\n                            \"param_groups\": [\n                                {\n                                    \"dampening\": 0,\n                                    \"differentiable\": false,\n                                    \"foreach\": null,\n                                    \"initial_lr\": 0.1,\n                                    \"lr\": 0.07269999999999996,\n                                    \"maximize\": false,\n                                    \"momentum\": 0,\n                                    \"nesterov\": false,\n                                    \"params\": [\n                                        0\n                                    ],\n                                    \"weight_decay\": 0\n                                }\n                            ],\n                            \"state\": {}\n                        }\n                    },\n                    \"param\": {\n                        \"coef_\": [\n                            [\n                                -0.10828543454408646\n                            ],\n                            [\n                                -0.07341302931308746\n                            ],\n                            [\n                                -0.10850320011377335\n                            ],\n                            [\n                                -0.10066638141870499\n                            ],\n                            [\n                                -0.04595951363444328\n                            ],\n                            [\n                                -0.07001449167728424\n                            ],\n                            [\n                                -0.08949052542448044\n                            ],\n                            [\n                                -0.10958756506443024\n                            ],\n                            [\n                                -0.04012322425842285\n                            ],\n                            [\n                                0.02270071767270565\n                            ],\n                            [\n                                -0.07198350876569748\n                            ],\n                            [\n                                0.00548586156219244\n                            ],\n                            [\n                                -0.06599288433790207\n                            ],\n                            [\n                                -0.06410090625286102\n                            ],\n                            [\n                                0.016374297440052032\n                            ],\n                            [\n                                -0.01607361063361168\n                            ],\n                            [\n                                -0.011447405442595482\n                            ],\n                            [\n                                -0.04352564364671707\n                            ],\n                            [\n                                0.013161249458789825\n                            ],\n                            [\n                                0.013506329618394375\n                            ]\n                        ],\n                        \"dtype\": \"float32\",\n                        \"intercept_\": null\n                    }\n                }\n            },\n            \"meta\": {\n                \"batch_size\": null,\n                \"epochs\": 10,\n                \"init_param\": {\n                    \"fill_val\": 0.0,\n                    \"fit_intercept\": false,\n                    \"method\": \"zeros\",\n                    \"random_state\": null\n                },\n                \"label_count\": false,\n                \"learning_rate_param\": {\n                    \"method\": \"linear\",\n                    \"scheduler_params\": {\n                        \"start_factor\": 0.7,\n                        \"total_iters\": 100\n                    }\n                },\n                \"optimizer_param\": {\n                    \"alpha\": 0.001,\n                    \"method\": \"sgd\",\n                    \"optimizer_params\": {\n                        \"lr\": 0.1\n                    },\n                    \"penalty\": \"l2\"\n                },\n                \"ovr\": false\n            }\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"quick_start/#2322-downloading-models","title":"2.3.2.2 Downloading Models","text":"<p><pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> For example, with the previously submitted training DAG task, you can use <code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code> to download. The download result is shown below: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre></p>"},{"location":"quick_start/#233-output-data","title":"2.3.3 Output Data","text":""},{"location":"quick_start/#2331-query-data-table","title":"2.3.3.1 Query Data Table","text":"<p><pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For instance, with the previously submitted training DAG task, you can use <code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> to query. The result looks like this: <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"quick_start/#2332-preview-data","title":"2.3.3.2 Preview Data","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, with the previously submitted training DAG task, you can use <code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> to preview output data.</p>"},{"location":"quick_start/#2333-download-data","title":"2.3.3.3 Download Data","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> For example, with the previously submitted training DAG task, you can use <code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code> to download output data. The download result is as follows: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"quick_start/#3-more-documentation","title":"3. More Documentation","text":"<ul> <li>Restful-api</li> <li>CLI</li> <li>Pipeline</li> <li>FATE Quick Start</li> <li>FATE Algorithms</li> </ul>"},{"location":"system_conf/","title":"System Configuration","text":"<p>FATE Flow uses YAML to define system configurations, and the configuration file is located at: <code>conf/service_conf.yaml</code>. The specific configuration contents and their meanings are as follows:</p> Configuration Item Description Values party_id Local site ID For example, \"9999\", \"10000\" log_level Log level DEBUG:10, INFO:20, DEBUG:30, ERROR: 40 use_registry Whether to use a registry center; currently, only ZooKeeper mode is supported, and it requires correct ZooKeeper configuration. Note: If using high availability mode, ensure this configuration is set to true. true/false encrypt Encryption module See Encryption Module fateflow Configuration for the FATE Flow service, including ports, command channel service, and proxy See FateFlow Configuration database Configuration information for the database service See Database Configuration default_engines System's engine services, including computing, storage, and communication engines See Engine Configuration default_provider Component source information, including provider name, component version, and execution mode See Default Registered Algorithm Configuration federation Communication service pool See Communication Engine Pool computing Computing service pool See Computing Engine Pool storage Storage service pool See Storage Engine Pool hook_module Hook configuration, currently supports client authentication, site authentication, and authorization hooks See Hook Module Configuration authentication Authentication and authorization switches See Authentication Switch model_store Model storage configuration See Model Storage zookeeper ZooKeeper service configuration See ZooKeeper Configuration"},{"location":"system_conf/#encryption-module","title":"Encryption Module","text":"<p><pre><code>key_0:\n  module: fate_flow.hub.encrypt.password_encrypt#pwdecrypt\n  private_path: private_key.pem\n</code></pre> This encryption module is primarily used for encrypting passwords (e.g., MySQL passwords): - \"key_0\" is the key for the encryption module (you can customize the name), making it easier to reference in other configurations when multiple encryption modes coexist.   - module: The encryption module, formatted as \"encryption module\" + \"#\" + \"encryption function.\"   - private_path: The path to the encryption key. If you provide a relative path, its root directory is <code>fate_flow/conf/</code>.</p>"},{"location":"system_conf/#fateflow-configuration","title":"FateFlow Configuration","text":"<p><pre><code>host: 127.0.0.1\nhttp_port: 9380\ngrpc_port: 9360\nproxy_name: osx\nnginx:\n  host:\n  http_port:\n  grpc_port:\n</code></pre> - host: Host address. - http_port: HTTP port number. - grpc_port: gRPC port number. - proxy_name: Command channel service name, supporting osx/nginx. Detailed configurations need to be set within Communication Engine Pool. - nginx: Proxy service configuration for load balancing.</p>"},{"location":"system_conf/#database-configuration","title":"Database Configuration","text":"<p><pre><code>engine: sqlite\ndecrypt_key:\nmysql:\n  name: fate_flow\n  user: fate\n  passwd: fate\n  host: 127.0.0.1\n  port: 3306\n  max_connections: 100\n  stale_timeout: 30\nsqlite:\n  path:\n</code></pre> - engine: Database engine name. If set to \"mysql\" here, update the detailed MySQL configuration. - decrypt_key: Encryption module, selected from Encryption Module. If not configured, it's considered to not use password encryption. If used, you need to set the \"passwd\" below to ciphertext and configure the key path in Encryption Module. - mysql: MySQL service configuration. If using password encryption functionality, set the \"passwd\" in this configuration to ciphertext and configure the key path in Encryption Module. - sqlite: SQLite file path, default path is <code>fate_flow/fate_flow_sqlite.db</code>.</p>"},{"location":"system_conf/#engine-configuration","title":"Engine Configuration","text":"<pre><code>default_engines:\n  computing: standalone\n  federation: standalone\n  storage: standalone\n</code></pre> <ul> <li>computing: Computing engine, supports \"standalone\", \"eggroll\", \"spark\".</li> <li>federation: Communication engine, supports \"standalone\", \"osx\", \"rabbitmq\", \"pulsar\".</li> <li>storage: Storage engine, supports \"standalone,\" \"eggroll,\" \"hdfs.\"</li> </ul>"},{"location":"system_conf/#default-registered-algorithm-configuration","title":"Default Registered Algorithm Configuration","text":"<ul> <li>name: Algorithm name.</li> <li>version: Algorithm version. If not configured, it uses the configuration in <code>fateflow.env</code>.</li> <li>device: Algorithm launch mode, local/docker/k8s, etc.</li> </ul>"},{"location":"system_conf/#communication-engine-pool","title":"Communication Engine Pool","text":""},{"location":"system_conf/#osx","title":"OSx","text":"<pre><code>  host: 127.0.0.1\n  port: 9370\n  mode: stream\n</code></pre>"},{"location":"system_conf/#computing-engine-pool","title":"Computing Engine Pool","text":""},{"location":"system_conf/#standalone","title":"Standalone","text":"<p><pre><code>  cores: 32\n</code></pre> - cores: Total resources.</p>"},{"location":"system_conf/#eggroll","title":"Eggroll","text":"<p><pre><code>eggroll:\n  cores: 32\n  nodes: 1\n  host: 127.0.0.1\n  port: 4670\n</code></pre> - cores: Total cluster resources. - nodes: Number of node managers in the cluster. - host: eggroll cluster manager host ip - port: eggroll cluster manager port</p>"},{"location":"system_conf/#spark","title":"Spark","text":"<p><pre><code>spark:\n  home: \n  cores: 32\n</code></pre> - home: Spark home directory. If not filled, \"pyspark\" will be used as the computing engine. - cores: Total resources.</p>"},{"location":"system_conf/#storage-engine-pool","title":"Storage Engine Pool","text":"<pre><code>  hdfs:\n    name_node: hdfs://fate-cluster\n</code></pre>"},{"location":"system_conf/#hook-module-configuration","title":"Hook Module Configuration","text":"<p><pre><code>hook_module:\n  client_authentication: fate_flow.hook.flow.client_authentication\n  site_authentication: fate_flow.hook.flow.site_authentication\n  permission: fate_flow.hook.flow.permission\n</code></pre> - client_authentication: Client authentication hook. - site_authentication: Site authentication hook. - permission: Permission authentication hook.</p>"},{"location":"system_conf/#authentication-switch","title":"Authentication Switch","text":"<pre><code>authentication:\n  client: false\n  site: false\n  permission: false\n</code></pre>"},{"location":"system_conf/#model-storage","title":"Model Storage","text":"<p><pre><code>model_store:\n  engine: file\n  decrypt_key:\n  file:\n    path:\n  mysql:\n    name: fate_flow\n    user: fate\n    passwd: fate\n    host: 127.0.0.1\n    port: 3306\n    max_connections: 100\n    stale_timeout: 30\n  tencent_cos:\n    Region:\n    SecretId:\n    SecretKey:\n    Bucket:\n</code></pre> - engine: Model storage engine, supports \"file,\" \"mysql\", and \"tencent_cos\". - decrypt_key: Encryption module, needs to be selected from Encryption Module. If not configured, it is assumed to not use password encryption. If used, you need to set the \"passwd\" below accordingly to ciphertext and configure the key path in Encryption Module. - file: Model storage directory, default location is <code>fate_flow/model</code>. - mysql: MySQL service configuration; if using password encryption functionality, you need to set the \"passwd\" in this configuration to ciphertext and configure the key path in Encryption Module. - tencent_cos: Tencent Cloud key configuration.</p>"},{"location":"system_conf/#zookeeper-configuration","title":"ZooKeeper Configuration","text":"<pre><code>zookeeper:\n  hosts:\n    - 127.0.0.1:2181\n  use_acl: true\n  user: fate\n  password: fate\n</code></pre>"},{"location":"mkdocs/","title":"Build","text":""},{"location":"mkdocs/#use-docker","title":"use docker","text":"<p>At repo root, execute</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs  \n</code></pre> <p>to serve docs in http://localhost:8000</p> <p>or</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs build\n</code></pre> <p>to build docs to <code>site</code> folder.</p>"},{"location":"mkdocs/#manually","title":"manually","text":"<p><code>mkdocs-material</code> and servel plugins are needed to build this docs</p> <p>Fisrt, create an python virtual environment</p> <p><pre><code>python3 -m venv \"fatedocs\"\nsource fatedocs/bin/activate\npip install -U pip\n</code></pre> And then install requirements</p> <pre><code>pip install -r doc/mkdocs/requirements.txt\n</code></pre> <p>Now, use</p> <pre><code>mkdocs serve\n</code></pre> <p>at repo root to serve docs or</p> <p>use </p> <pre><code>mkdocs build\n</code></pre> <p>at repo root to build docs to folder <code>site</code></p>"},{"location":"mkdocs/#develop-guide","title":"Develop guide","text":"<p>We use mkdocs-material to build our docs.  Servel markdown extensions are really useful to write pretty documents such as  admonitions and  content-tabs.</p> <p>Servel plugins are introdused to makes mkdocs-material much powerful:</p> <ul> <li> <p>mkdocstrings      automatic documentation from sources code. We mostly use this to automatic generate     <code>params api</code> for <code>federatedml</code>.</p> </li> <li> <p>awesome-pages     for powerful nav rule</p> </li> <li> <p>i18n     for multi-languege support</p> </li> <li> <p>mkdocs-jupyter     for jupyter format support</p> </li> <li> <p>mkdocs-simple-hooks     for simple plugin-in</p> </li> </ul>"},{"location":"mkdocs/docker/","title":"Image for build FATE's documents","text":"<p>This image is modified from mkdocs-meterial with some plugins embeded.</p> <p>Usage</p> <p>Mount the folder where your mkdocs.yml resides as a volume into /docs:</p> <ul> <li>Start development server on http://localhost:8000</li> </ul> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs\n</code></pre> <ul> <li>Build documentation</li> </ul> <pre><code>docker run --rm -it -v ${PWD}:/docs sagewei/mkdocs build\n</code></pre> <ul> <li>Deploy documentation to GitHub Pages</li> </ul> <pre><code>docker run --rm -it -v ~/.ssh:/root/.ssh -v ${PWD}:/docs sagewei0/mkdocs gh-deploy \n</code></pre>"},{"location":"mkdocs/theme/","title":"Index","text":"<p>Mostly copied from https://github.com/cirruslabs/cirrus-ci-docs/tree/master/theme</p>"},{"location":"swagger/","title":"API","text":""},{"location":"swagger/#swagger-api","title":"Swagger API","text":""},{"location":"zh/bfia_access/","title":"BFIA\u63a5\u5165\u6307\u5357","text":"<p>BFIA\u534f\u8bae\u7531\u5317\u4eac\u91d1\u878d\u79d1\u6280\u4ea7\u4e1a\u8054\u76df\u7ec4\u7ec7\uff0c\u4e2d\u56fd\u94f6\u8054\u7275\u5934\uff0c\u8054\u5408\u4e3b\u8981\u91d1\u878d\u673a\u6784\u3001\u7535\u4fe1\u8fd0\u8425\u5546\u3001\u4e92\u8054\u7f51\u516c\u53f8\u3001\u79d1\u6280\u516c\u53f8\u3001\u68c0\u6d4b\u673a\u6784\u3001\u79d1\u7814\u9662\u6240\u7b4960\u4f59\u5bb6\u5355\u4f4d\u5171\u540c\u5236\u5b9a\u7684\u4e92\u8054\u4e92\u901aAPI\u63a5\u53e3\u89c4\u8303\u3002FATE 2.0\u7248\u672c\u4ecePipeline\u3001\u8c03\u5ea6\u3001\u901a\u4fe1\u7b49\u51e0\u4e2a\u5c42\u9762\u9002\u914d\u6b64\u534f\u8bae\uff0c\u672c\u6587\u5c06\u4ecb\u7ecd\u5982\u4f55\u4ee5BFIA\u534f\u8bae\u4e0eFATE\u6846\u67b6\u8fdb\u884c\u8054\u90a6\u5b66\u4e60\u3002</p>"},{"location":"zh/bfia_access/#1-pipeline","title":"1. Pipeline","text":"<p> pipeline\u6784\u5efaFATE\u7684\u4e92\u8054\u4e92\u901a\u7edf\u4e00\u5ba2\u6237\u7aef\uff0c\u4ea7\u751f\u57fa\u4e8eFATE 2.0\u534f\u8bae\u7684DAG\u914d\u7f6e\u3002pipeline\u5e76\u4e0d\u76f4\u63a5\u8c03\u7528BFIA\u534f\u8baeAPI\uff0c\u800c\u662f\u8c03\u7528FATE\u534f\u8baeAPI\uff0c\u5728FATE Flow\u5185\u901a\u8fc7\u9002\u914d\u5668\u6a21\u5f0f\u8f6c\u5316\u4e3aBFIA\u534f\u8bae\u8fd0\u884c\u3002</p>"},{"location":"zh/bfia_access/#11-fate","title":"1.1 FATE\u7b97\u6cd5","text":"<pre><code>from fate_client.pipeline import FateFlowPipeline\nfrom fate_client.pipeline.components.fate import CoordinatedLR, PSI\nfrom fate_client.pipeline.interface.channel import DataWarehouseChannel\n\n\nguest = \"JG0100001100000010\"\nhost = \"JG0100001100000010\"\narbiter = \"JG0100001100000010\"\npipeline = FateFlowPipeline().set_parties(guest=guest, host=host, arbiter=arbiter)\npipeline.set_site_role(\"guest\")\npipeline.set_site_party_id(guest)\n\npsi_0 = PSI(\"psi_0\",\n        input_data=[DataWarehouseChannel(dataset_id=\"experiment#breast_hetero_guest\", parties=dict(guest=guest)),\n                    DataWarehouseChannel(dataset_id=\"experiment#breast_hetero_host\", parties=dict(host=host))])\nlr_0 = CoordinatedLR(\"lr_0\",\n                 epochs=10,\n                 batch_size=300,\n                 optimizer={\"method\": \"SGD\", \"optimizer_params\": {\"lr\": 0.1}, \"penalty\": \"l2\", \"alpha\": 0.001},\n                 init_param={\"fit_intercept\": True, \"method\": \"zeros\"},\n                 train_data=psi_0.outputs[\"output_data\"],\n                 learning_rate_scheduler={\"method\": \"linear\", \"scheduler_params\": {\"start_factor\": 0.7,\n                                                                                   \"total_iters\": 100}})\n\npipeline.add_tasks([psi_0, lr_0])\n\npipeline.protocol_kind = \"bfia\"\npipeline.conf.set(\n\"extra\",\ndict(initiator={'party_id': guest, 'role': 'guest'})\n)\npipeline.guest.conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.hosts[0].conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.compile()\npipeline.fit()\n</code></pre>"},{"location":"zh/bfia_access/#12","title":"1.2 \u94f6\u8054\u7b97\u6cd5","text":"<pre><code>from fate_client.pipeline import FateFlowPipeline\nfrom fate_client.pipeline.adapters.bfia.components.unionpay.intersection import Intersection\nfrom fate_client.pipeline.adapters.bfia.components.unionpay.hetero_lr import HeteroLR\nfrom fate_client.pipeline.interface import DataWarehouseChannel\n\n\npipeline = FateFlowPipeline().set_parties(\n    guest=\"JG0100001100000010\",\n    host=\"JG0100001100000010\",\n    arbiter=\"JG0100001100000010\"\n)\npipeline.set_site_role(\"guest\")\npipeline.set_site_party_id(\"JG0100001100000010\")\n\nintersection_0 = Intersection(\n    \"intersect_rsa_1\",\n    id=\"id\",\n    intersect_method=\"rsa\",\n    only_output_key=False,\n    rsa_params=dict(\n        final_hash_method=\"sha256\",\n        hash_method=\"sha256\",\n        key_length=2048\n    ),\n    sync_intersect_ids=True,\n    connect_engine=\"mesh\",\n    train_data=[\n        DataWarehouseChannel(dataset_id=\"testspace#test_guest\", parties=dict(guest=\"JG0100001100000010\")),\n        DataWarehouseChannel(dataset_id=\"testspace#test_host\", parties=dict(host=\"JG0100001100000010\"))\n    ]\n)\n\nhetero_lr_0 = HeteroLR(\n    \"hetero_logistic_regression_1\",\n    id=\"id\",\n    label=\"y\",\n    batch_size=-1,\n    penalty=\"L2\",\n    early_stop=\"diff\",\n    tol=0.0001,\n    max_iter=2,\n    alpha=0.01,\n    optimizer=\"nesterov_momentum_sgd\",\n    init_param={\"init_method\":\"zeros\"},\n    learning_rate=0.15,\n    connect_engine=\"mesh\",\n    train_data=intersection_0.outputs[\"train_data\"]\n)\n\npipeline.add_task(intersection_0)\npipeline.add_task(hetero_lr_0)\npipeline.conf.set(\n    \"extra\",\n    dict(initiator={'party_id': 'JG0100001100000010', 'role': 'guest'})\n)\n\npipeline.protocol_kind = \"bfia\"\npipeline.guest.conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.hosts[0].conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.compile()\npipeline.fit()\n</code></pre>"},{"location":"zh/bfia_access/#13-bfia","title":"1.3 BFIA\u534f\u8bae\u5176\u4ed6\u7b97\u6cd5","text":""},{"location":"zh/bfia_access/#131-pipeline","title":"1.3.1 pipeline\u9002\u914d\u5f00\u53d1","text":"<p>\u76ee\u524dpipeline\u9002\u914d\u4e86fate\u548c\u94f6\u8054\u7b97\u6cd5\u7684\u751f\u6210\uff0c\u5176\u4ed6\u7684\u7b97\u6cd5\u4e5f\u53ef\u4ee5\u63a5\u5165pipeline\u3002\u5177\u4f53\u63a5\u5165\u65b9\u6cd5\u5982\u4e0b - \u7ec4\u4ef6\u63cf\u8ff0\u6587\u4ef6\uff1a\u9700\u8981\u5c06\u7b97\u6cd5\u7ec4\u4ef6\u63cf\u8ff0\u6587\u4ef6\u653e\u5728pipeline-component-define - \u7ec4\u4ef6\u5b9a\u4e49\uff1a\u9700\u8981\u5c06\u7b97\u6cd5\u7ec4\u4ef6\u63cf\u8ff0\u6587\u4ef6\u653e\u5728pipeline-component</p>"},{"location":"zh/bfia_access/#2","title":"2. \u8c03\u5ea6","text":""},{"location":"zh/bfia_access/#21","title":"2.1 \u4fee\u6539\u914d\u7f6e","text":"<ul> <li>\u4fee\u6539\u8def\u7531\u914d\u7f6e</li> <li>\u672c\u65b9\u7ad9\u70b9local-site-settings</li> <li><code>LOCAL_SITE_ID</code>: \u672c\u65b9\u7ad9\u70b9id</li> <li><code>STORAGE_ADDRESS</code>: s3\u5b58\u50a8\u5730\u5740</li> <li><code>TRANSPORT</code>: \u672c\u65b9\u7b97\u6cd5\u6240\u4f7f\u7528\u7684\u901a\u4fe1\u5f15\u64ce\u5730\u5740</li> <li><code>CONTAINER_LOG_PATH</code>: \u5bb9\u5668\u7684\u65e5\u5fd7\u78c1\u76d8\u6302\u8f7d\u7684\u672c\u5730\u8def\u5f84</li> <li><code>CALLBACK_ADDRESS</code>: \u8c03\u5ea6\u670d\u52a1\u7684\u5730\u5740\uff0c\u4f9b\u7b97\u6cd5\u56de\u8c03\u4f7f\u7528</li> </ul>"},{"location":"zh/bfia_access/#22","title":"2.2 \u6ce8\u518c\u7b97\u6cd5","text":"<p><pre><code>{\n  \"name\": \"unionpay\",\n  \"device\": \"docker\",\n  \"version\": \"2.0.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"unionpay:2.0.0\"\n  },\n  \"protocol\": \"bfia\",\n  \"components_description\": {}\n}\n</code></pre> \u6ce8\u518c\u914d\u7f6e\u8bf4\u660e\uff1a - <code>name</code>: \u63d0\u4f9b\u5382\u5546\u540d\u79f0 - <code>device</code>: \u7b97\u6cd5\u8fd0\u884c\u7684\u6a21\u5f0f\uff0c\u5f53\u524d\u652f\u6301\"docker\" - <code>version</code>: \u7b97\u6cd5\u7248\u672c - <code>metadata</code>: \u955c\u50cf\u4fe1\u606f - <code>protocol</code>: \u7b97\u6cd5\u4f7f\u7528\u534f\u8bae - <code>components_description</code>: \u7b97\u6cd5\u7ec4\u4ef6\u63cf\u8ff0\u4fe1\u606f, \u53c2\u8003BFIA\u7b97\u6cd5\u81ea\u63cf\u8ff0</p>"},{"location":"zh/bfia_access/#221-fate","title":"2.2.1 \u6ce8\u518cFATE\u7b97\u6cd5","text":"<p><pre><code>flow provider register -c examples/bfia/fate/register/fate_components.json\n</code></pre> - \u914d\u7f6e\u53c2\u8003fate_components.json</p>"},{"location":"zh/bfia_access/#222","title":"2.2.2 \u6ce8\u518c\u94f6\u8054\u7b97\u6cd5","text":"<p><pre><code>flow provider register -c examples/bfia/unionpay/register/unionpay_components.json\n</code></pre> - \u914d\u7f6e\u53c2\u8003unionpay_components.json</p>"},{"location":"zh/bfia_access/#223","title":"2.2.3 \u6ce8\u518c\u5176\u4ed6\u7b97\u6cd5","text":"<p>\u53ef\u4ee5\u6309\u7167\u4e0a\u9762\u914d\u7f6e\u5c06\u5176\u4ed6\u5382\u5546\u7684\u7b97\u6cd5\u955c\u50cf\u6ce8\u518c\u5230FATE Flow\u670d\u52a1\u4e2d\u3002\u8fd0\u884c\u65f6\u4f1a\u81ea\u52a8\u52a0\u8f7d\u6210\u5bb9\u5668\u8fd0\u884c\u6b64\u7b97\u6cd5\u3002</p>"},{"location":"zh/bfia_access/#3","title":"3. \u4f7f\u7528","text":"<ul> <li>\u6309\u7167\u4e0a\u8ff02.1\u4fee\u6539\u914d\u7f6e</li> <li>\u6309\u7167\u4e0a\u8ff02.2\u6ce8\u518c\u5bf9\u5e94\u7684\u7b97\u6cd5</li> </ul>"},{"location":"zh/bfia_access/#31-fate","title":"3.1 \u4f7f\u7528FATE\u7b97\u6cd5\u955c\u50cf","text":""},{"location":"zh/bfia_access/#311","title":"3.1.1 \u6570\u636e\u4e0a\u4f20","text":""},{"location":"zh/bfia_access/#3111-upload","title":"3.1.1.1 upload","text":"<ul> <li>\u5b89\u88c5FATE Flow\u548c Flow Cli <pre><code>pip install fate_flow==2.0.0\npip install fate_client==2.0.0\n</code></pre></li> <li>upload\u6570\u636e\u5230s3\u5b58\u50a8 <pre><code>import os\nimport tempfile\n\nfrom fate_flow.adapter.bfia.container.wraps.wraps import DataIo\nfrom fate_flow.components.components.upload import Upload, UploadParam\nfrom fate_flow.entity.spec.dag import Metadata\n\n\ndef upload_data(s3_address, namespace, name, file, meta, head=True, partitions=16, extend_sid=True, storage_engine=\"standalone\"):\n    upload_object = Upload()\n    params = {\n        'name': name,\n        'namespace': namespace,\n        'file': file,\n        'storage_engine': storage_engine,\n        'head': head,\n        'partitions': partitions,\n        'extend_sid': extend_sid,\n        'meta': meta\n    }\n    params = UploadParam(**params)\n\n    with tempfile.TemporaryDirectory() as data_home:\n        os.environ[\"STANDALONE_DATA_HOME\"] = data_home\n        data_meta = upload_object.run(params).get(\"data_meta\")\n\n        metadata = Metadata(metadata=dict(options=dict(partitions=partitions), schema=data_meta))\n        data_path = os.path.join(data_home, namespace, name)\n        engine = DataIo(s3_address)\n        engine.upload_to_s3(data_path, name=name, namespace=namespace, metadata=metadata.dict())\n\n\nif __name__ == \"__main__\":\n    s3_address = \"s3://127.0.0.1:9000?username=admin&amp;password=12345678\"\n    file = 'examples/data/breast_hetero_guest.csv'\n    namespace = \"upload\"\n    name = \"guest\"\n\n\n    meta = {\n        \"delimiter\": \",\",\n        \"label_name\": \"y\",\n        \"match_id_name\": \"id\"\n    }\n    upload_data(s3_address=s3_address, namespace=namespace, name=name, file=file, meta=meta)\n</code></pre> \u4fee\u6539\u4e0a\u9762\u7684<code>s3_address</code>\u3001<code>file</code>\u3001<code>namespace</code>\u3001 <code>name</code>\u3001<code>meta</code>\u53c2\u6570\u4e3a\u5b9e\u9645\u503c\uff0c\u53c2\u6570\u542b\u4e49\u5982\u4e0b\uff1a <pre><code>s3_address: s3\u5b58\u50a8\u5730\u5740\nfile: \u672c\u5730\u6570\u636e\u7684\u8def\u5f84\nnamespace: fate\u7684\u8868\u7a7a\u95f4\u540d\nname: fate\u7684\u8868\u540d\nmeta: \u6570\u636e\u5143\u4fe1\u606f\n</code></pre></li> </ul>"},{"location":"zh/bfia_access/#3112-dataframe-transformer","title":"3.1.1.2 dataframe-transformer","text":"<p>\u8bf4\u660e\uff1a\u4e0a\u9762\u7684upload\u662f\u5c06\u6570\u636e\u4e0a\u4f20\u5230s3\u5b58\u50a8\u4e2d\uff0cfate\u7684\u7b97\u6cd5\u4f9d\u8d56dataframe\u683c\u5f0f\u6570\u636e\u96c6\uff0cfate\u63d0\u4f9b<code>dataframe-transformer</code>\u7ec4\u4ef6\u5c06\u8fdb\u884c\u6570\u636e\u8f6c\u5316\u3002\u5728BFIA\u534f\u8bae\u4e2d\u7684\u6570\u636e\u8f93\u5165\u53c2\u6570\u4e3a<code>dataset_id</code>, FATE\u9002\u914d\u8fd9\u4e2a\u53c2\u6570\u7684\u65b9\u5f0f\u4e3a<code>$namespace + '#' + $name</code> - \u914d\u7f6e\uff1adataframe-transformer - \u5c06\u914d\u7f6e\u4e2d\u7684<code>JG0100001100000010</code>\u66ff\u6362\u6210\u5b9e\u9645\u7ad9\u70b9ID - \u4fee\u6539<code>dataset_id</code>\u4e3a<code>$namespace + '#' + $name</code>, \u5176\u4e2dnamespace\u548cname\u4e3aupload\u8bbe\u7f6e\u7684\u53c2\u6570 <pre><code>dag:\n  tasks:\n    transformer_0:\n      inputs:\n        data:\n          table:\n            data_warehouse:\n              dataset_id: upload#guest\n</code></pre> - \u8f93\u51fa\u7684\u6570\u636e\u8868\u5728dag.tasks.transformer_0.parameters\u53c2\u6570\u4e2d\u5b9a\u4e49\uff0c\u53ef\u4ee5\u4fee\u6539\u4e3a\u81ea\u5b9a\u4e49\u7684\u503c <pre><code>dag:\n  tasks:\n    transformer_0:\n      parameters:\n        name: breast_hetero_guest\n        namespace: experiment\n</code></pre> - \u63d0\u4ea4\u5e76<code>dataframe-transformer</code>\u7ec4\u4ef6: <code>flow job submit -c examples/bfia/fate/job/dataframe_transformer.yaml</code></p>"},{"location":"zh/bfia_access/#312-fate","title":"3.1.2 \u8fd0\u884cFATE\u7b97\u6cd5\u7ec4\u4ef6","text":"<p>\u53ef\u4ee5\u901a\u8fc7cli\u3001pipeline\u6216\u8005bfia\u7684restful-api\u63d0\u4ea4\u4f5c\u4e1a - cli\u63d0\u4ea4\u4f5c\u4e1a:    - \u914d\u7f6e\uff1apsi-lr\u3001psi-sbt   - \u547d\u4ee4: <code>flow job submit -c examples/bfia/fate/job/psi_lr.yaml</code> - pipeline\u63d0\u4ea4\u4f5c\u4e1a\uff1apsi-lr\u3001psi-sbt - restful-api: psi-lr\u3001psi-sbt</p>"},{"location":"zh/bfia_access/#32","title":"3.2 \u4f7f\u7528\u5176\u4ed6\u5382\u5546\u7b97\u6cd5\u955c\u50cf","text":""},{"location":"zh/bfia_access/#321","title":"3.2.1 \u6570\u636e\u4e0a\u4f20","text":"<p>\u7531\u5404\u5382\u5546\u63d0\u4f9b\u5404\u81ea\u7684\u6570\u636e\u4e0a\u4f20\u63a5\u53e3</p>"},{"location":"zh/bfia_access/#322","title":"3.2.2 \u8fd0\u884c\u5176\u4ed6\u5382\u5546\u7b97\u6cd5\u7ec4\u4ef6(\u94f6\u8054\u4e3a\u4f8b)","text":"<p>\u53ef\u4ee5\u901a\u8fc7cli\u3001pipeline\u6216\u8005bfia\u7684restful-api\u63d0\u4ea4\u4f5c\u4e1a - cli\u63d0\u4ea4\u4f5c\u4e1a:    - \u914d\u7f6e\uff1apsi-lr\u3001psi-sbt   - \u547d\u4ee4: <code>flow job submit -c examples/bfia/unionpay/job/psi_lr.yaml</code> - pipeline\u63d0\u4ea4\u4f5c\u4e1a\uff1apsi-lr\u3001psi-sbt - restful-api: psi-lr\u3001psi-sbt</p>"},{"location":"zh/data_access/","title":"FATE\u6570\u636e\u63a5\u5165\u6307\u5357","text":""},{"location":"zh/data_access/#1","title":"1. \u4e0a\u4f20\u6d41\u7a0b","text":"<p>\u6570\u636e\u4e0a\u4f20\u7684\u6d41\u7a0b\u56fe\u5982\u4e0b\uff1a</p> <p> - \u5ba2\u6237\u7aef\u5c06\u6570\u636e\u4e0a\u4f20\u5230\u670d\u52a1\u7aef\uff1b - \u670d\u52a1\u7aef\u5c06\u4e0a\u4f20\u53c2\u6570\u5c01\u88c5\u6210DAG\u4f5c\u4e1a\u914d\u7f6e, \u914d\u7f6e\u4e2d\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6, \u5373upload\u548cdataframe-transformer\uff0c\u5e76\u8c03\u7528submit\u63a5\u53e3\u63d0\u4ea4\u4f5c\u4e1a\uff1b - upload\u7ec4\u4ef6\u5c06\u6570\u636e\u5b58\u50a8\u5230fate\u5b58\u50a8\u670d\u52a1\u4e2d\uff1b - transformer\u7ec4\u4ef6\u5c06upload\u7ec4\u4ef6\u7684\u6570\u636e\u8f93\u51fa\u8f6c\u5316\u6210dataframe\u5e76\u5b58\u50a8\u5230fate\u5b58\u50a8\u670d\u52a1\u4e2d\uff1b - \u6570\u636e\u7684meta\u4fe1\u606f\u5b58\u50a8\u5230DB\u4e2d.</p>"},{"location":"zh/data_access/#2","title":"2. \u6570\u636e\u4e0a\u4f20\u65b9\u5f0f","text":"<p>\u6ce8\uff1a fate\u63d0\u4f9b\u7684\u5ba2\u6237\u7aef\u5305\u62ecSDK\u3001CLI\u3001Pipeline\uff0c\u82e5\u4f60\u7684\u73af\u5883\u4e2d\u6ca1\u6709\u90e8\u7f72FATE Client,\u53ef\u4ee5\u4f7f\u7528<code>pip install fate_client</code>\u4e0b\u8f7d\uff0c\u4ee5\u4e0b\u7684\u4f7f\u7528\u64cd\u4f5c\u5747\u57fa\u4e8ecli\u7f16\u5199\u3002</p>"},{"location":"zh/data_access/#21","title":"2.1 \u4e0a\u4f20\u573a\u666f\u8bf4\u660e","text":"<ul> <li>\u5ba2\u6237\u7aef\u3001\u670d\u52a1\u5668\u5206\u79bb\uff1a\u5b89\u88c5\u7684\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u5668\u4e0d\u5728\u4e00\u53f0\u673a\u5668</li> <li>\u5ba2\u6237\u7aef\u3001\u670d\u52a1\u5668\u4e0d\u5206\u79bb\uff1a\u5b89\u88c5\u7684\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u5668\u5728\u540c\u4e00\u53f0\u673a\u5668 \u4e24\u8005\u533a\u522b\uff1a\u5ba2\u6237\u7aef\u4e0d\u5206\u79bb\u7684\u573a\u666f\uff0c\u53ef\u4ee5\u53bb\u6389\u4e0a\u8ff0\u6d41\u7a0b\u4e2d\"\u5ba2\u6237\u7aef\u5c06\u6570\u636e\u4e0a\u4f20\u5230\u670d\u52a1\u7aef\"\uff0c\u4ee5\u6b64\u63d0\u9ad8\u5927\u6570\u636e\u91cf\u573a\u666f\u4e0b\u6570\u636e\u4e0a\u4f20\u7684\u6548\u7387\u3002\u4e24\u79cd\u573a\u666f\u63a5\u53e3\u3001\u53c2\u6570\u6709\u533a\u522b\uff0c\u53ef\u4ee5\u9009\u62e9\u5bf9\u5e94\u7684\u573a\u666f\u8fdb\u884c\u6570\u636e\u4e0a\u4f20\u3002</li> </ul>"},{"location":"zh/data_access/#22","title":"2.2 \u6570\u636e\u4e0a\u4f20","text":""},{"location":"zh/data_access/#221","title":"2.2.1 \u914d\u7f6e\u53ca\u6570\u636e\u51c6\u5907","text":"<ul> <li>\u4e0a\u4f20\u914d\u7f6e\u4f4d\u4e8eexamples-upload <pre><code>{\n  \"file\": \"examples/data/breast_hetero_guest.csv\",\n  \"head\": true,\n  \"partitions\": 16,\n  \"extend_sid\": true,\n  \"meta\": {\n    \"delimiter\": \",\",\n    \"label_name\": \"y\",\n    \"match_id_name\": \"id\"\n  },\n  \"namespace\": \"experiment\",\n  \"name\": \"breast_hetero_guest\"\n}\n</code></pre></li> <li>file: \u6587\u4ef6\u8def\u5f84</li> <li>head: \u6570\u636e\u662f\u5426\u643a\u5e26header: true/false</li> <li>partitions: \u6570\u636e\u5b58\u50a8\u5206\u533a\u6570\u91cf</li> <li>extend_sid\uff1a\u662f\u5426\u9700\u8981\u751f\u6210sid\u5217</li> <li>meta\uff1a\u6570\u636e\u7684\u5143\u4fe1\u606f</li> <li>namespace &amp;&amp; name: \u6570\u636e\u5728fate\u7684\u5b58\u50a8\u8868\u5f15\u7528</li> <li>\u4e0a\u4f20\u6570\u636e\u4f4d\u4e8eupload-data</li> <li>\u4f60\u4e5f\u53ef\u4ee5\u4f7f\u7528\u81ea\u5df1\u7684\u6570\u636e\uff0c\u5e76\u4fee\u6539upload\u914d\u7f6e\u4e2d\u7684\"meta\"\u4fe1\u606f</li> </ul>"},{"location":"zh/data_access/#222","title":"2.2.2 \u4e0a\u4f20\u6570\u636e\u547d\u4ee4","text":""},{"location":"zh/data_access/#-","title":"\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u4e0d\u5206\u79bb","text":"<p><pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre> \u6ce8\uff1a\u9700\u8981\u4fdd\u8bc1\u914d\u7f6e\u4e2d\u7684file\u8def\u5f84\u5728\u670d\u52a1\u5668\u4e2d\u5b58\u5728\u3002</p>"},{"location":"zh/data_access/#-_1","title":"\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u5206\u79bb","text":"<pre><code>flow data upload-file -c examples/upload/upload_guest.json\n</code></pre>"},{"location":"zh/data_access/#223","title":"2.2.3 \u4e0a\u4f20\u7ed3\u679c","text":"<pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\"\n    },\n    \"job_id\": \"202312281606030428210\",\n    \"message\": \"success\"\n}\n</code></pre>"},{"location":"zh/data_access/#224","title":"2.2.4 \u6570\u636e\u67e5\u8be2","text":"<p>\u56e0\u4e3a\u6574\u4e2a\u4e0a\u4f20\u4e3a\u5f02\u6b65\u64cd\u4f5c\uff0c\u9700\u8981\u786e\u8ba4\u662f\u5426\u4e0a\u4f20\u6210\u529f\u624d\u53ef\u8fdb\u884c\u540e\u7eed\u64cd\u4f5c\u3002 <pre><code>flow table query --namespace experiment --name breast_hetero_guest\n</code></pre> - \u6570\u636e\u4e0a\u4f20\u6210\u529f\u8fd4\u56de <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"count\": 569,\n        \"data_type\": \"dataframe\",\n        \"engine\": \"standalone\",\n        \"meta\": {},\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\",\n        \"path\": \"xxx\",\n        \"source\": {\n            \"component\": \"dataframe_transformer\",\n            \"output_artifact_key\": \"dataframe_output\",\n            \"output_index\": null,\n            \"party_task_id\": \"202312281606030428210_transformer_0_0_local_0\",\n            \"task_id\": \"202312281606030428210_transformer_0\",\n            \"task_name\": \"transformer_0\"\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"zh/data_access/#3","title":"3. \u6570\u636e\u7ed1\u5b9a","text":"<p>\u5bf9\u4e8e\u7279\u5b9a\u7684\u7b97\u6cd5\uff0c\u53ef\u80fd\u9700\u8981\u7279\u6b8a\u7684\u6570\u636e\u96c6\uff0cFATE Flow\u63d0\u4f9bdata bind\u63a5\u53e3\u6765\u5c06\u6570\u636e\u4f9bFATE\u4f7f\u7528</p> <pre><code>flow table bind --namespace bind_data --name breast_hetero_guest --path /data/projects/fate/fate_flow/data/xxx\n</code></pre>"},{"location":"zh/data_access/#4","title":"4. \u6570\u636e\u67e5\u8be2","text":"<p>\u5bf9\u4e8e\u4e0a\u4f20\u6216\u8005\u7ed1\u5b9a\u7684\u6570\u636e\u8868\uff0c\u53ef\u4ee5\u901a\u8fc7\u67e5\u8be2\u63a5\u53e3\u6765\u83b7\u53d6\u6570\u636e\u7684\u7b80\u7565\u4fe1\u606f</p> <pre><code>flow table query --namespace experiment --name breast_hetero_guest\n</code></pre>"},{"location":"zh/data_access/#5","title":"5. \u6570\u636e\u6e05\u7406","text":"<p>\u53ef\u4ee5\u901a\u8fc7\u6e05\u7406\u63a5\u53e3\u6765\u6e05\u7406\u5df2\u7ecf\u5b58\u5728FATE\u7684\u6570\u636e\u8868</p> <pre><code>flow table delete --namespace experiment --name breast_hetero_guest\n</code></pre>"},{"location":"zh/fate_access/","title":"FATE 2.0 \u7248\u672c\u4e92\u8054\u4e92\u901a\u63a5\u5165\u6307\u5357","text":""},{"location":"zh/fate_access/#1-fate-flow","title":"1. FATE Flow\u63a5\u5165\u6307\u5357","text":"<ul> <li>\u8bf4\u660e\uff1a\u6b64\u7ae0\u8282\u4e3a\u5f02\u6784\u8c03\u5ea6\u5e73\u53f0\u5bf9\u63a5FATE\u8c03\u5ea6\u5e73\u53f0FATE FLow\u7684\u63a5\u5165\u6307\u5357</li> <li>\u573a\u666f\uff1a\u672c\u65b9\u4e3a\u5f85\u63a5\u5165\u7cfb\u7edf\uff0c\u5408\u4f5c\u65b9\u4e3aFATE\u7ad9\u70b9</li> </ul>"},{"location":"zh/fate_access/#11","title":"1.1 \u63a5\u53e3","text":"<p> FATE flow\u63a5\u53e3\u5212\u5206\u4e3a4\u7c7b\uff1a - 1\u8d1f\u8d23\u63a5\u6536\u6765\u81ea\u4e0a\u5c42\u7cfb\u7edf\u7684\u8bf7\u6c42\uff0c\u5982\u63d0\u4ea4\u3001\u505c\u6b62\u3001\u67e5\u8be2\u4f5c\u4e1a\u7b49\uff1b - 2\u8d1f\u8d23\u63a5\u6536\u6765\u81ea\u8c03\u5ea6\u5c42\u7684\u8bf7\u6c42\uff0c\u5982\u5f00\u59cb\u3001\u505c\u6b62\u4efb\u52a1\u7b49\uff1b - 3\u8d1f\u8d23\u63a5\u6536\u6765\u81ea\u7b97\u6cd5\u5bb9\u5668\u7684\u8bf7\u6c42\uff0c\u5982\u4efb\u52a1\u7684\u72b6\u6001\u3001\u8f93\u5165\u4e0a\u62a5\u7b49 - 4\u8d1f\u8d23\u6765\u81ea\u5e73\u53f0\u5c42\u7684\u8bf7\u6c42\uff0c\u5e76\u5206\u53d1\u7ed9\u5404\u4e2a\u53c2\u4e0e\u65b9\u7684\u63a5\u53e32\uff0c\u5982\u521b\u5efa\u4f5c\u4e1a\uff0c\u505c\u6b62\u4f5c\u4e1a\u7b49</p>"},{"location":"zh/fate_access/#111-api-1","title":"1.1.1 api-1","text":"<p>\u8bf4\u660e\uff1a\u7531\u4e8e\u662f\u5bf9\u63a5\u4e0a\u5c42\u7cfb\u7edf\uff0c\u5e76\u4e0d\u6d89\u53ca\u8c03\u5ea6\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0c\u975e\u5fc5\u9700\u63a5\u53e3\uff0c\u53ef\u81ea\u5b9a\u4e49\u5b9e\u73b0\uff0c\u63a5\u53e3\u5c42\u9762\u4e0d\u505a\u7ea6\u675f\u3002</p>"},{"location":"zh/fate_access/#112-api-2","title":"1.1.2 api-2","text":"<p>\u53ef\u53c2\u8003\u63a5\u53e3\u5b9e\u73b0 - <code>/v2/partner/job/create</code>: \u521b\u5efa\u4f5c\u4e1a - <code>/v2/partner/job/start</code>: \u5f00\u59cb\u4f5c\u4e1a - <code>/v2/partner/job/status/update</code>: \u66f4\u65b0\u4f5c\u4e1a\u72b6\u6001 - <code>/v2/partner/job/update</code>: \u66f4\u65b0\u4f5c\u4e1a(\u5982\u8fdb\u5ea6\u4fe1\u606f) - <code>/v2/partner/job/resource/apply</code>: \u7533\u8bf7\u4f5c\u4e1a\u8d44\u6e90 - <code>/v2/partner/job/resource/return</code>: \u5f52\u8fd8\u4f5c\u4e1a\u8d44\u6e90 - <code>/v2/partner/job/stop</code>: \u505c\u6b62\u4f5c\u4e1a - <code>/v2/partner/task/resource/apply</code>: \u7533\u8bf7\u4efb\u52a1\u8d44\u6e90 - <code>/v2/partner/task/resource/return</code>: \u5f52\u8fd8\u4efb\u52a1\u8d44\u6e90 - <code>/v2/partner/task/start</code>: \u5f00\u59cb\u4efb\u52a1 - <code>/v2/partner/task/collect</code>: \u8c03\u5ea6\u5c42\u6536\u96c6\u4efb\u52a1\u72b6\u6001 - <code>/v2/partner/task/status/update</code>: \u66f4\u65b0\u4efb\u52a1\u72b6\u6001 - <code>/v2/partner/task/stop</code>: \u505c\u6b62\u4efb\u52a1 - <code>/v2/partner/task/rerun</code>: \u91cd\u8dd1\u4efb\u52a1</p>"},{"location":"zh/fate_access/#113-api-3","title":"1.1.3 api-3","text":"<p>\u53ef\u53c2\u8003\u63a5\u53e3\u5b9e\u73b0 - <code>/v2/worker/task/status</code>: \u72b6\u6001\u4e0a\u62a5 - <code>/v2/worker/model/save</code>: \u6a21\u578b\u5b58\u50a8 - <code>/v2/worker/model/download</code>: \u6a21\u578b\u4e0b\u8f7d - <code>/v2/worker/data/tracking/query</code>: \u67e5\u8be2\u6570\u636e - <code>/v2/worker/data/tracking/save</code>: \u8bb0\u5f55\u6570\u636e - <code>/v2/worker/metric/save/&lt;execution_id&gt;</code>: \u8bb0\u5f55\u6307\u6807</p>"},{"location":"zh/fate_access/#114-api-4","title":"1.1.4 api-4","text":"<p>\u53ef\u53c2\u8003\u63a5\u53e3\u5b9e\u73b0 - <code>/v2/scheduler/job/create</code>: \u521b\u5efa\u4f5c\u4e1a\u3001 - <code>/v2/scheduler/job/stop</code>: \u505c\u6b62\u4f5c\u4e1a - <code>/v2/scheduler/task/report</code>: \u4efb\u52a1\u4e0a\u62a5(\u5982\u72b6\u6001) - <code>/v2/scheduler/job/rerun</code>: \u91cd\u8dd1\u4f5c\u4e1a</p>"},{"location":"zh/fate_access/#12","title":"1.2 \u8c03\u5ea6\u5668","text":"<p>\u8c03\u5ea6\u5668\u4e3b\u8981\u5305\u62ec\u4e24\u90e8\u5206\uff1a\u8c03\u5ea6\u903b\u8f91\u548c\u8c03\u5ea6\u63a5\u53e3\u3002\u5f02\u6784\u7684\u573a\u666f\u4e0b\u7684\u8c03\u5ea6\u5c42\u60f3\u8981\u5b9e\u73b0\u4e92\u8054\u4e92\u901a\uff0c\u7edf\u4e00\u7684\u8c03\u5ea6\u6d41\u7a0b\u548c\u63a5\u53e3\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u3002\u4e0a\u8ff0\u63d0\u5230\u82e5\u4f7f\u7528FATE Flow\u4f5c\u4e3a\u8c03\u5ea6\u65b9\uff0c\u4e0e\u5176\u5b83\u5382\u5546\u4e92\u8054\u65f6\uff0c\u53ef\u5ffd\u7565\u8c03\u5ea6\u5668\u7684\u5b9e\u73b0\u3002</p>"},{"location":"zh/fate_access/#121","title":"1.2.1 \u65b9\u6848","text":"<p>\u8c03\u5ea6\u7684\u6838\u5fc3\u662f\u8c03\u5ea6\u6d41\u7a0b\uff0c\u6d41\u7a0b\u5b9a\u4e49\u4f5c\u4e1a\u7684\u751f\u547d\u5468\u671f\u3002\u5728FATE 1.x\u7248\u672c\u4e2d\u8c03\u5ea6\u5668\u4e0e\u53d1\u8d77\u65b9\u903b\u8f91\u662f\u7ed1\u5b9a\u7684\uff0c\u5373\u591a\u65b9\u4f5c\u4e1a\u7684\u534f\u8c03\u8c03\u5ea6\u662f\u5728\u53d1\u8d77\u65b9\u3002 \u8fd9\u6837\u6709\u4e2a\u5f0a\u5904\uff1a\u5047\u8bbeA\u3001B\u3001C\u4e09\u5bb6\u5382\u5546\u5404\u81ea\u90fd\u6709\u53d1\u8d77\u4efb\u52a1\u7684\u9700\u6c42\uff0c\u4ed6\u4eec\u7684\u8c03\u5ea6\u5c42\u90fd\u9700\u8981\u57fa\u4e8e\u76f8\u540c\u7684\u8c03\u5ea6\u903b\u8f91\u5b9e\u73b0\u8c03\u5ea6\u5668\uff0c\u4e92\u8054\u4e92\u901a\u7684\u6210\u672c\u8f83\u9ad8\u3002 \u57282.0\u7248\u672c\u4e2d\uff0c\u5c06\u8c03\u5ea6\u6a21\u5757\u4e2d\u7684\u53d1\u8d77\u65b9\u4e0e\u8c03\u5ea6\u65b9\u903b\u8f91\u89e3\u8026\uff0c\u4e14\u8c03\u5ea6\u65b9\u53ef\u4ee5\u5728\u4f5c\u4e1a\u914d\u7f6e\u4e2d\u88ab\u6307\u5b9a\u3002\u5728\u4e0a\u8bc9\u7684\u6848\u4f8b\u4e2d\uff0c\u53ea\u8981A\u3001B\u3001C\u5382\u5546\u4e2d\u7684\u4efb\u610f\u4e00\u5bb6\u5b9e\u73b0\u4e86\u8c03\u5ea6\u5668\uff0c \u6216\u8005\u76f4\u63a5\u4f7f\u7528FATE\u4f5c\u4e3a\u8c03\u5ea6\u65b9\uff0c\u5176\u4ed6\u5382\u5546\u53ea\u9700\u8981\u5b9e\u73b0\u8c03\u5ea6\u5ba2\u6237\u7aef\u63a5\u53e3\uff0c\u5373\u53ef\u6ee1\u8db3\u9700\u6c42\uff0c\u5927\u5927\u964d\u4f4e\u4e92\u8054\u4e92\u901a\u6210\u672c\u3002</p> <p></p> <p>P\u4ee3\u8868\u8c03\u5ea6\u5ba2\u6237\u7aef\u63a5\u53e3\uff0cS\u4ee3\u8868\u8c03\u5ea6\u5668\u63a5\u53e3</p> <p>\u4e3e\u4e2a\u4f8b\u5b50\u7b80\u5355\u8bf4\u660e\u4e0b\u8be5\u8c03\u5ea6\u6a21\u5f0f\uff1a\u5047\u8bbeA\u60f3\u8981\u548cC\u521b\u5efa\u4f5c\u4e1a\uff0c\u8c03\u5ea6\u65b9\u4e3aFATE Flow\u3002\u9996\u5148A\u8bf7\u6c42FATE-FLow S(create-job)\u63a5\u53e3, FATE FLow\u6536\u5230\u8bf7\u6c42\u540e\u901a\u8fc7job\u914d\u7f6e\u83b7\u53d6\u53c2\u4e0e\u65b9\u4fe1\u606f(A\u3001C)\uff0c\u968f\u5373\u5206\u53d1\u7ed9\u53c2\u4e0e\u65b9\u5404\u81ea\u7684P(create-job)\u63a5\u53e3\u3002</p>"},{"location":"zh/fate_access/#122","title":"1.2.2 \u8c03\u5ea6\u903b\u8f91","text":"<p>\u5bf9\u4f5c\u4e1a\u7684\u751f\u547d\u5468\u671f\u7ba1\u7406\uff0c\u4e3b\u8981\u5305\u62ec\u4f5c\u4e1a\u4f55\u65f6\u542f\u505c\u3001\u4efb\u52a1\u4f55\u65f6\u542f\u505c\u3001DAG\u89e3\u6790\u3001\u7ec4\u4ef6\u8fd0\u884c\u4f9d\u8d56\u7b49\u7b49\u3002FATE FLow\u7684\u8c03\u5ea6\u6d41\u7a0b\u6309\u4efb\u52a1\u72b6\u6001\u83b7\u53d6\u6a21\u5f0f\u5206\u4e3a\u4e24\u79cd:  callback\u548cpoll\u3002\u5176\u4e2dcallback\u6a21\u5f0f\u662f\u7531\u5404\u53c2\u4e0e\u65b9\u4e3b\u52a8\u4e0a\u62a5\u4efb\u52a1\u72b6\u6001\u7ed9\u8c03\u5ea6\u65b9\uff0cpoll\u6a21\u5f0f\u662f\u8c03\u5ea6\u65b9\u5b9a\u65f6\u5411\u5404\u53c2\u4e0e\u65b9\u62c9\u53d6\u4efb\u52a1\u72b6\u6001\u3002 \u4e24\u79cd\u6a21\u5f0f\u5bf9\u5e94\u7684\u8c03\u5ea6\u6d41\u7a0b\u56fe\u5982\u4e0b\uff1a</p> <p></p> <p>callback\u6a21\u5f0f</p> <p></p> <p>poll\u6a21\u5f0f</p>"},{"location":"zh/fate_access/#123","title":"1.2.3 \u8c03\u5ea6\u63a5\u53e3","text":"<p>\u8d1f\u8d23\u6765\u81ea\u5e73\u53f0\u5c42\u7684\u8bf7\u6c42\uff0c\u5e76\u5206\u53d1\u7ed9\u5404\u4e2a\u53c2\u4e0e\u65b9\u7684api-2\uff0c\u5982\u521b\u5efa\u4f5c\u4e1a\uff0c\u505c\u6b62\u4f5c\u4e1a\u7b49\u3002\u63a5\u53e3\u89c1api-4</p>"},{"location":"zh/fate_access/#2","title":"2 \u7b97\u6cd5\u63a5\u5165\u6307\u5357","text":"<p>\u5728FATE \u5386\u53f2\u7248\u672c\u4e2d\uff0c\u7b97\u6cd5\u662f\u4ee5\u8c03\u5ea6\u670d\u52a1\u542f\u52a8\u7684\u672c\u5730\u8fdb\u7a0b\u65b9\u5f0f\u8fd0\u884c\uff0c\u5728\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5f88\u96be\u6ee1\u8db3\u4e92\u8054\u4e92\u901a\u7684\u9700\u6c42\u3002\u57282.0\u7248\u672c\u4e2d\u91c7\u7528\u201c\u7b97\u6cd5\u5bb9\u5668\u201d\u8fd0\u884c\u7b97\u6cd5\uff0c \u901a\u8fc7\u5236\u5b9a\u7edf\u4e00\u7684\u7b97\u6cd5\u955c\u50cf\u6784\u5efa\u6807\u51c6\u4e0e\u5b9a\u4e49\u4e00\u5957\u89c4\u8303\u7684\u955c\u50cf\u52a0\u8f7d\u673a\u5236\u6765\u5b9e\u73b0\u5f02\u6784\u7b97\u6cd5\u8c03\u5ea6\u529f\u80fd\u3002 </p>"},{"location":"zh/fate_access/#21-fate","title":"2.1 FATE\u7b97\u6cd5\u5bb9\u5668\u5316\u65b9\u6848","text":"<ul> <li>\u524d\u5904\u7406: \u6570\u636e\u3001\u6a21\u578b\u3001\u7b97\u6cd5\u53c2\u6570\u7b49\u8f93\u5165\u5904\u7406\uff0c\u4f1a\u8c03\u7528\u5e73\u53f0\u5c42\u63a5\u53e3api-3\u4ece\u5e73\u53f0\u83b7\u53d6\u76f8\u5173\u4f9d\u8d56</li> <li>\u7ec4\u4ef6\u8fd0\u884c: \u7b97\u6cd5\u7ec4\u4ef6\u903b\u8f91</li> <li>\u540e\u5904\u7406: \u7b97\u6cd5\u7ec4\u4ef6\u8f93\u51fa\u5185\u5bb9\u5904\u7406\uff0c\u4f1a\u8c03\u7528\u5e73\u53f0\u5c42\u63a5\u53e3api-3\u5c06\u8f93\u51fa\u4e0a\u4f20\u5230\u5e73\u53f0 </li> </ul>"},{"location":"zh/fate_access/#22","title":"2.2 \u63a5\u5165","text":""},{"location":"zh/fate_access/#221","title":"2.2.1 \u7b97\u6cd5\u53c2\u6570","text":"<p>FATE FLow\u4f1a\u4ee5\u73af\u5883\u53d8\u91cf\u7684\u5f62\u5f0f\u5c06\u53c2\u6570\u4f20\u9012\u7ed9\u7b97\u6cd5\u5bb9\u5668\uff0c\u73af\u5883\u53d8\u91cf\u7684key\u4e3a\"CONFIG\"\uff0c\u53c2\u6570\u503c\u4e3aJSON\u5b57\u7b26\u4e32\u3002\u5185\u5bb9\u5982\u4e0b\uff1a <pre><code>component: psi\ncomputing_partitions: 8\nconf:\n  computing:\n    metadata:\n      computing_id: 202402271112016150790_psi_0_0_host_9998\n      host\uff1a127.0.0.1\n      port:4670\n    type: standalone/eggroll/spark\n  device:\n    metadata: {}\n    type: CPU\n  federation:\n    metadata:\n      federation_id: 202402271112016150790_psi_0_0\n      parties:\n        local:\n          partyid: '9998'\n          role: host\n        parties:\n        - partyid: '9999'\n          role: guest\n        - partyid: '9998'\n          role: host\n      osx_config:\n        host: 127.0.01\n        port: 9370\n    type: osx\n  logger:\n    config:\n  storage: standalone/eggroll/hdfs\nengine_run:\n  cores: 4\ninput_artifacts:\n  data:\n    input_data:\n      output_artifact_key: output_data\n      output_artifact_type_alias: null\n      parties:\n      - party_id:\n        - '9998'\n        role: host\n      producer_task: reader_0\n  model: null\njob_id: '202402271112016150790'\nlauncher_conf: {}\nlauncher_name: default\nmlmd:\n  metadata:\n    api_version: v2\n    host: 127.0.0.1\n    port: 9380\n    protocol: http\n  type: flow\nmodel_id: '202402271112016150790'\nmodel_version: '0'\nparameters: {}\nparty_id: '9998'\nparty_task_id: 202402271112016150790_psi_0_0_host_9998\nprovider_name: fate\nrole: host\nstage: default\ntask_id: 202402271112016150790_psi_0\ntask_name: psi_0\ntask_version: '0'\n</code></pre> \u5176\u4e2d\uff0c\u5173\u952e\u7684\u914d\u7f6e\u4e3a\uff1a - component\uff1a\u7b97\u6cd5\u540d\u3002\u591a\u4e2a\u7b97\u6cd5\u6253\u5305\u5728\u540c\u4e00\u4e2a\u955c\u50cf\u65f6\u53ef\u901a\u8fc7\u8be5\u53c2\u6570\u6807\u8bc6 - conf.computing: \u4e3a\u8ba1\u7b97\u5f15\u64ce\u914d\u7f6e - conf.federation: \u4e3a\u901a\u4fe1\u5f15\u64ce\u914d\u7f6e - conf.storage: \u4e3a\u5b58\u50a8\u5f15\u64ce\u914d\u7f6e\uff0c\u652f\u6301standalone/eggroll\u548chdfs - mlmd: \u4e3a\u5e73\u53f0\u5c42\u63a5\u53e3\uff0c\u4f9b\u7b97\u6cd5\u7684\u8f93\u51fa\u8bb0\u5f55\u4f7f\u7528\u3002\u63a5\u53e3\u4e3aapi-3 - input_artifacts\uff1a\u8f93\u5165\u4f9d\u8d56\uff0c\u5305\u62ec\u6570\u636e\u3001\u6a21\u578b\u7b49 - parameters\uff1a\u7b97\u6cd5\u53c2\u6570 \u7b97\u6cd5\u7684\u542f\u52a8\u5165\u53e3\u9700\u8981\u5728\u6253\u955c\u50cf\u65f6\u6307\u5b9aCMD\uff0c\u7b97\u6cd5\u7ed3\u675f\u9700\u8981\u8c03\u7528api-3\u4e2d\u7684\u72b6\u6001\u4e0a\u62a5\u63a5\u53e3</p>"},{"location":"zh/fate_access/#222","title":"2.2.2 \u6ce8\u518c\u7b97\u6cd5\u955c\u50cf","text":"<p><pre><code>flow provider register -c examples/provider/register_image.json\n</code></pre> \u5176\u4e2d\uff0cregister_image.json\u5982\u4e0b\uff1a <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"docker\",\n  \"version\": \"2.1.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"federatedai/fate:2.1.0\"\n  }\n}\n</code></pre></p>"},{"location":"zh/fate_access/#223","title":"2.2.3 \u4f7f\u7528\u7b97\u6cd5\u955c\u50cf","text":"<p>\u6ce8\u518c\u5b8c\u6210\u540e\uff0c\u5728\u4f5c\u4e1a\u914d\u7f6e\u7684DAG\u4e2d\u53ef\u4ee5\u6307\u5b9aprovider\u6765\u8fd0\u884c\u6b64fate\u7b97\u6cd5\u955c\u50cf\uff0c\u53c2\u8003\u5982\u4e0b\uff1a <pre><code>dag:\n  conf:\n    task:\n      provider: fate:2.1.0@docker\n</code></pre> \u6216\u8005\u4f60\u4e5f\u53ef\u4ee5\u6307\u5b9a\u5355\u4e2a\u7b97\u6cd5\u4f7f\u7528\u6b64\u955c\u50cf\uff0c\u8be6\u7ec6\u53ef\u53c2\u8003provider\u6307\u5357</p>"},{"location":"zh/fate_flow/","title":"\u6574\u4f53\u8bbe\u8ba1","text":""},{"location":"zh/fate_flow/#1","title":"1. \u8bbe\u8ba1\u67b6\u6784\u56fe","text":"<p> - \u5e94\u7528\u5c42\u63a5\u53e3\uff1a\u4f9b\u5982fate-board\u3001fate-client\u7b49\u4e0a\u5c42\u4f7f\u7528 - \u4e92\u8054\u4e92\u901a\u5c42\u63a5\u53e3\uff1a\u5206\u4e3a\u8c03\u5ea6\u5668\u63a5\u53e3\u548c\u53c2\u4e0e\u65b9\u63a5\u53e3\uff0c\u8c03\u5ea6\u5668\u63a5\u53e3\u7528\u4e8e\u63a5\u6536\u5982\u521b\u5efa\u3001\u505c\u6b62\u7b49\u8c03\u5ea6\u547d\u4ee4\u5e76\u4e0b\u53d1\u7ed9\u53c2\u4e0e\u65b9\uff0c\u53c2\u4e0e\u65b9\u63a5\u53e3\u7528\u4e8e\u5404\u53c2\u4e0e\u65b9\u63a5\u6536\u5982\u521b\u5efa\u3001\u8fd0\u884c\u3001\u505c\u6b62\u7b49\u547d\u4ee4\u5e76\u6267\u884c - \u5e95\u5ea7\u63a5\u53e3\uff1a \u7528\u4e8e\u63a5\u6536\u7b97\u6cd5\u5bb9\u5668\u4e0a\u62a5\u7684\u72b6\u6001\u7b49 - \u8c03\u5ea6\u5668\uff1a\u8054\u90a6\u8c03\u5ea6\u903b\u8f91\uff0c\u89e3\u6790DSL\u4f9d\u8d56\u53ca\u8fd0\u884c\u76f8\u5173\u7684\u4f5c\u4e1a\u53ca\u4efb\u52a1 - \u7b97\u6cd5\u5bb9\u5668\uff1a\u662f\u7b97\u6cd5\u8fd0\u884c\u7684\u73af\u5883\uff0cFATE Flow\u652f\u6301\u7b97\u6cd5\u8fd0\u884c\u5728\u672c\u5730\u8fdb\u7a0b\u3001\u7b97\u6cd5\u5bb9\u5668\u4e2d\uff0c\u5176\u8fd0\u884c\u65b9\u5f0f\u7c7b\u4f3c\u3002 - \u5e73\u53f0\u8d44\u6e90\u6c60\uff1a \u62bd\u8c61\u8ba1\u7b97\u3001\u901a\u4fe1\u3001\u5b58\u50a8API</p>"},{"location":"zh/fate_flow/#2","title":"2. \u6574\u4f53\u67b6\u6784","text":""},{"location":"zh/fate_flow/#21-fate","title":"2.1 FATE\u6574\u4f53\u67b6\u6784","text":""},{"location":"zh/fate_flow/#22-fate-flow","title":"2.2 FATE Flow\u529f\u80fd\u67b6\u6784","text":""},{"location":"zh/fate_flow/#23-fate-flow","title":"2.3 FATE Flow\u96c6\u7fa4\u67b6\u6784","text":""},{"location":"zh/fate_flow/#3","title":"3. \u8c03\u5ea6\u67b6\u6784","text":""},{"location":"zh/fate_flow/#31","title":"3.1 \u57fa\u4e8e\u5171\u4eab\u72b6\u6001\u7684\u8c03\u5ea6\u67b6\u6784","text":"<ul> <li>\u5265\u79bb\u72b6\u6001(\u8d44\u6e90\u3001\u4f5c\u4e1a)\u4e0e\u7ba1\u7406\u5668(\u8c03\u5ea6\u5668\u3001\u8d44\u6e90\u7ba1\u7406\u5668)</li> <li>\u8d44\u6e90\u72b6\u6001\u4e0e\u4f5c\u4e1a\u72b6\u6001\u6301\u4e45\u5316\u5b58\u4e8eMySQL\uff0c\u5168\u5c40\u5171\u4eab\uff0c\u63d0\u4f9b\u53ef\u9760\u4e8b\u52a1\u6027\u64cd\u4f5c</li> <li>\u63d0\u9ad8\u7ba1\u7406\u670d\u52a1\u7684\u9ad8\u53ef\u7528\u4e0e\u6269\u5c55\u6027</li> <li>\u4f5c\u4e1a\u53ef\u4ecb\u5165\uff0c\u652f\u6301\u5b9e\u73b0\u5982\u91cd\u542f\u3001\u91cd\u8dd1\u3001\u5e76\u884c\u63a7\u5236\u3001\u8d44\u6e90\u9694\u79bb\u7b49</li> </ul>"},{"location":"zh/fate_flow/#32","title":"3.2 \u72b6\u6001\u9a71\u52a8\u8c03\u5ea6","text":"<ul> <li>\u5357\u5317\u5411\u72b6\u6001\u4e0a\u62a5/\u67e5\u8be2</li> <li>\u4e1c\u897f\u5411\u591a\u65b9\u4efb\u52a1\u72b6\u6001\u8ba1\u7b97\u8054\u90a6\u4efb\u52a1\u72b6\u6001</li> <li>\u4e0a\u4e0b\u6e38\u4efb\u52a1\u72b6\u6001\u8ba1\u7b97\u4f5c\u4e1a\u4f5c\u6001</li> </ul>"},{"location":"zh/fate_flow/#321-callback","title":"3.2.1 callback\u56de\u8c03\u6a21\u5f0f","text":"<p>\u8c03\u5ea6\u5668\u521b\u5efa\u4f5c\u4e1a\u548c\u4efb\u52a1\uff0c\u7531\u5404\u53c2\u4e0e\u65b9\u4e3b\u52a8\u56de\u8c03\u4f5c\u4e1a\u6216\u4efb\u52a1\u7684\u72b6\u6001</p> <p></p>"},{"location":"zh/fate_flow/#322-poll","title":"3.2.2 poll\u8f6e\u8be2\u6a21\u5f0f","text":"<p>\u8c03\u5ea6\u5668\u4e0d\u4ec5\u9700\u521b\u5efa\u4f5c\u4e1a\u548c\u4efb\u52a1\uff0c\u5728\u8c03\u5ea6\u8fc7\u7a0b\u4e2d\u4f1a\u8f6e\u8be2\u53c2\u4e0e\u65b9\u7684\u4f5c\u4e1a\u6216\u4efb\u52a1\u7684\u72b6\u6001</p> <p></p>"},{"location":"zh/fate_flow/#34","title":"3.4 \u7b97\u6cd5\u7ec4\u4ef6\u8c03\u5ea6","text":"<ul> <li>\u524d\u5904\u7406: \u6570\u636e\u3001\u6a21\u578b\u3001\u7b97\u6cd5\u53c2\u6570\u7b49\u8f93\u5165\u5904\u7406</li> <li>\u7ec4\u4ef6\u8fd0\u884c: \u7b97\u6cd5\u7ec4\u4ef6\u903b\u8f91</li> <li>\u540e\u5904\u7406: \u7b97\u6cd5\u7ec4\u4ef6\u8f93\u51fa\u5185\u5bb9\u5904\u7406 </li> </ul>"},{"location":"zh/fate_flow/#4","title":"4. \u591a\u65b9\u8d44\u6e90\u534f\u8c03","text":"<ul> <li>\u6bcf\u4e2a\u5f15\u64ce\u603b\u8d44\u6e90\u5927\u5c0f\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u914d\u7f6e\uff0c\u540e\u7eed\u5b9e\u73b0\u7cfb\u7edf\u5bf9\u63a5</li> <li>\u603b\u8d44\u6e90\u5927\u5c0f\u4e2d\u7684cores\u8868\u793a\u6bcf\u4e2a\u8ba1\u7b97\u8282\u70b9cpu\u6838\u6570</li> <li>FATEFlow server\u542f\u52a8\u65f6\u4ece\u914d\u7f6e\u6587\u4ef6\u8bfb\u53d6\u8d44\u6e90\u5927\u5c0f\u914d\u7f6e\uff0c\u5e76\u6ce8\u518c\u66f4\u65b0\u5230\u6570\u636e\u5e93</li> <li>\u4ee5Job\u7ef4\u5ea6\u7533\u8bf7\u8d44\u6e90\uff0cJob Conf\u63d0\u4ea4\u65f6\u751f\u6548</li> </ul>"},{"location":"zh/fate_flow/#5","title":"5. \u4f5c\u4e1a\u5b9e\u65f6\u76d1\u6d4b","text":"<ul> <li>\u5de5\u4f5c\u8fdb\u7a0b\u5b58\u6d3b\u6027\u68c0\u6d4b</li> <li>\u4f5c\u4e1a\u8d85\u65f6\u68c0\u6d4b</li> <li>\u8d44\u6e90\u56de\u6536\u68c0\u6d4b</li> <li>\u57fa\u7840\u5f15\u64ce\u4f1a\u8bdd\u8d85\u65f6\u68c0\u6d4b</li> </ul>"},{"location":"zh/fate_flow/#6","title":"6. \u4efb\u52a1\u7ec4\u4ef6\u4e2d\u5fc3","text":""},{"location":"zh/fate_flow/#7","title":"7. \u6570\u636e\u63a5\u5165","text":""},{"location":"zh/job_scheduling/","title":"\u591a\u65b9\u8054\u5408\u4f5c\u4e1a","text":""},{"location":"zh/job_scheduling/#1","title":"1. \u8bf4\u660e","text":"<p>\u4e3b\u8981\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528<code>FATE Flow</code>\u8054\u90a6\u5b66\u4e60\u4f5c\u4e1a\u7684\u5b9a\u4e49</p>"},{"location":"zh/job_scheduling/#2-dag","title":"2. DAG\u5b9a\u4e49","text":"<p>FATE 2.0\u91c7\u7528\u5168\u65b0DAG\u5b9a\u4e49\u4e00\u4e2a\u4f5c\u4e1a\uff0c\u5305\u542b\u5404\u4e2a\u7ec4\u4ef6\u7684\u4e0a\u4e0b\u4f9d\u8d56\u5173\u7cfb</p>"},{"location":"zh/job_scheduling/#3","title":"3. \u4f5c\u4e1a\u529f\u80fd\u914d\u7f6e","text":""},{"location":"zh/job_scheduling/#31","title":"3.1 \u9884\u6d4b","text":"<p><pre><code>dag:\n  conf:\n    model_warehouse:                        \n      model_id: '202307171452088269870'      \n      model_version: '0'                    \n</code></pre> \u5728dag.conf.model_warehouse\u4e2d\u5b9a\u4e49\u9884\u6d4b\u4efb\u52a1\u4f9d\u8d56\u7684\u6a21\u578b\u4fe1\u606f\uff0c\u5728\u7b97\u6cd5\u4e2d\u5c06\u4f7f\u7528\u6b64\u6a21\u578b\u8fdb\u884c\u9884\u6d4b</p>"},{"location":"zh/job_scheduling/#32-job","title":"3.2 job\u7ee7\u627f","text":"<p><pre><code>dag:\n  conf:\n    inheritance:                  \n      job_id: \"202307041704214920920\"  \n      task_list: [\"reader_0\"]         \n</code></pre> \u5728job.conf.inheritance\u4e2d\u586b\u5165\u9700\u8981\u7ee7\u627f\u7684job\u548c\u7b97\u6cd5\u7ec4\u4ef6\u540d\uff0c\u65b0\u542f\u52a8\u7684job\u5c06\u76f4\u63a5\u590d\u7528\u8fd9\u4e9b\u7ec4\u4ef6\u7684\u8f93\u51fa</p>"},{"location":"zh/job_scheduling/#33","title":"3.3 \u6307\u5b9a\u8c03\u5ea6\u65b9","text":"<p><pre><code>dag:\n  conf:\n    scheduler_party_id: \"9999\"   \n</code></pre> \u5728job.conf.scheduler_party_id\u4e2d\u53ef\u6307\u5b9a\u8c03\u5ea6\u65b9\u4fe1\u606f\uff0c\u82e5\u4e0d\u6307\u5b9a\u5219\u7531\u53d1\u8d77\u65b9\u5145\u5f53\u8c03\u5ea6\u65b9</p>"},{"location":"zh/job_scheduling/#34","title":"3.4 \u6307\u5b9a\u4f5c\u4e1a\u4f18\u5148\u7ea7","text":"<p><pre><code>dag:\n  conf:\n    priority: 2\n</code></pre> \u5728job.conf.priority\u4e2d\u6307\u5b9a\u4efb\u52a1\u7684\u8c03\u5ea6\u6743\u91cd\uff0c\u6570\u503c\u8d8a\u5927\uff0c\u4f18\u5148\u7ea7\u8d8a\u9ad8</p>"},{"location":"zh/job_scheduling/#35","title":"3.5 \u5931\u8d25\u81ea\u52a8\u91cd\u8bd5","text":"<p><pre><code>dag:\n  conf:\n    auto_retries: 2\n</code></pre> \u5728job.conf.auto_retries\u4e2d\u6307\u5b9a\u4efb\u52a1\u5931\u8d25\u91cd\u8bd5\u6b21\u6570\uff0c\u9ed8\u8ba4\u4e3a0\u3002</p>"},{"location":"zh/job_scheduling/#36","title":"3.6 \u8d44\u6e90\u6570","text":"<p><pre><code>dag:\n  conf:\n    cores: 4\n  task:\n    engine_run:\n      cores: 2\n</code></pre> - \u5176\u4e2d, dag.conf.cores\u4e3a\u6574\u4e2ajob\u7684\u5206\u914d\u8d44\u6e90\u6570(job_cores)\uff0cdag.conf.engine_run.cores\u4e3atask\u7684\u5206\u914d\u8d44\u6e90\u6570(task_cores)\u3002\u82e5\u4ee5\u6b64\u914d\u7f6e\u542f\u52a8job\uff0c\u5176\u6700\u5927\u5e76\u884c\u5ea6\u4e3a2\u3002 - task\u5e76\u884c\u5ea6 = job_cores / task_cores</p>"},{"location":"zh/job_scheduling/#37","title":"3.7 \u4efb\u52a1\u8d85\u65f6\u65f6\u95f4","text":"<p><pre><code>dag:\n  task:\n    timeout: 3600 # s\n</code></pre> \u5728dag.task.timeout\u4e2d\u6307\u5b9atask\u7684\u8d85\u65f6\u65f6\u95f4\u3002\u5f53\u4efb\u52a1\u5728\u8fbe\u5230\u8d85\u65f6\u65f6\u95f4\u8fd8\u5904\u4e8erunning\u72b6\u6001\u65f6\uff0c\u4f1a\u89e6\u53d1\u81ea\u52a8kill job\u64cd\u4f5c</p>"},{"location":"zh/job_scheduling/#38-provider","title":"3.8 \u4efb\u52a1provider","text":"<p><pre><code>dag:\n  task:\n    provider: fate:2.0.1@local\n</code></pre> \u5728dag.task.provider\u4e2d\u6307\u5b9atask\u7684\u7b97\u6cd5\u63d0\u4f9b\u8005\u3001\u7248\u672c\u53f7\u548c\u8fd0\u884c\u6a21\u5f0f</p>"},{"location":"zh/job_scheduling/#4","title":"4. \u8f93\u5165","text":"<p>\u63cf\u8ff0 \u4e0a\u6e38\u8f93\u5165\uff0c\u5206\u4e3a\u4e24\u79cd\u8f93\u5165\u7c7b\u578b\uff0c\u5206\u522b\u662f\u6570\u636e\u548c\u6a21\u578b\u3002</p>"},{"location":"zh/job_scheduling/#41","title":"4.1 \u6570\u636e\u8f93\u5165","text":"<ul> <li> <p>\u4f5c\u4e3a\u7ec4\u4ef6\u7684\u53c2\u6570\u8f93\u5165 <pre><code>dag:\n  party_tasks:\n    guest_9999:\n      tasks:\n        reader_0:\n          parameters:\n            name: breast_hetero_guest\n            namespace: experiment\n    host_9998:\n      tasks:\n        reader_0:\n          parameters:\n            name: breast_hetero_host\n            namespace: experiment\n</code></pre> reader\u7ec4\u4ef6\u652f\u6301\u76f4\u63a5\u4f20\u5165\u67d0\u4efdfate\u6570\u636e\u8868\u4f5c\u4e3ajob\u7ea7\u7684\u6570\u636e\u8f93\u5165\u3002</p> </li> <li> <p>\u67d0\u4e2a\u7ec4\u4ef6\u8f93\u5165\u53e6\u5916\u4e00\u4e2a\u7ec4\u4ef6\u7684\u8f93\u51fa <pre><code>dag:\n  tasks:\n    binning_0:\n      component_ref: hetero_feature_binning\n      inputs:\n        data:\n          train_data:\n            task_output_artifact:\n              output_artifact_key: train_output_data\n              producer_task: scale_0\n</code></pre> binning_0\u4f9d\u8d56scale_0\u7684\u8f93\u51fa\u6570\u636etrain_output_data</p> </li> </ul>"},{"location":"zh/job_scheduling/#42","title":"4.2 \u6a21\u578b\u8f93\u5165","text":"<ul> <li>model warehouse <pre><code>dag:\n  conf:\n    model_warehouse:                        \n      model_id: '202307171452088269870'      \n      model_version: '0'  \n  tasks:\n    selection_0:\n      component_ref: hetero_feature_selection\n      dependent_tasks:\n      - scale_0\n        model:\n          input_model:\n            model_warehouse:\n              output_artifact_key: train_output_model\n              producer_task: selection_0\n</code></pre></li> </ul>"},{"location":"zh/job_scheduling/#5","title":"5. \u8f93\u51fa","text":"<p>\u4f5c\u4e1a\u7684\u8f93\u51fa\u5305\u62ec\u6570\u636e\u3001\u6a21\u578b\u548c\u6307\u6807</p>"},{"location":"zh/job_scheduling/#51","title":"5.1 \u8f93\u51fa\u6307\u6807","text":""},{"location":"zh/job_scheduling/#_2","title":"\u67e5\u8be2\u6307\u6807","text":"<p>\u67e5\u8be2\u8f93\u51fa\u6307\u6807\u547d\u4ee4\uff1a <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code> - \u8f93\u5165\u5185\u5bb9\u5982\u4e0b <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"zh/job_scheduling/#52","title":"5.2 \u8f93\u51fa\u6a21\u578b","text":""},{"location":"zh/job_scheduling/#_3","title":"\u67e5\u8be2\u6a21\u578b","text":"<p><pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code> - \u67e5\u8be2\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"output_model\": {\n            \"data\": {\n                \"estimator\": {\n                    \"end_epoch\": 10,\n                    \"is_converged\": false,\n                    \"lr_scheduler\": {\n                        \"lr_params\": {\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100\n                        },\n                        \"lr_scheduler\": {\n                            \"_get_lr_called_within_step\": false,\n                            \"_last_lr\": [\n                                0.07269999999999996\n                            ],\n                            \"_step_count\": 10,\n                            \"base_lrs\": [\n                                0.1\n                            ],\n                            \"end_factor\": 1.0,\n                            \"last_epoch\": 9,\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100,\n                            \"verbose\": false\n                        },\n                        \"method\": \"linear\"\n                    },\n                    \"optimizer\": {\n                        \"alpha\": 0.001,\n                        \"l1_penalty\": false,\n                        \"l2_penalty\": true,\n                        \"method\": \"sgd\",\n                        \"model_parameter\": [\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ]\n                        ],\n                        \"model_parameter_dtype\": \"float32\",\n                        \"optim_param\": {\n                            \"lr\": 0.1\n                        },\n                        \"optimizer\": {\n                            \"param_groups\": [\n                                {\n                                    \"dampening\": 0,\n                                    \"differentiable\": false,\n                                    \"foreach\": null,\n                                    \"initial_lr\": 0.1,\n                                    \"lr\": 0.07269999999999996,\n                                    \"maximize\": false,\n                                    \"momentum\": 0,\n                                    \"nesterov\": false,\n                                    \"params\": [\n                                        0\n                                    ],\n                                    \"weight_decay\": 0\n                                }\n                            ],\n                            \"state\": {}\n                        }\n                    },\n                    \"param\": {\n                        \"coef_\": [\n                            [\n                                -0.10828543454408646\n                            ],\n                            [\n                                -0.07341302931308746\n                            ],\n                            [\n                                -0.10850320011377335\n                            ],\n                            [\n                                -0.10066638141870499\n                            ],\n                            [\n                                -0.04595951363444328\n                            ],\n                            [\n                                -0.07001449167728424\n                            ],\n                            [\n                                -0.08949052542448044\n                            ],\n                            [\n                                -0.10958756506443024\n                            ],\n                            [\n                                -0.04012322425842285\n                            ],\n                            [\n                                0.02270071767270565\n                            ],\n                            [\n                                -0.07198350876569748\n                            ],\n                            [\n                                0.00548586156219244\n                            ],\n                            [\n                                -0.06599288433790207\n                            ],\n                            [\n                                -0.06410090625286102\n                            ],\n                            [\n                                0.016374297440052032\n                            ],\n                            [\n                                -0.01607361063361168\n                            ],\n                            [\n                                -0.011447405442595482\n                            ],\n                            [\n                                -0.04352564364671707\n                            ],\n                            [\n                                0.013161249458789825\n                            ],\n                            [\n                                0.013506329618394375\n                            ]\n                        ],\n                        \"dtype\": \"float32\",\n                        \"intercept_\": null\n                    }\n                }\n            },\n            \"meta\": {\n                \"batch_size\": null,\n                \"epochs\": 10,\n                \"init_param\": {\n                    \"fill_val\": 0.0,\n                    \"fit_intercept\": false,\n                    \"method\": \"zeros\",\n                    \"random_state\": null\n                },\n                \"label_count\": false,\n                \"learning_rate_param\": {\n                    \"method\": \"linear\",\n                    \"scheduler_params\": {\n                        \"start_factor\": 0.7,\n                        \"total_iters\": 100\n                    }\n                },\n                \"optimizer_param\": {\n                    \"alpha\": 0.001,\n                    \"method\": \"sgd\",\n                    \"optimizer_params\": {\n                        \"lr\": 0.1\n                    },\n                    \"penalty\": \"l2\"\n                },\n                \"ovr\": false\n            }\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"zh/job_scheduling/#_4","title":"\u4e0b\u8f7d\u6a21\u578b","text":"<p><pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> - <code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code> - \u4e0b\u8f7d\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre></p>"},{"location":"zh/job_scheduling/#53","title":"5.3 \u8f93\u51fa\u6570\u636e","text":""},{"location":"zh/job_scheduling/#_5","title":"\u67e5\u8be2\u6570\u636e\u8868","text":"<p><pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> - \u67e5\u8be2\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"zh/job_scheduling/#_6","title":"\u9884\u89c8\u6570\u636e","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code></p>"},{"location":"zh/job_scheduling/#_7","title":"\u4e0b\u8f7d\u6570\u636e","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> - <code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code> - \u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"zh/provider_register/","title":"\u7ec4\u4ef6\u6ce8\u518c\u4e2d\u5fc3","text":""},{"location":"zh/provider_register/#1","title":"1. \u8bf4\u660e","text":"<p>FATE Flow\u8bbe\u8ba1\u4e86\u7b97\u6cd5\u7ec4\u4ef6\u6ce8\u518c\u6a21\u5757\uff0c\u4ee5\u652f\u6301\u591a\u4e2a\u7b97\u6cd5\u5f00\u53d1\u5382\u5546\u3001\u591a\u4e2a\u7248\u672c\u53ca\u591a\u79cd\u8fd0\u884c\u6a21\u5f0f\u3002</p>"},{"location":"zh/provider_register/#2-provider","title":"2. provider","text":"<p>\u5b9a\u4e49\uff1a <code>$name:$version@device</code>, \u5982<code>fate:2.0.0@local</code> - name\uff1a \u7b97\u6cd5\u63d0\u4f9b\u5382\u5546 - version: \u7b97\u6cd5\u7248\u672c - device: \u7b97\u6cd5\u8fd0\u884c\u6a21\u5f0f\uff0c\u5982: docker, k8s, local\u7b49</p>"},{"location":"zh/provider_register/#21","title":"2.1 \u6ce8\u518c","text":"<ul> <li>\u6ce8\u518c\u547d\u4ee4\uff1a</li> </ul> <p><pre><code>flow provider register -c examples/provider/register.json\n</code></pre> - \u6ce8\u518c\u672c\u5730\u7684\u7b97\u6cd5\u5305\uff0c\u9700\u8981\u4f20\u5165\u7b97\u6cd5\u5305\u8def\u5f84(path)\u548cpython\u73af\u5883\u8def\u5f84(\u53ef\u9009\uff0c\u82e5\u4e0d\u4f20\u5c06\u4f7f\u7528\u7cfb\u7edf\u7684\u73af\u5883) <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"local\",\n  \"version\": \"2.0.1\",\n  \"metadata\": {\n    \"path\": \"/Users/tonly/FATE/python\",\n    \"venv\": \"/Users/tonly/opt/anaconda3/envs/fate3.8/bin/python\"\n  }\n}\n</code></pre></p> <ul> <li>\u6ce8\u518cdocker\u7b97\u6cd5\u955c\u50cf\u5305 <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"docker\",\n  \"version\": \"2.0.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"federatedai/fate:2.0.0\"\n  },\n  \"protocol\": \"bfia\",\n  \"components_description\": {}\n}\n</code></pre></li> </ul>"},{"location":"zh/provider_register/#22","title":"2.2 \u67e5\u8be2","text":"<ul> <li>\u547d\u4ee4\uff1a <pre><code>flow provider register --name fate --version 2.0.1 --device local\n</code></pre></li> <li>\u8f93\u51fa\uff1a <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"create_time\": 1703762542058,\n            \"device\": \"local\",\n            \"metadata\": {\n                \"path\": \"/Users/tonly/FATE/python\",\n                \"venv\": \"/Users/tonly/opt/anaconda3/envs/fate3.8/bin/python\"\n            },\n            \"name\": \"fate\",\n            \"provider_name\": \"fate:2.0.1@local\",\n            \"update_time\": 1703762542058,\n            \"version\": \"2.0.1\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></li> </ul>"},{"location":"zh/provider_register/#23","title":"2.3 \u5220\u9664","text":"<p>\u7528\u4e8e\u5220\u9664\u5df2\u7ecf\u6ce8\u518c\u7684\u7b97\u6cd5 - \u547d\u4ee4\uff1a <pre><code>flow provider delete --name fate --version 2.0.1 --device local\n</code></pre> - \u8f93\u51fa\uff1a <pre><code>{\n    \"code\": 0,\n    \"data\": true,\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"zh/provider_register/#3","title":"3.\u7ec4\u4ef6\u6ce8\u518c\u4e0e\u53d1\u73b0\u673a\u5236","text":"<ul> <li>\u6ce8\u518c\u7b97\u6cd5</li> <li>\u4efb\u52a1\u914d\u7f6e\u4e2d\u643a\u5e26provider\u53c2\u6570\uff0c\u8be6\u89c1\u5982\u4e0b\u914d\u7f6e\u65b9\u6cd5</li> </ul>"},{"location":"zh/provider_register/#4","title":"4. \u914d\u7f6e\u65b9\u6cd5","text":""},{"location":"zh/provider_register/#41-job","title":"4.1 \u5168\u5c40job\u914d\u7f6e","text":"<p><pre><code>dag:\n  conf:\n    task:\n      provider: fate:2.0.1@local\n</code></pre> job\u4e0b\u7684\u6240\u6709task\u7ee7\u627f\u6b64provider</p>"},{"location":"zh/provider_register/#42-task","title":"4.2 \u5168\u5c40\u53c2\u4e0e\u65b9task\u914d\u7f6e","text":"<p><pre><code>dag:\n  party_tasks:\n    guest_9999:\n      parties:\n      - party_id:\n        - '9999'\n        role: guest\n      conf:\n        provider: fate:2.0.1@local\n</code></pre> guest 9999\u4e0b\u7684\u6240\u6709task\u7ee7\u627f\u6b64provider</p>"},{"location":"zh/provider_register/#43-task","title":"4.3 \u5168\u5c40task\u914d\u7f6e","text":"<p><pre><code>dag:\n  tasks:\n    reader_0:\n      conf:\n        provider: fate:2.0.1@local\n      component_ref: reader\n</code></pre> \u6240\u6709\u53c2\u4e0e\u65b9\u7684reader\u7ec4\u4ef6\u7ee7\u627f\u6b64provider</p>"},{"location":"zh/provider_register/#44-task","title":"4.4 \u6307\u5b9atask\u914d\u7f6e","text":"<p><pre><code>dag:\n  party_tasks:\n    guest_9999:\n      parties:\n      - party_id:\n        - '9999'\n        role: guest\n      tasks:\n        reader_0:\n          conf:\n            provider: fate:2.0.1@local\n</code></pre> guest 9999\u4e0breader\u7ec4\u4ef6\u7ee7\u627f\u6b64provider</p>"},{"location":"zh/quick_start/","title":"\u5feb\u901f\u5165\u95e8","text":""},{"location":"zh/quick_start/#1","title":"1. \u73af\u5883\u90e8\u7f72","text":"<p>\u4ee5\u4e0b\u4e09\u79cd\u6a21\u5f0f\u53ef\u6839\u636e\u9700\u6c42\u81ea\u884c\u9009\u62e9\u4e00\u79cd</p>"},{"location":"zh/quick_start/#11-pypi","title":"1.1 Pypi\u5305\u5b89\u88c5","text":"<p>\u8bf4\u660e\uff1a\u6b64\u65b9\u5f0f\u7684\u8fd0\u884c\u6a21\u5f0f\u4e3a\u5355\u673a\u6a21\u5f0f</p>"},{"location":"zh/quick_start/#111","title":"1.1.1 \u5b89\u88c5","text":"<ul> <li>conda\u73af\u5883\u51c6\u5907\u53ca\u5b89\u88c5</li> <li>\u521b\u5efa\u865a\u62df\u73af\u5883 <pre><code># fate\u7684\u8fd0\u884c\u73af\u5883\u4e3apython&gt;=3.8\nconda create -n fate_env python=3.8\nconda activate fate_env\n</code></pre></li> <li>\u5b89\u88c5fate flow\u53ca\u76f8\u5173\u4f9d\u8d56 <pre><code>pip install fate_client[fate,fate_flow]==2.0.0\n</code></pre></li> </ul>"},{"location":"zh/quick_start/#112","title":"1.1.2 \u670d\u52a1\u521d\u59cb\u5316","text":"<p><pre><code>fate_flow init --ip 127.0.0.1 --port 9380 --home $HOME_DIR\n</code></pre> - ip: \u670d\u52a1\u8fd0\u884cip - port\uff1a\u670d\u52a1\u8fd0\u884c\u65f6\u7684http\u7aef\u53e3 - home: \u6570\u636e\u5b58\u50a8\u76ee\u5f55\u3002\u4e3b\u8981\u5305\u62ec\uff1a\u6570\u636e/\u6a21\u578b/\u65e5\u5fd7/\u4f5c\u4e1a\u914d\u7f6e/sqlite.db\u7b49\u5185\u5bb9</p>"},{"location":"zh/quick_start/#113","title":"1.1.3 \u670d\u52a1\u542f\u505c","text":"<pre><code>fate_flow status/start/stop/restart\n</code></pre>"},{"location":"zh/quick_start/#12","title":"1.2 \u5355\u673a\u7248\u90e8\u7f72","text":"<p>\u53c2\u8003\u5355\u673a\u7248\u90e8\u7f72</p>"},{"location":"zh/quick_start/#13","title":"1.3 \u96c6\u7fa4\u90e8\u7f72","text":"<p>\u53c2\u8003allinone\u90e8\u7f72</p>"},{"location":"zh/quick_start/#2","title":"2. \u4f7f\u7528\u6307\u5357","text":"<p>fate\u63d0\u4f9b\u7684\u5ba2\u6237\u7aef\u5305\u62ecSDK\u3001CLI\u548cPipeline\uff0c\u82e5\u4f60\u7684\u73af\u5883\u4e2d\u6ca1\u6709\u90e8\u7f72FATE Client,\u53ef\u4ee5\u4f7f\u7528<code>pip install fate_client</code>\u4e0b\u8f7d\uff0c\u4ee5\u4e0b\u7684\u4f7f\u7528\u64cd\u4f5c\u5747\u57fa\u4e8ecli\u7f16\u5199\u3002</p>"},{"location":"zh/quick_start/#21","title":"2.1 \u6570\u636e\u4e0a\u4f20","text":"<p>\u66f4\u8be6\u7ec6\u7684\u6570\u636e\u64cd\u4f5c\u6307\u5357\u53ef\u53c2\u8003\uff1a\u6570\u636e\u63a5\u5165\u6307\u5357</p>"},{"location":"zh/quick_start/#211","title":"2.1.1 \u914d\u7f6e\u53ca\u6570\u636e","text":"<ul> <li>\u4e0a\u4f20\u914d\u7f6e: examples-upload</li> <li>\u4e0a\u4f20\u6570\u636e: upload-data</li> </ul>"},{"location":"zh/quick_start/#212-guest","title":"2.1.2 \u4e0a\u4f20guest\u65b9\u6570\u636e","text":"<pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre>"},{"location":"zh/quick_start/#213-host","title":"2.1.3 \u4e0a\u4f20host\u65b9\u6570\u636e","text":"<pre><code>flow data upload -c examples/upload/upload_host.json\n</code></pre>"},{"location":"zh/quick_start/#22-fate","title":"2.2 \u5f00\u59cbFATE\u4f5c\u4e1a","text":""},{"location":"zh/quick_start/#221","title":"2.2.1 \u63d0\u4ea4\u4f5c\u4e1a","text":"<p>\u5f53\u4f60\u7684\u6570\u636e\u51c6\u5907\u597d\u540e\uff0c\u53ef\u4ee5\u5f00\u59cb\u63d0\u4ea4\u4f5c\u4e1a\u7ed9FATE Flow\uff1a - job\u914d\u7f6eexample\u4f4d\u4e8elr-train; - job\u914d\u7f6e\u4e2d\u7ad9\u70b9id\u4e3a\"9998\"\u548c\"9999\"\u3002\u5982\u679c\u4f60\u7684\u90e8\u7f72\u73af\u5883\u4e3a\u96c6\u7fa4\u7248\uff0c\u9700\u8981\u66ff\u6362\u6210\u771f\u5b9e\u7684\u7ad9\u70b9id\uff1b\u5355\u673a\u7248\u53ef\u4f7f\u7528\u9ed8\u8ba4\u914d\u7f6e\u3002 - \u5982\u679c\u60f3\u8981\u4f7f\u7528\u81ea\u5df1\u7684\u6570\u636e\uff0c\u53ef\u4ee5\u66f4\u6539\u914d\u7f6e\u4e2dreader\u7684\u53c2\u6570\u3002 - \u63d0\u4ea4\u4f5c\u4e1a\u7684\u547d\u4ee4\u4e3a: <pre><code>flow job submit -c examples/lr/train_lr.yaml \n</code></pre> - \u63d0\u4ea4\u6210\u529f\u8fd4\u56de\u7ed3\u679c: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"model_id\": \"202308211911505128750\",\n        \"model_version\": \"0\"\n    },\n    \"job_id\": \"202308211911505128750\",\n    \"message\": \"success\"\n}\n</code></pre> \u8fd9\u91cc\u7684\"data\"\u5185\u5bb9\u5373\u4e3a\u8be5\u4f5c\u4e1a\u7684\u8f93\u51fa\u6a21\u578b\u3002</p>"},{"location":"zh/quick_start/#222","title":"2.2.2 \u67e5\u8be2\u4f5c\u4e1a","text":"<p>\u5728\u4f5c\u4e1a\u7684\u8fd0\u884c\u8fc7\u7a0b\u65f6\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u67e5\u8be2\u547d\u4ee4\u83b7\u53d6\u4f5c\u4e1a\u7684\u8fd0\u884c\u72b6\u6001 <pre><code>flow job query -j $job_id\n</code></pre></p>"},{"location":"zh/quick_start/#223","title":"2.2.3 \u505c\u6b62\u4f5c\u4e1a","text":"<p>\u5728\u4f5c\u4e1a\u7684\u8fd0\u884c\u8fc7\u7a0b\u65f6\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u505c\u6b62\u4f5c\u4e1a\u547d\u4ee4\u6765\u7ec8\u6b62\u5f53\u524d\u4f5c\u4e1a <pre><code>flow job stop -j $job_id\n</code></pre></p>"},{"location":"zh/quick_start/#224","title":"2.2.4 \u91cd\u8dd1\u4f5c\u4e1a","text":"<p>\u5728\u4f5c\u4e1a\u7684\u8fd0\u884c\u8fc7\u7a0b\u65f6\uff0c\u5982\u679c\u8fd0\u884c\u5931\u8d25\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u91cd\u8dd1\u547d\u4ee4\u6765\u91cd\u8dd1\u5f53\u524d\u4f5c\u4e1a <pre><code>flow job rerun -j $job_id\n</code></pre></p>"},{"location":"zh/quick_start/#23","title":"2.3 \u83b7\u53d6\u4f5c\u4e1a\u8f93\u51fa\u7ed3\u679c","text":"<p>\u4f5c\u4e1a\u7684\u8f93\u51fa\u5305\u62ec\u6570\u636e\u3001\u6a21\u578b\u548c\u6307\u6807</p>"},{"location":"zh/quick_start/#231","title":"2.3.1 \u8f93\u51fa\u6307\u6807","text":"<p>\u67e5\u8be2\u8f93\u51fa\u6307\u6807\u547d\u4ee4\uff1a <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code>\u67e5\u8be2\u3002 \u67e5\u8be2\u7ed3\u679c\u5982\u4e0b: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"zh/quick_start/#232","title":"2.3.2 \u8f93\u51fa\u6a21\u578b","text":""},{"location":"zh/quick_start/#2321","title":"2.3.2.1 \u67e5\u8be2\u6a21\u578b","text":"<p><pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code>\u67e5\u8be2\u3002 \u67e5\u8be2\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"output_model\": {\n            \"data\": {\n                \"estimator\": {\n                    \"end_epoch\": 10,\n                    \"is_converged\": false,\n                    \"lr_scheduler\": {\n                        \"lr_params\": {\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100\n                        },\n                        \"lr_scheduler\": {\n                            \"_get_lr_called_within_step\": false,\n                            \"_last_lr\": [\n                                0.07269999999999996\n                            ],\n                            \"_step_count\": 10,\n                            \"base_lrs\": [\n                                0.1\n                            ],\n                            \"end_factor\": 1.0,\n                            \"last_epoch\": 9,\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100,\n                            \"verbose\": false\n                        },\n                        \"method\": \"linear\"\n                    },\n                    \"optimizer\": {\n                        \"alpha\": 0.001,\n                        \"l1_penalty\": false,\n                        \"l2_penalty\": true,\n                        \"method\": \"sgd\",\n                        \"model_parameter\": [\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ]\n                        ],\n                        \"model_parameter_dtype\": \"float32\",\n                        \"optim_param\": {\n                            \"lr\": 0.1\n                        },\n                        \"optimizer\": {\n                            \"param_groups\": [\n                                {\n                                    \"dampening\": 0,\n                                    \"differentiable\": false,\n                                    \"foreach\": null,\n                                    \"initial_lr\": 0.1,\n                                    \"lr\": 0.07269999999999996,\n                                    \"maximize\": false,\n                                    \"momentum\": 0,\n                                    \"nesterov\": false,\n                                    \"params\": [\n                                        0\n                                    ],\n                                    \"weight_decay\": 0\n                                }\n                            ],\n                            \"state\": {}\n                        }\n                    },\n                    \"param\": {\n                        \"coef_\": [\n                            [\n                                -0.10828543454408646\n                            ],\n                            [\n                                -0.07341302931308746\n                            ],\n                            [\n                                -0.10850320011377335\n                            ],\n                            [\n                                -0.10066638141870499\n                            ],\n                            [\n                                -0.04595951363444328\n                            ],\n                            [\n                                -0.07001449167728424\n                            ],\n                            [\n                                -0.08949052542448044\n                            ],\n                            [\n                                -0.10958756506443024\n                            ],\n                            [\n                                -0.04012322425842285\n                            ],\n                            [\n                                0.02270071767270565\n                            ],\n                            [\n                                -0.07198350876569748\n                            ],\n                            [\n                                0.00548586156219244\n                            ],\n                            [\n                                -0.06599288433790207\n                            ],\n                            [\n                                -0.06410090625286102\n                            ],\n                            [\n                                0.016374297440052032\n                            ],\n                            [\n                                -0.01607361063361168\n                            ],\n                            [\n                                -0.011447405442595482\n                            ],\n                            [\n                                -0.04352564364671707\n                            ],\n                            [\n                                0.013161249458789825\n                            ],\n                            [\n                                0.013506329618394375\n                            ]\n                        ],\n                        \"dtype\": \"float32\",\n                        \"intercept_\": null\n                    }\n                }\n            },\n            \"meta\": {\n                \"batch_size\": null,\n                \"epochs\": 10,\n                \"init_param\": {\n                    \"fill_val\": 0.0,\n                    \"fit_intercept\": false,\n                    \"method\": \"zeros\",\n                    \"random_state\": null\n                },\n                \"label_count\": false,\n                \"learning_rate_param\": {\n                    \"method\": \"linear\",\n                    \"scheduler_params\": {\n                        \"start_factor\": 0.7,\n                        \"total_iters\": 100\n                    }\n                },\n                \"optimizer_param\": {\n                    \"alpha\": 0.001,\n                    \"method\": \"sgd\",\n                    \"optimizer_params\": {\n                        \"lr\": 0.1\n                    },\n                    \"penalty\": \"l2\"\n                },\n                \"ovr\": false\n            }\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"zh/quick_start/#2322","title":"2.3.2.2 \u4e0b\u8f7d\u6a21\u578b","text":"<p><pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code>\u4e0b\u8f7d\u3002 \u4e0b\u8f7d\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre></p>"},{"location":"zh/quick_start/#233","title":"2.3.3 \u8f93\u51fa\u6570\u636e","text":""},{"location":"zh/quick_start/#2331","title":"2.3.3.1 \u67e5\u8be2\u6570\u636e\u8868","text":"<p><pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code>\u67e5\u8be2\u3002 \u67e5\u8be2\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"zh/quick_start/#2332","title":"2.3.3.2 \u9884\u89c8\u6570\u636e","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code>\u9884\u89c8\u8f93\u51fa\u6570\u636e\u3002</p>"},{"location":"zh/quick_start/#2333","title":"2.3.3.3 \u4e0b\u8f7d\u6570\u636e","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> \u5982\u4f7f\u7528\u4e0a\u9762\u7684\u8bad\u7ec3dag\u63d0\u4ea4\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528<code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code>\u4e0b\u8f7d\u8f93\u51fa\u6570\u636e\u3002 \u4e0b\u8f7d\u7ed3\u679c\u5982\u4e0b\uff1a <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"zh/quick_start/#3","title":"3.\u66f4\u591a\u6587\u6863","text":"<ul> <li>Restful-api</li> <li>CLI</li> <li>Pipeline</li> <li>FATE\u5feb\u901f\u5f00\u59cb</li> <li>FATE\u7b97\u6cd5</li> </ul>"},{"location":"zh/system_conf/","title":"\u7cfb\u7edf\u914d\u7f6e\u63cf\u8ff0\u6587\u6863","text":"<p>FATE Flow\u4f7f\u7528yaml\u5b9a\u4e49\u7cfb\u7edf\u914d\u7f6e\uff0c\u914d\u7f6e\u8def\u5f84\u4f4d\u4e8e: conf/service_conf.yaml, \u5177\u4f53\u914d\u7f6e\u5185\u5bb9\u53ca\u5176\u542b\u4e49\u5982\u4e0b\uff1a</p> \u914d\u7f6e\u9879 \u8bf4\u660e \u503c party_id \u672c\u65b9\u7ad9\u70b9id \u5982: \"9999\", \"10000 use_registry \u662f\u5426\u4f7f\u7528\u6ce8\u518c\u4e2d\u5fc3\uff0c\u5f53\u524d\u4ec5\u652f\u6301zookeeper\u6a21\u5f0f\uff0c\u9700\u8981\u4fdd\u8bc1zookeeper\u7684\u914d\u7f6e\u6b63\u786e\uff1b\u6ce8\uff1a\u82e5\u4f7f\u7528\u9ad8\u53ef\u7528\u6a21\u5f0f\uff0c\u9700\u4fdd\u8bc1\u8be5\u914d\u7f6e\u8bbe\u7f6e\u4e3atrue true/false log_level \u65e5\u5fd7\u7ea7\u522b DEBUG:10, INFO:20, DEBUG:30, ERROR: 40 encrypt \u52a0\u5bc6\u6a21\u5757 \u89c1\u52a0\u5bc6\u6a21\u5757 fateflow FATE Flow\u670d\u52a1\u7684\u914d\u7f6e\uff0c\u4e3b\u8981\u5305\u62ec\u7aef\u53e3\u3001\u547d\u4ee4\u901a\u9053\u670d\u52a1\u3001\u4ee3\u7406\u7b49 \u89c1FateFlow\u914d\u7f6e database \u6570\u636e\u5e93\u670d\u52a1\u7684\u914d\u7f6e\u4fe1\u606f \u89c1\u6570\u636e\u5e93\u914d\u7f6e default_engines \u7cfb\u7edf\u7684\u5f15\u64ce\u670d\u52a1\uff0c\u4e3b\u8981\u5305\u62ec\u8ba1\u7b97\u3001\u5b58\u50a8\u548c\u901a\u4fe1\u5f15\u64ce \u89c1\u5f15\u64ce\u914d\u7f6e default_provider \u7ec4\u4ef6\u7684\u6765\u6e90\u4fe1\u606f\uff0c\u4e3b\u8981\u5305\u62ec\u63d0\u4f9b\u65b9\u540d\u79f0\u3001\u7ec4\u4ef6\u7248\u672c\u548c\u8fd0\u884c\u6a21\u5f0f \u89c1\u9ed8\u8ba4\u6ce8\u518c\u7b97\u6cd5\u914d\u7f6e federation \u901a\u4fe1\u670d\u52a1\u6c60 \u89c1\u901a\u4fe1\u5f15\u64ce\u6c60 computing \u8ba1\u7b97\u670d\u52a1\u6c60 \u89c1\u8ba1\u7b97\u5f15\u64ce\u6c60 storage \u5b58\u50a8\u670d\u52a1\u6c60 \u89c1\u5b58\u50a8\u5f15\u64ce\u6c60 hook_module \u94a9\u5b50\u914d\u7f6e\uff0c\u5f53\u524d\u652f\u6301\u5ba2\u6237\u7aef\u8ba4\u8bc1\u3001\u7ad9\u70b9\u7aef\u8ba4\u8bc1\u4ee5\u53ca\u9274\u6743\u94a9\u5b50 \u89c1\u94a9\u5b50\u6a21\u5757\u914d\u7f6e authentication \u8ba4\u8bc1&amp;&amp;\u9274\u6743\u5f00\u5173 \u89c1\u8ba4\u8bc1\u5f00\u5173 model_store \u6a21\u578b\u5b58\u50a8\u914d\u7f6e \u89c1\u6a21\u578b\u5b58\u50a8 zookeeper zookeeper\u670d\u52a1\u7684\u914d\u7f6e \u89c1zookeeper\u914d\u7f6e"},{"location":"zh/system_conf/#_2","title":"\u52a0\u5bc6\u6a21\u5757","text":"<p><pre><code>key_0:\n  module: fate_flow.hub.encrypt.password_encrypt#pwdecrypt\n  private_path: private_key.pem\n</code></pre> \u8be5\u52a0\u5bc6\u6a21\u5757\u4e3b\u8981\u7528\u4e8e\u5bc6\u7801(\u5982mysql\u5bc6\u7801)\u7b49\u5185\u5bb9\u52a0\u5bc6\uff1a - \u5176\u4e2d\"key_0\"\u4e3a\u52a0\u5bc6\u6a21\u5757\u7684key(\u53ef\u4ee5\u81ea\u5b9a\u4e49\u540d\u5b57)\uff0c\u4fbf\u4e8e\u5176\u5b83\u914d\u7f6e\u4e2d\u76f4\u63a5\u5f15\u7528\uff0c\u591a\u5957\u52a0\u5bc6\u6a21\u5f0f\u5171\u5b58\u3002   - module: \u52a0\u5bc6\u6a21\u5757\uff0c\u62fc\u63a5\u89c4\u5219\u4e3a\uff1a\u52a0\u5bc6\u6a21\u5757 + \"#\" + \u52a0\u5bc6\u51fd\u6570\u3002   - private_path\uff1a\u5bc6\u94a5\u8def\u5f84\u3002\u5982\u586b\u76f8\u5bf9\u8def\u5f84\uff0c\u5176\u6839\u76ee\u5f55\u4f4d\u4e8efate_flow/conf/</p>"},{"location":"zh/system_conf/#fateflow","title":"FateFlow\u914d\u7f6e","text":"<p><pre><code>host: 127.0.0.1\nhttp_port: 9380\ngrpc_port: 9360\nproxy_name: osx\nnginx:\n  host:\n  http_port:\n  grpc_port:\n</code></pre> - host: \u4e3b\u673a\u5730\u5740; - http_port\uff1ahttp\u7aef\u53e3\u53f7; - grpc_port: grpc\u7aef\u53e3\u53f7; - proxy_name: \u547d\u4ee4\u901a\u9053\u670d\u52a1\u540d\uff0c\u652f\u6301osx/nginx\u3002\u8be6\u7ec6\u914d\u7f6e\u9700\u8981\u5728\u901a\u4fe1\u5f15\u64ce\u6c60 \u91cc\u9762\u914d\u7f6e; - nginx: \u4ee3\u7406\u670d\u52a1\u914d\u7f6e\uff0c\u7528\u4e8e\u8d1f\u8f7d\u5747\u8861\u3002</p>"},{"location":"zh/system_conf/#_3","title":"\u6570\u636e\u5e93\u914d\u7f6e","text":"<p><pre><code>engine: sqlite\ndecrypt_key:\nmysql:\n  name: fate_flow\n  user: fate\n  passwd: fate\n  host: 127.0.0.1\n  port: 3306\n  max_connections: 100\n  stale_timeout: 30\nsqlite:\n  path:\n</code></pre> - engine: \u6570\u636e\u5e93\u5f15\u64ce\u540d\u5b57\uff0c\u5982\u8fd9\u91cc\u586b\"mysql\"\uff0c\u5219\u9700\u8981\u66f4\u65b0mysql\u7684\u914d\u7f6e\u8be6\u7ec6\u914d\u7f6e\u3002 - decrypt_key: \u52a0\u5bc6\u6a21\u5757,\u9700\u8981\u4ece\u52a0\u5bc6\u6a21\u5757\u4e2d\u9009\u62e9\u3002 \u82e5\u4e0d\u914d\u7f6e\uff0c\u89c6\u4e3a\u4e0d\u4f7f\u7528\u5bc6\u7801\u52a0\u5bc6\uff1b\u82e5\u4f7f\u7528\uff0c\u5219\u9700\u8981\u5c06\u4e0b\u9762\u7684passwd\u76f8\u5e94\u8bbe\u7f6e\u4e3a\u5bc6\u6587\u3002 - mysql: mysql\u670d\u52a1\u914d\u7f6e\uff1b\u82e5\u4f7f\u7528\u5bc6\u7801\u52a0\u5bc6\u529f\u80fd\uff0c\u9700\u8981\u5c06\u6b64\u914d\u7f6e\u4e2d\u7684\"passwd\"\u8bbe\u7f6e\u4e3a\u5bc6\u6587\uff0c\u5e76\u5728\u52a0\u5bc6\u6a21\u5757\u4e2d\u914d\u7f6e\u5bc6\u94a5\u8def\u5f84 - sqlite: sqlite\u6587\u4ef6\u8def\u5f84\uff0c\u9ed8\u8ba4\u8def\u5f84\u4e3afate_flow/fate_flow_sqlite.db</p>"},{"location":"zh/system_conf/#_4","title":"\u5f15\u64ce\u914d\u7f6e","text":"<pre><code>default_engines:\n  computing: standalone\n  federation: standalone\n  storage: standalone\n</code></pre> <ul> <li>computing: \u8ba1\u7b97\u5f15\u64ce\uff0c\u652f\u6301\"standalone\"\u3001\"eggroll\"\u3001\"spark\"</li> <li>federation: \u901a\u4fe1\u5f15\u64ce\uff0c\u652f\u6301\"standalone\"\u3001\"osx\"\u3001\"rabbitmq\"\u3001\"pulsar\"</li> <li>storage: \u5b58\u50a8\u5f15\u64ce\uff0c\u652f\u6301\"standalone\"\u3001\"eggroll\"\u3001\"hdfs\"</li> </ul>"},{"location":"zh/system_conf/#_5","title":"\u9ed8\u8ba4\u6ce8\u518c\u7b97\u6cd5\u914d\u7f6e","text":"<ul> <li>name: \u7b97\u6cd5\u540d\u79f0</li> <li>version: \u7b97\u6cd5\u7248\u672c\uff0c\u82e5\u4e0d\u914d\u7f6e\uff0c\u5219\u4f7f\u7528fateflow.env\u4e2d\u7684\u914d\u7f6e</li> <li>device: \u7b97\u6cd5\u542f\u52a8\u65b9\u5f0f, local/docker/k8s\u7b49</li> </ul>"},{"location":"zh/system_conf/#_6","title":"\u901a\u4fe1\u5f15\u64ce\u6c60","text":""},{"location":"zh/system_conf/#osx","title":"osx","text":"<pre><code>  host: 127.0.0.1\n  port: 9370\n  mode: stream\n</code></pre>"},{"location":"zh/system_conf/#_7","title":"\u8ba1\u7b97\u5f15\u64ce\u6c60","text":""},{"location":"zh/system_conf/#standalone","title":"standalone","text":"<p><pre><code>  cores: 32\n</code></pre> - cores: \u8d44\u6e90\u603b\u6570</p>"},{"location":"zh/system_conf/#eggroll","title":"eggroll","text":"<p><pre><code>eggroll:\n  cores: 32\n  nodes: 1\n  host: 127.0.0.1\n  port: 4670\n</code></pre> - cores: \u96c6\u7fa4\u8d44\u6e90\u603b\u6570 - nodes: \u96c6\u7fa4node-manager\u6570\u91cf - host: eggroll cluster manager host ip - port: eggroll cluster manager port</p>"},{"location":"zh/system_conf/#spark","title":"spark","text":"<p><pre><code>spark:\n  home: \n  cores: 32\n</code></pre> - home: spark home\u76ee\u5f55\uff0c\u5982\u679c\u4e0d\u586b\uff0c\u5c06\u4f7f\u7528\"pyspark\"\u4f5c\u4e3a\u8ba1\u7b97\u5f15\u64ce\u3002 - cores: \u8d44\u6e90\u603b\u6570</p>"},{"location":"zh/system_conf/#_8","title":"\u5b58\u50a8\u5f15\u64ce\u6c60","text":"<pre><code>  hdfs:\n    name_node: hdfs://fate-cluster\n</code></pre>"},{"location":"zh/system_conf/#_9","title":"\u94a9\u5b50\u6a21\u5757\u914d\u7f6e","text":"<p><pre><code>hook_module:\n  client_authentication: fate_flow.hook.flow.client_authentication\n  site_authentication: fate_flow.hook.flow.site_authentication\n  permission: fate_flow.hook.flow.permission\n</code></pre> - client_authentication: \u5ba2\u6237\u7aef\u8ba4\u8bc1\u94a9\u5b50 - site_authentication: \u7ad9\u70b9\u8ba4\u8bc1\u94a9\u5b50 - permission: \u6743\u9650\u8ba4\u8bc1\u94a9\u5b50</p>"},{"location":"zh/system_conf/#_10","title":"\u8ba4\u8bc1\u5f00\u5173","text":"<pre><code>authentication:\n  client: false\n  site: false\n  permission: false\n</code></pre>"},{"location":"zh/system_conf/#_11","title":"\u6a21\u578b\u5b58\u50a8","text":"<p><pre><code>model_store:\n  engine: file\n  decrypt_key:\n  file:\n    path:\n  mysql:\n    name: fate_flow\n    user: fate\n    passwd: fate\n    host: 127.0.0.1\n    port: 3306\n    max_connections: 100\n    stale_timeout: 30\n  tencent_cos:\n    Region:\n    SecretId:\n    SecretKey:\n    Bucket:\n</code></pre> - engine: \u6a21\u578b\u5b58\u50a8\u5f15\u64ce\uff0c\u652f\u6301\"file\"\u3001\"mysql\"\u548c\"tencent_cos\"\u3002 - decrypt_key: \u52a0\u5bc6\u6a21\u5757,\u9700\u8981\u4ece\u52a0\u5bc6\u6a21\u5757\u4e2d\u9009\u62e9\u3002 \u82e5\u4e0d\u914d\u7f6e\uff0c\u89c6\u4e3a\u4e0d\u4f7f\u7528\u5bc6\u7801\u52a0\u5bc6\uff1b\u82e5\u4f7f\u7528\uff0c\u5219\u9700\u8981\u5c06\u4e0b\u9762\u7684passwd\u76f8\u5e94\u8bbe\u7f6e\u4e3a\u5bc6\u6587\u3002 - file: \u6a21\u578b\u5b58\u50a8\u76ee\u5f55\uff0c\u9ed8\u8ba4\u4f4d\u4e8e\uff1a fate_flow/model - mysql: mysql\u670d\u52a1\u914d\u7f6e\uff1b\u82e5\u4f7f\u7528\u5bc6\u7801\u52a0\u5bc6\u529f\u80fd\uff0c\u9700\u8981\u5c06\u6b64\u914d\u7f6e\u4e2d\u7684\"passwd\"\u8bbe\u7f6e\u4e3a\u5bc6\u6587\uff0c\u5e76\u5728\u52a0\u5bc6\u6a21\u5757\u4e2d\u914d\u7f6e\u5bc6\u94a5\u8def\u5f84 - tencent_cos: \u817e\u8baf\u4e91\u5bc6\u94a5\u914d\u7f6e</p>"},{"location":"zh/system_conf/#zookeeper","title":"zookeeper\u914d\u7f6e","text":"<pre><code>zookeeper:\n  hosts:\n    - 127.0.0.1:2181\n  use_acl: true\n  user: fate\n  password: fate\n</code></pre>"},{"location":"bfia_access/","title":"BFIA Integration Guide","text":"<p>The BFIA protocol, organized by the Beijing Financial Technology Industry Alliance and led by China UnionPay, is an API interface specification established jointly by over 60 units, including major financial institutions, telecom operators, internet companies, technology firms, testing agencies, and research institutes. FATE 2.0 has adapted this protocol across various layers like Pipeline, Scheduling, Communication, and more. This document will guide how to perform federated learning with FATE framework using the BFIA protocol.</p>"},{"location":"bfia_access/#1-pipeline","title":"1. Pipeline","text":"<p>The pipeline constructs a unified client for FATE's interoperation, generating a DAG configuration based on the FATE 2.0 protocol. The pipeline doesn't directly call the BFIA protocol API; instead, it utilizes the FATE protocol API and transforms it into BFIA protocol execution within the FATE Flow through an adapter pattern.</p>"},{"location":"bfia_access/#11-fate-algorithm","title":"1.1 FATE Algorithm","text":"<pre><code>from fate_client.pipeline import FateFlowPipeline\nfrom fate_client.pipeline.components.fate import CoordinatedLR, PSI\nfrom fate_client.pipeline.interface.channel import DataWarehouseChannel\n\n\nguest = \"JG0100001100000010\"\nhost = \"JG0100001100000010\"\narbiter = \"JG0100001100000010\"\npipeline = FateFlowPipeline().set_parties(guest=guest, host=host, arbiter=arbiter)\npipeline.set_site_role(\"guest\")\npipeline.set_site_party_id(guest)\n\npsi_0 = PSI(\"psi_0\",\n        input_data=[DataWarehouseChannel(dataset_id=\"experiment#breast_hetero_guest\", parties=dict(guest=guest)),\n                    DataWarehouseChannel(dataset_id=\"experiment#breast_hetero_host\", parties=dict(host=host))])\nlr_0 = CoordinatedLR(\"lr_0\",\n                 epochs=10,\n                 batch_size=300,\n                 optimizer={\"method\": \"SGD\", \"optimizer_params\": {\"lr\": 0.1}, \"penalty\": \"l2\", \"alpha\": 0.001},\n                 init_param={\"fit_intercept\": True, \"method\": \"zeros\"},\n                 train_data=psi_0.outputs[\"output_data\"],\n                 learning_rate_scheduler={\"method\": \"linear\", \"scheduler_params\": {\"start_factor\": 0.7,\n                                                                                   \"total_iters\": 100}})\n\npipeline.add_tasks([psi_0, lr_0])\n\npipeline.protocol_kind = \"bfia\"\npipeline.conf.set(\n\"extra\",\ndict(initiator={'party_id': guest, 'role': 'guest'})\n)\npipeline.guest.conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.hosts[0].conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.compile()\npipeline.fit()\n</code></pre>"},{"location":"bfia_access/#12-unionpay-algorithm","title":"1.2 UnionPay Algorithm","text":"<pre><code>from fate_client.pipeline import FateFlowPipeline\nfrom fate_client.pipeline.adapters.bfia.components.unionpay.intersection import Intersection\nfrom fate_client.pipeline.adapters.bfia.components.unionpay.hetero_lr import HeteroLR\nfrom fate_client.pipeline.interface import DataWarehouseChannel\n\n\npipeline = FateFlowPipeline().set_parties(\n    guest=\"JG0100001100000010\",\n    host=\"JG0100001100000010\",\n    arbiter=\"JG0100001100000010\"\n)\npipeline.set_site_role(\"guest\")\npipeline.set_site_party_id(\"JG0100001100000010\")\n\nintersection_0 = Intersection(\n    \"intersect_rsa_1\",\n    id=\"id\",\n    intersect_method=\"rsa\",\n    only_output_key=False,\n    rsa_params=dict(\n        final_hash_method=\"sha256\",\n        hash_method=\"sha256\",\n        key_length=2048\n    ),\n    sync_intersect_ids=True,\n    connect_engine=\"mesh\",\n    train_data=[\n        DataWarehouseChannel(dataset_id=\"testspace#test_guest\", parties=dict(guest=\"JG0100001100000010\")),\n        DataWarehouseChannel(dataset_id=\"testspace#test_host\", parties=dict(host=\"JG0100001100000010\"))\n    ]\n)\n\nhetero_lr_0 = HeteroLR(\n    \"hetero_logistic_regression_1\",\n    id=\"id\",\n    label=\"y\",\n    batch_size=-1,\n    penalty=\"L2\",\n    early_stop=\"diff\",\n    tol=0.0001,\n    max_iter=2,\n    alpha=0.01,\n    optimizer=\"nesterov_momentum_sgd\",\n    init_param={\"init_method\":\"zeros\"},\n    learning_rate=0.15,\n    connect_engine=\"mesh\",\n    train_data=intersection_0.outputs[\"train_data\"]\n)\n\npipeline.add_task(intersection_0)\npipeline.add_task(hetero_lr_0)\npipeline.conf.set(\n    \"extra\",\n    dict(initiator={'party_id': 'JG0100001100000010', 'role': 'guest'})\n)\n\npipeline.protocol_kind = \"bfia\"\npipeline.guest.conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.hosts[0].conf.set(\"resources\", dict(cpu=-1, disk=-1, memory=-1))\npipeline.compile()\npipeline.fit()\n</code></pre>"},{"location":"bfia_access/#13-other-bfia-protocol-algorithms","title":"1.3 Other BFIA Protocol Algorithms","text":""},{"location":"bfia_access/#131-pipeline-adaptation-development","title":"1.3.1 Pipeline Adaptation Development:","text":"<p>To integrate other algorithms, follow these steps: - Component Description File: Place the algorithm component description file in pipeline-component-define - Component Definition: Place the algorithm component definition file in pipeline-component</p>"},{"location":"bfia_access/#2-scheduling","title":"2. Scheduling","text":""},{"location":"bfia_access/#21-modifying-configurations","title":"2.1 Modifying Configurations","text":"<ul> <li>Modify Route-Table.</li> <li>Update local-site-settings</li> <li><code>LOCAL_SITE_ID</code>: ID of the local site.</li> <li><code>STORAGE_ADDRESS</code>: S3 storage address.</li> <li><code>TRANSPORT</code>: Communication engine address used by the local algorithm.</li> <li><code>CONTAINER_LOG_PATH</code>: Local path for container logs.</li> <li><code>CALLBACK_ADDRESS</code>: Address for scheduling service used by the algorithm for callbacks.</li> </ul>"},{"location":"bfia_access/#22-registering-algorithms","title":"2.2 Registering Algorithms","text":"<pre><code>{\n  \"name\": \"unionpay\",\n  \"device\": \"docker\",\n  \"version\": \"2.0.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"unionpay:2.0.0\"\n  },\n  \"protocol\": \"bfia\",\n  \"components_description\": {}\n}\n</code></pre> <p>Registration Configuration Explanation: - <code>name</code>: Name of the provider/vendor. - <code>device</code>: Mode of algorithm execution, currently supporting \"docker\". - <code>version</code>: Algorithm version. - <code>metadata</code>: Image information. - <code>protocol</code>: Protocol used by the algorithm. - <code>components_description</code>: Description of algorithm components, reference BFIA Algorithm Self-description</p>"},{"location":"bfia_access/#221-registering-fate-algorithms","title":"2.2.1 Registering FATE Algorithms","text":"<p><pre><code>flow provider register -c examples/bfia/fate/register/fate_components.json\n</code></pre> - Configuration reference: fate_components.json</p>"},{"location":"bfia_access/#222-registering-unionpay-algorithms","title":"2.2.2 Registering UnionPay Algorithms","text":"<p><pre><code>flow provider register -c examples/bfia/unionpay/register/unionpay_components.json\n</code></pre> - Configuration reference: unionpay_components.json</p>"},{"location":"bfia_access/#223-registering-other-algorithms","title":"2.2.3 Registering Other Algorithms","text":"<p>You can use the above configuration to register algorithm images from other vendors into the FATE Flow service. They will be automatically loaded and run as containers during execution.</p>"},{"location":"bfia_access/#3-usage","title":"3. Usage","text":"<ul> <li>Modify configurations as outlined in section 2.1.</li> <li>Register corresponding algorithms as described in section 2.2.</li> </ul>"},{"location":"bfia_access/#31-using-fate-algorithm-images","title":"3.1 Using FATE Algorithm Images","text":""},{"location":"bfia_access/#311-data-upload","title":"3.1.1 Data Upload","text":""},{"location":"bfia_access/#3111-upload","title":"3.1.1.1 Upload","text":"<ul> <li>Install FATE Flow and Flow Cli <pre><code>pip install fate_flow==2.0.0\npip install fate_client==2.0.0\n</code></pre></li> <li>Upload data to s3 storage <pre><code>import os\nimport tempfile\n\nfrom fate_flow.adapter.bfia.container.wraps.wraps import DataIo\nfrom fate_flow.components.components.upload import Upload, UploadParam\nfrom fate_flow.entity.spec.dag import Metadata\n\n\ndef upload_data(s3_address, namespace, name, file, meta, head=True, partitions=16, extend_sid=True, storage_engine=\"standalone\"):\n    upload_object = Upload()\n    params = {\n        'name': name,\n        'namespace': namespace,\n        'file': file,\n        'storage_engine': storage_engine,\n        'head': head,\n        'partitions': partitions,\n        'extend_sid': extend_sid,\n        'meta': meta\n    }\n    params = UploadParam(**params)\n\n    with tempfile.TemporaryDirectory() as data_home:\n        os.environ[\"STANDALONE_DATA_HOME\"] = data_home\n        data_meta = upload_object.run(params).get(\"data_meta\")\n\n        metadata = Metadata(metadata=dict(options=dict(partitions=partitions), schema=data_meta))\n        data_path = os.path.join(data_home, namespace, name)\n        engine = DataIo(s3_address)\n        engine.upload_to_s3(data_path, name=name, namespace=namespace, metadata=metadata.dict())\n\n\nif __name__ == \"__main__\":\n    s3_address = \"s3://127.0.0.1:9000?username=admin&amp;password=12345678\"\n    file = 'examples/data/breast_hetero_guest.csv'\n    namespace = \"upload\"\n    name = \"guest\"\n\n\n    meta = {\n        \"delimiter\": \",\",\n        \"label_name\": \"y\",\n        \"match_id_name\": \"id\"\n    }\n    upload_data(s3_address=s3_address, namespace=namespace, name=name, file=file, meta=meta)\n</code></pre> Modify the parameters <code>s3_address</code>, <code>file</code>, <code>namespace</code>, <code>name</code>, <code>meta</code> in the above code with actual values, where: <pre><code>s3_address: s3 storage address\nfile: local path of the data\nnamespace: FATE table namespace\nname: FATE table name\nmeta: Data metadata\n</code></pre></li> </ul>"},{"location":"bfia_access/#3112-dataframe-transformer","title":"3.1.1.2 dataframe-transformer","text":"<p>Explanation: The upload process stores data in the s3 storage. FATE algorithms depend on dataframe-format datasets. FATE provides the <code>dataframe-transformer</code> component for data conversion. In the BFIA protocol, the input parameter for data is <code>dataset_id</code>, which FATE adapts as <code>$namespace + '#' + $name</code> - Configuration: dataframe-transformer - Replace <code>JG0100001100000010</code> in the configuration with the actual site ID - Modify <code>dataset_id</code> to <code>$namespace + '#' + $name</code>, where namespace and name are the parameters set for upload. <pre><code>dag:\n  tasks:\n    transformer_0:\n      inputs:\n        data:\n          table:\n            data_warehouse:\n              dataset_id: upload#guest\n</code></pre> - The output data table is defined in dag.tasks.transformer_0.parameters and can be customized. <pre><code>dag:\n  tasks:\n    transformer_0:\n      parameters:\n        name: breast_hetero_guest\n        namespace: experiment\n</code></pre> - Submit the <code>dataframe-transformer</code> component: <code>flow job submit -c examples/bfia/fate/job/dataframe_transformer.yaml</code></p>"},{"location":"bfia_access/#312-running-fate-algorithm-components","title":"3.1.2 Running FATE Algorithm Components","text":"<p>Jobs can be submitted via CLI, pipelines, or the BFIA's restful-api</p> <ul> <li>Submitting jobs via CLI:</li> <li>Configuration: psi-lr, psi-sbt</li> <li>Command: <code>flow job submit -c examples/bfia/fate/job/psi_lr.yaml</code></li> <li>Submitting jobs via pipelines: psi-lr, psi-sbt</li> <li>Using the restful-api: psi-lr, psi-sbt</li> </ul>"},{"location":"bfia_access/#32-using-algorithm-images-from-other-vendors","title":"3.2 Using Algorithm Images from Other Vendors","text":""},{"location":"bfia_access/#321-data-upload","title":"3.2.1 Data Upload","text":"<p>Each vendor provides its own data upload interface.</p>"},{"location":"bfia_access/#322-running-algorithm-components-from-other-vendors-unionpay-example","title":"3.2.2 Running Algorithm Components from Other Vendors (UnionPay example)","text":"<p>Jobs can be submitted via CLI, pipelines, or the BFIA's restful-api</p> <ul> <li>Submitting jobs via CLI:</li> <li>Configuration: psi-lr, psi-sbt</li> <li>Command: <code>flow job submit -c examples/bfia/unionpay/job/psi_lr.yaml</code></li> <li>Submitting jobs via pipelines: psi-lr, psi-sbt</li> <li>restful-api: psi-lr\u3001psi-sbt</li> </ul>"},{"location":"data_access/","title":"FATE Data Access Guide","text":""},{"location":"data_access/#1-upload-process","title":"1. Upload Process","text":"<p>The process diagram for data upload is as follows:</p> <p> - The client uploads data to the server. - The server encapsulates the upload parameters into a DAG job configuration, including two components: 'upload' and 'dataframe-transformer,' then calls the submit interface to submit the job. - The 'upload' component stores data into the FATE storage service. - The 'transformer' component converts the data output from the 'upload' component into a dataframe and stores it into the FATE storage service. - Metadata about the data is stored in the database.</p>"},{"location":"data_access/#2-data-upload-methods","title":"2. Data Upload Methods","text":"<p>Note: FATE provides clients including SDK, CLI, and Pipeline. If you haven't deployed the FATE Client in your environment, you can use <code>pip install fate_client</code> to download it. The following operations are CLI-based.</p>"},{"location":"data_access/#21-upload-scenario-explanation","title":"2.1 Upload Scenario Explanation","text":"<ul> <li>Client-server separation: Installed client and server are on different machines.</li> <li>Client-server non-separation: Installed client and server are on the same machine. Difference: In scenarios where the client and server are not separated, the step \"the client uploads data to the server\" in the above process can be omitted to improve data upload efficiency in scenarios with large data volumes. There are differences in interfaces and parameters between the two scenarios, and you can choose the corresponding scenario for data upload.</li> </ul>"},{"location":"data_access/#22-data-upload","title":"2.2 Data Upload","text":""},{"location":"data_access/#221-configuration-and-data-preparation","title":"2.2.1 Configuration and Data Preparation","text":"<ul> <li>Upload configuration is located in examples-upload <pre><code>{\n  \"file\": \"examples/data/breast_hetero_guest.csv\",\n  \"head\": true,\n  \"partitions\": 16,\n  \"extend_sid\": true,\n  \"meta\": {\n    \"delimiter\": \",\",\n    \"label_name\": \"y\",\n    \"match_id_name\": \"id\"\n  },\n  \"namespace\": \"experiment\",\n  \"name\": \"breast_hetero_guest\"\n}\n</code></pre></li> <li>file: File path</li> <li>head: Whether the data contains a header: true/false</li> <li>partitions: Number of data storage partitions</li> <li>extend_sid: Whether to generate an 'sid' column</li> <li>meta: Metadata about the data</li> <li>namespace &amp;&amp; name: Reference to data in the FATE storage table</li> <li>Uploaded data is located in upload-data</li> <li>You can also use your own data and modify the \"meta\" information in the upload configuration.</li> </ul>"},{"location":"data_access/#222-data-upload-commands","title":"2.2.2 Data Upload Commands","text":""},{"location":"data_access/#client-server-non-separation","title":"Client-Server Non-Separation","text":"<p><pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre> Note: Ensure that the file path in the configuration exists on the server.</p>"},{"location":"data_access/#client-server-separation","title":"Client-Server Separation","text":"<pre><code>flow data upload-file -c examples/upload/upload_guest.json\n</code></pre>"},{"location":"data_access/#223-upload-results","title":"2.2.3 Upload Results","text":"<pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\"\n    },\n    \"job_id\": \"202312281606030428210\",\n    \"message\": \"success\"\n}\n</code></pre>"},{"location":"data_access/#224-data-query","title":"2.2.4 Data Query","text":"<p>Since the entire upload is an asynchronous operation, it's necessary to confirm successful upload before performing subsequent operations. <pre><code>flow table query --namespace experiment --name breast_hetero_guest\n</code></pre> - Successful data upload returns: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"count\": 569,\n        \"data_type\": \"dataframe\",\n        \"engine\": \"standalone\",\n        \"meta\": {},\n        \"name\": \"breast_hetero_guest\",\n        \"namespace\": \"experiment\",\n        \"path\": \"xxx\",\n        \"source\": {\n            \"component\": \"dataframe_transformer\",\n            \"output_artifact_key\": \"dataframe_output\",\n            \"output_index\": null,\n            \"party_task_id\": \"202312281606030428210_transformer_0_0_local_0\",\n            \"task_id\": \"202312281606030428210_transformer_0\",\n            \"task_name\": \"transformer_0\"\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"data_access/#3-data-binding","title":"3. Data Binding","text":"<p>For specific algorithms that may require particular datasets, FATE Flow provides a data binding interface to make the data available for use in FATE.</p> <pre><code>flow table bind --namespace bind_data --name breast_hetero_guest --path /data/projects/fate/fate_flow/data/xxx\n</code></pre>"},{"location":"data_access/#4-data-query","title":"4. Data Query","text":"<p>For uploaded or bound data tables, you can use the query interface to retrieve brief information about the data.</p> <pre><code>flow table query --namespace experiment --name breast_hetero_guest\n</code></pre>"},{"location":"data_access/#5-data-cleaning","title":"5. Data Cleaning","text":"<p>You can use delete cli to clean data tables that already exist in FATE.</p> <pre><code>flow table delete --namespace experiment --name breast_hetero_guest\n</code></pre>"},{"location":"fate_access/","title":"FATE 2.0 Version Interconnection Guide","text":""},{"location":"fate_access/#1-fate-flow-integration-guide","title":"1. FATE Flow Integration Guide","text":"<ul> <li>Description: This section provides guidance on integrating heterogeneous scheduling platforms with the FATE scheduling platform's FATE Flow.</li> <li>Scenario: This side is the system to be integrated, and the partner is the FATE site.</li> </ul>"},{"location":"fate_access/#11-interfaces","title":"1.1 Interfaces","text":"<p> FATE Flow interfaces are divided into 4 categories: - 1.responsible for receiving requests from upper-level systems, such as submitting, stopping, and querying jobs; - 2.responsible for receiving requests from the scheduling layer, such as starting and stopping tasks; - 3.responsible for receiving requests from algorithm containers, such as task status, input reporting, etc.; - 4.responsible for receiving requests from the platform layer and distributing them to the interfaces of the participating parties.</p>"},{"location":"fate_access/#111-api-1","title":"1.1.1 api-1","text":"<p>Description: Since it is about integrating with the upper-level system and does not involve interaction between schedulers, this interface is optional and can be customized without constraints.</p>"},{"location":"fate_access/#112-api-2","title":"1.1.2 api-2","text":"<p>Refer to interface implementation - <code>/v2/partner/job/create</code>: Create a job - <code>/v2/partner/job/start</code>: Start a job - <code>/v2/partner/job/status/update</code>: Update job status - <code>/v2/partner/job/update</code>: Update job (e.g., progress information) - <code>/v2/partner/job/resource/apply</code>: Apply for job resources - <code>/v2/partner/job/resource/return</code>: Return job resources - <code>/v2/partner/job/stop</code>: Stop job - <code>/v2/partner/task/resource/apply</code>: Apply for task resources - <code>/v2/partner/task/resource/return</code>: Return task resources - <code>/v2/partner/task/start</code>: Start task - <code>/v2/partner/task/collect</code>: Scheduler collects task status - <code>/v2/partner/task/status/update</code>: Update task status - <code>/v2/partner/task/stop</code>: Stop task - <code>/v2/partner/task/rerun</code>: Rerun task</p>"},{"location":"fate_access/#113-api-3","title":"1.1.3 api-3","text":"<p>Refer to interface implementation - <code>/v2/worker/task/status</code>: Status report - <code>/v2/worker/model/save</code>: Save model - <code>/v2/worker/model/download</code>: Download model - <code>/v2/worker/data/tracking/query</code>: Query data - <code>/v2/worker/data/tracking/save</code>: Record data - <code>/v2/worker/metric/save/&lt;execution_id&gt;</code>: Record metrics</p>"},{"location":"fate_access/#114-api-4","title":"1.1.4 api-4","text":"<p>Refer to interface implementation - <code>/v2/scheduler/job/create</code>: Create a job - <code>/v2/scheduler/job/stop</code>: Stop a job - <code>/v2/scheduler/task/report</code>: Task report (e.g., status) - <code>/v2/scheduler/job/rerun</code>: Rerun a job</p>"},{"location":"fate_access/#12-scheduler","title":"1.2 Scheduler","text":"<p>The scheduler mainly consists of two parts: scheduling logic and scheduling interface. In the case of interconnection in a heterogeneous scenario, a unified scheduling process and interface are indispensable. In the case mentioned above, when using FATE Flow as the scheduling party in connection with other vendors, the implementation of the scheduler can be ignored.</p>"},{"location":"fate_access/#121-approach","title":"1.2.1 Approach","text":"<p>The core of scheduling is the scheduling process, which defines the lifecycle of a job. In version 1.x of FATE, the scheduler and the initiator logic are bound, meaning the coordination scheduling of jobs from multiple parties is done at the initiator. This has a disadvantage: suppose companies A, B, and C each have the need to initiate tasks, their scheduling layers need to implement the scheduler based on the same scheduling logic, and the cost of interconnection is high. In version 2.0, the initiator and scheduler logic in the scheduling module are decoupled, and the scheduler can be specified in the job configuration. In the above case, as long as any one of A, B, or C companies implements the scheduler, or directly uses FATE as the scheduler, other vendors only need to implement the scheduler client interface to meet the requirements, greatly reducing the cost of interconnection.</p> <p></p> <p>P represents the scheduling client interface, S represents the scheduler interface</p> <p>To illustrate this scheduling mode with an example: Suppose A wants to create a job with C, and FATE Flow is the scheduler. First, A requests the FATE-Flow S (create-job) interface. After receiving the request, FATE Flow obtains participant information (A, C) through job configuration, and then distributes it to the P (create-job) interface of each participant.</p>"},{"location":"fate_access/#122-scheduling-logic","title":"1.2.2 Scheduling Logic","text":"<p>It manages the lifecycle of jobs, including when to start and stop jobs, when to start and stop tasks, DAG parsing, and component runtime dependencies, etc. FATE Flow's scheduling process is divided into two modes based on task status acquisition: callback and poll. Among them, the callback mode is for the participants to actively report task status to the scheduler, and the poll mode is for the scheduler to pull task status from the participants at regular intervals. The scheduling process diagrams for the two modes are as follows:</p> <p></p> <p>Callback Mode</p> <p></p> <p>Poll Mode</p>"},{"location":"fate_access/#123-scheduling-interface","title":"1.2.3 Scheduling Interface","text":"<p>Responsible for receiving requests from the platform layer and distributing them to the interfaces of various participants api-2, such as creating jobs, stopping jobs, etc. Interfaces see api-4</p>"},{"location":"fate_access/#2-algorithm-integration-guide","title":"2 Algorithm Integration Guide","text":"<p>In previous versions of FATE, algorithms ran as local processes started by the scheduling service, and there were shortcomings in terms of scalability, making it difficult to meet the needs of interconnection. In version 2.0, the \"algorithm container\" is used to run algorithms, implementing heterogeneous algorithm scheduling functionality through a standardized algorithm image construction and loading mechanism.</p> <p></p>"},{"location":"fate_access/#21-fate-algorithm-containerization-solution","title":"2.1 FATE Algorithm Containerization Solution","text":"<ul> <li>Pre-processing: Input processing for data, models, algorithm parameters, etc., will call the platform-layer interface api-3 to obtain relevant dependencies.</li> <li>Component runtime: Algorithm component logic.</li> <li>Post-processing: Output content processing for algorithm components, will call the platform-layer interface api-3 to upload the output to the platform. </li> </ul>"},{"location":"fate_access/#22-integration","title":"2.2 Integration","text":""},{"location":"fate_access/#221-algorithm-parameters","title":"2.2.1 Algorithm Parameters","text":"<p>FATE Flow will pass parameters to the algorithm container in the form of environment variables, with the key being \"CONFIG\" and the parameter value being a JSON string. The content is as follows: <pre><code>component: psi\ncomputing_partitions: 8\nconf:\n  computing:\n    metadata:\n      computing_id: 202402271112016150790_psi_0_0_host_9998\n      host\uff1a127.0.0.1\n      port:4670\n    type: standalone/eggroll/spark\n  device:\n    metadata: {}\n    type: CPU\n  federation:\n    metadata:\n      federation_id: 202402271112016150790_psi_0_0\n      parties:\n        local:\n          partyid: '9998'\n          role: host\n        parties:\n        - partyid: '9999'\n          role: guest\n        - partyid: '9998'\n          role: host\n      osx_config:\n        host: 127.0.01\n        port: 9370\n    type: osx\n  logger:\n    config:\n  storage: standalone/eggroll/hdfs\nengine_run:\n  cores: 4\ninput_artifacts:\n  data:\n    input_data:\n      output_artifact_key: output_data\n      output_artifact_type_alias: null\n      parties:\n      - party_id:\n        - '9998'\n        role: host\n      producer_task: reader_0\n  model: null\njob_id: '202402271112016150790'\nlauncher_conf: {}\nlauncher_name: default\nmlmd:\n  metadata:\n    api_version: v2\n    host: 127.0.0.1\n    port: 9380\n    protocol: http\n  type: flow\nmodel_id: '202402271112016150790'\nmodel_version: '0'\nparameters: {}\nparty_id: '9998'\nparty_task_id: 202402271112016150790_psi_0_0_host_9998\nprovider_name: fate\nrole: host\nstage: default\ntask_id: 202402271112016150790_psi_0\ntask_name: psi_0\ntask_version: '0'\n</code></pre> Here are the key configurations: - <code>component</code>: The name of the algorithm. When multiple algorithms are packaged in the same image, this parameter is used to identify them. - <code>conf.computing</code>: Configuration for the computing engine. - <code>conf.federation</code>: Configuration for the communication engine. - <code>conf.storage</code>: Configuration for the storage engine, supporting standalone/eggroll and hdfs. - <code>mlmd</code>: Platform-layer interface used for recording the output of the algorithm. The interface is api-3. - <code>input_artifacts</code>: Input dependencies, including data, models, etc. - <code>parameters</code>: Algorithm parameters. The entry point for starting the algorithm needs to be specified with CMD when building the image, and the algorithm should call the status reporting interface in api-3 upon completion.</p>"},{"location":"fate_access/#222-registering-algorithm-image","title":"2.2.2 Registering Algorithm Image","text":"<p><pre><code>flow provider register -c examples/provider/register_image.json\n</code></pre> Where <code>register_image.json</code> looks like this: <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"docker\",\n  \"version\": \"2.1.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"federatedai/fate:2.1.0\"\n  }\n}\n</code></pre></p>"},{"location":"fate_access/#223-using-algorithm-image","title":"2.2.3 Using Algorithm Image","text":"<p>After registration, in the DAG of the job configuration, you can specify the provider to run this FATE algorithm image, as shown below: <pre><code>dag:\n  conf:\n    task:\n      provider: fate:2.1.0@docker\n</code></pre> Alternatively, you can specify this image for a specific algorithm. For details, refer to the provider guide.</p>"},{"location":"fate_flow/","title":"Overall Design","text":""},{"location":"fate_flow/#1-design-architecture-diagram","title":"1. Design Architecture Diagram","text":"<p> - Application Layer Interface: Used by higher-level components like fate-board, fate-client, etc. - Interconnect Layer Interface: Divided into Scheduler Interface and Participant Interface. Scheduler Interface receives scheduling commands like create, stop, etc., and sends them to participants. Participant Interface is used by each participant to receive commands like create, run, stop, etc., and execute them. - Base Interface: Receives status reports from algorithm containers, etc. - Scheduler: Federated scheduling logic, interprets DSL dependencies, and runs related jobs and tasks. - Algorithm Container: Environment for algorithm execution. FATE Flow supports running algorithms in local processes or in algorithm containers, with similar execution modes. - Platform Resource Pool: Abstract computation, communication, storage APIs.</p>"},{"location":"fate_flow/#2-overall-architecture","title":"2. Overall Architecture","text":""},{"location":"fate_flow/#21-fate-overall-architecture","title":"2.1 FATE Overall Architecture","text":""},{"location":"fate_flow/#22-fate-flow-functional-architecture","title":"2.2 FATE Flow Functional Architecture","text":""},{"location":"fate_flow/#23-fate-flow-cluster-architecture","title":"2.3 FATE Flow Cluster Architecture","text":""},{"location":"fate_flow/#3-scheduling-architecture","title":"3. Scheduling Architecture","text":""},{"location":"fate_flow/#31-state-based-scheduling-architecture","title":"3.1 State-Based Scheduling Architecture","text":"<ul> <li>Separation of states (resources, jobs) and managers (scheduler, resource manager)</li> <li>Persistent storage of resource and job states in MySQL, globally shared, providing reliable transactional operations</li> <li>Improved high availability and scalability of management services</li> <li>Intervention in jobs, supporting actions like restarts, reruns, parallel control, resource isolation, etc.</li> </ul>"},{"location":"fate_flow/#32-state-driven-scheduling","title":"3.2 State-Driven Scheduling","text":"<ul> <li>North-south state reporting/querying</li> <li>East-west multi-party task state computation for federated task states</li> <li>Upstream and downstream task state computation for job states</li> </ul>"},{"location":"fate_flow/#321-callback-mode","title":"3.2.1 Callback Mode","text":"<p>Scheduler creates jobs and tasks, and each participant actively callbacks the state of jobs or tasks.</p> <p></p>"},{"location":"fate_flow/#322-polling-mode","title":"3.2.2 Polling Mode","text":"<p>Scheduler not only creates jobs and tasks but also polls the state of jobs or tasks from the participants during the scheduling process.</p> <p></p>"},{"location":"fate_flow/#34-algorithm-component-scheduling","title":"3.4 Algorithm Component Scheduling","text":"<ul> <li>Pre-processing: Handling inputs such as data, models, algorithm parameters</li> <li>Component execution: Logic of algorithm components</li> <li>Post-processing: Handling outputs of algorithm components</li> </ul>"},{"location":"fate_flow/#4-multi-party-resource-coordination","title":"4. Multi-Party Resource Coordination","text":"<ul> <li>Total resource size for each engine is configured via a configuration file, subsequent system integration to be implemented</li> <li>The cores within the total resource size represent the number of CPU cores per computing node</li> <li>FATEFlow server reads resource size configuration from the configuration file upon startup and registers updates to the database</li> <li>Resources are allocated at the Job level, becoming effective upon Job Conf submission</li> </ul>"},{"location":"fate_flow/#5-real-time-job-monitoring","title":"5. Real-time Job Monitoring","text":"<ul> <li>Work process liveness detection</li> <li>Job timeout detection</li> <li>Resource recovery detection</li> <li>Basic engine session timeout detection</li> </ul>"},{"location":"fate_flow/#6-task-component-center","title":"6. Task Component Center","text":""},{"location":"fate_flow/#7-data-access","title":"7. Data Access","text":""},{"location":"job_scheduling/","title":"Multi-Party Joint Operation","text":""},{"location":"job_scheduling/#1-introduction","title":"1. Introduction","text":"<p>This primarily introduces how to define federated learning jobs using <code>FATE Flow</code>.</p>"},{"location":"job_scheduling/#2-dag-definition","title":"2. DAG Definition","text":"<p>FATE 2.0 uses a brand new DAG to define a job, including the upstream and downstream dependencies of each component.</p>"},{"location":"job_scheduling/#3-job-functional-configuration","title":"3. Job Functional Configuration","text":""},{"location":"job_scheduling/#31-prediction","title":"3.1 Prediction","text":"<p><pre><code>dag:\n  conf:\n    model_warehouse:                        \n      model_id: '202307171452088269870'      \n      model_version: '0'                    \n</code></pre> In <code>dag.conf.model_warehouse</code>, define the model information that the prediction task relies on. This model will be used for prediction in the algorithm.</p>"},{"location":"job_scheduling/#32-job-inheritance","title":"3.2 Job Inheritance","text":"<p><pre><code>dag:\n  conf:\n    inheritance:                  \n      job_id: \"202307041704214920920\"  \n      task_list: [\"reader_0\"]         \n</code></pre> In <code>job.conf.inheritance</code>, fill in the job and algorithm component names that need to be inherited. The newly started job will directly reuse the outputs of these components.</p>"},{"location":"job_scheduling/#33-specifying-the-scheduler-party","title":"3.3 Specifying the Scheduler Party","text":"<p><pre><code>dag:\n  conf:\n    scheduler_party_id: \"9999\"   \n</code></pre> In <code>job.conf.scheduler_party_id</code>, you can specify scheduler party information. If not specified, the initiator acts as the scheduler.</p>"},{"location":"job_scheduling/#34-specifying-job-priority","title":"3.4 Specifying Job Priority","text":"<p><pre><code>dag:\n  conf:\n    priority: 2\n</code></pre> In <code>job.conf.priority</code>, specify the scheduling weight of the task. The higher the value, the higher the priority.</p>"},{"location":"job_scheduling/#35-automatic-retry-on-failure","title":"3.5 Automatic Retry on Failure","text":"<p><pre><code>dag:\n  conf:\n    auto_retries: 2\n</code></pre> In <code>job.conf.auto_retries</code>, specify the number of retries if a task fails. Default is 0.</p>"},{"location":"job_scheduling/#36-resource-allocation","title":"3.6 Resource Allocation","text":"<p><pre><code>dag:\n  conf:\n    cores: 4\n  task:\n    engine_run:\n      cores: 2\n</code></pre> - Here, <code>dag.conf.cores</code> represents the allocated resources for the entire job (<code>job_cores</code>), and <code>dag.conf.engine_run.cores</code> represents the allocated resources for the task (<code>task_cores</code>). If a job is started with this configuration, its maximum parallelism will be 2. - Task parallelism = job_cores / task_cores</p>"},{"location":"job_scheduling/#37-task-timeout","title":"3.7 Task Timeout","text":"<p><pre><code>dag:\n  task:\n    timeout: 3600 # s\n</code></pre> In <code>dag.task.timeout</code>, specify the task's timeout. When a task is in the 'running' state after reaching the timeout, it triggers an automatic job kill operation.</p>"},{"location":"job_scheduling/#38-task-provider","title":"3.8 Task Provider","text":"<p><pre><code>dag:\n  task:\n    provider: fate:2.0.1@local\n</code></pre> In <code>dag.task.provider</code>, specify the algorithm provider, version number, and execution mode for the task.</p>"},{"location":"job_scheduling/#4-input","title":"4. Input","text":"<p>Description: Upstream input, divided into two input types: data and models.</p>"},{"location":"job_scheduling/#41-data-input","title":"4.1 Data Input","text":"<ul> <li> <p>As parameter input to a component <pre><code>dag:\n  party_tasks:\n    guest_9999:\n      tasks:\n        reader_0:\n          parameters:\n            name: breast_hetero_guest\n            namespace: experiment\n    host_9998:\n      tasks:\n        reader_0:\n          parameters:\n            name: breast_hetero_host\n            namespace: experiment\n</code></pre> The <code>reader</code> component supports directly passing a FATE data table as job-level data input.</p> </li> <li> <p>Input of one component from another component's output <pre><code>dag:\n  tasks:\n    binning_0:\n      component_ref: hetero_feature_binning\n      inputs:\n        data:\n          train_data:\n            task_output_artifact:\n              output_artifact_key: train_output_data\n              producer_task: scale_0\n</code></pre> <code>binning_0</code> depends on the output data of <code>scale_0</code>.</p> </li> </ul>"},{"location":"job_scheduling/#42-model-input","title":"4.2 Model Input","text":"<ul> <li>Model Warehouse <pre><code>dag:\n  conf:\n    model_warehouse:                        \n      model_id: '202307171452088269870'      \n      model_version: '0'  \n  tasks:\n    selection_0:\n      component_ref: hetero_feature_selection\n      dependent_tasks:\n      - scale_0\n        model:\n          input_model:\n            model_warehouse:\n              output_artifact_key: train_output_model\n              producer_task: selection_0\n</code></pre></li> </ul>"},{"location":"job_scheduling/#5-output","title":"5. Output","text":"<p>The job's output includes data, models, and metrics.</p>"},{"location":"job_scheduling/#51-metric-output","title":"5.1 Metric Output","text":""},{"location":"job_scheduling/#querying-metrics","title":"Querying Metrics","text":"<p>Querying output metrics command: <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code> - Input content as follows: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"job_scheduling/#52-model-output","title":"5.2 Model Output","text":""},{"location":"job_scheduling/#querying-models","title":"Querying Models","text":"<p><pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code> - Query result as follows: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"output_model\": {\n            \"data\": {\n                \"estimator\": {\n                    \"end_epoch\": 10,\n                    \"is_converged\": false,\n                    \"lr_scheduler\": {\n                        \"lr_params\": {\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100\n                        },\n                        \"lr_scheduler\": {\n                            \"_get_lr_called_within_step\": false,\n                            \"_last_lr\": [\n                                0.07269999999999996\n                            ],\n                            \"_step_count\": 10,\n                            \"base_lrs\": [\n                                0.1\n                            ],\n                            \"end_factor\": 1.0,\n                            \"last_epoch\": 9,\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100,\n                            \"verbose\": false\n                        },\n                        \"method\": \"linear\"\n                    },\n                    \"optimizer\": {\n                        \"alpha\": 0.001,\n                        \"l1_penalty\": false,\n                        \"l2_penalty\": true,\n                        \"method\": \"sgd\",\n                        \"model_parameter\": [\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ]\n                        ],\n                        \"model_parameter_dtype\": \"float32\",\n                        \"optim_param\": {\n                            \"lr\": 0.1\n                        },\n                        \"optimizer\": {\n                            \"param_groups\": [\n                                {\n                                    \"dampening\": 0,\n                                    \"differentiable\": false,\n                                    \"foreach\": null,\n                                    \"initial_lr\": 0.1,\n                                    \"lr\": 0.07269999999999996,\n                                    \"maximize\": false,\n                                    \"momentum\": 0,\n                                    \"nesterov\": false,\n                                    \"params\": [\n                                        0\n                                    ],\n                                    \"weight_decay\": 0\n                                }\n                            ],\n                            \"state\": {}\n                        }\n                    },\n                    \"param\": {\n                        \"coef_\": [\n                            [\n                                -0.10828543454408646\n                            ],\n                            [\n                                -0.07341302931308746\n                            ],\n                            [\n                                -0.10850320011377335\n                            ],\n                            [\n                                -0.10066638141870499\n                            ],\n                            [\n                                -0.04595951363444328\n                            ],\n                            [\n                                -0.07001449167728424\n                            ],\n                            [\n                                -0.08949052542448044\n                            ],\n                            [\n                                -0.10958756506443024\n                            ],\n                            [\n                                -0.04012322425842285\n                            ],\n                            [\n                                0.02270071767270565\n                            ],\n                            [\n                                -0.07198350876569748\n                            ],\n                            [\n                                0.00548586156219244\n                            ],\n                            [\n                                -0.06599288433790207\n                            ],\n                            [\n                                -0.06410090625286102\n                            ],\n                            [\n                                0.016374297440052032\n                            ],\n                            [\n                                -0.01607361063361168\n                            ],\n                            [\n                                -0.011447405442595482\n                            ],\n                            [\n                                -0.04352564364671707\n                            ],\n                            [\n                                0.013161249458789825\n                            ],\n                            [\n                                0.013506329618394375\n                            ]\n                        ],\n                        \"dtype\": \"float32\",\n                        \"intercept_\": null\n                    }\n                }\n            },\n            \"meta\": {\n                \"batch_size\": null,\n                \"epochs\": 10,\n                \"init_param\": {\n                    \"fill_val\": 0.0,\n                    \"fit_intercept\": false,\n                    \"method\": \"zeros\",\n                    \"random_state\": null\n                },\n                \"label_count\": false,\n                \"learning_rate_param\": {\n                    \"method\": \"linear\",\n                    \"scheduler_params\": {\n                        \"start_factor\": 0.7,\n                        \"total_iters\": 100\n                    }\n                },\n                \"optimizer_param\": {\n                    \"alpha\": 0.001,\n                    \"method\": \"sgd\",\n                    \"optimizer_params\": {\n                        \"lr\": 0.1\n                    },\n                    \"penalty\": \"l2\"\n                },\n                \"ovr\": false\n            }\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"job_scheduling/#downloading-models","title":"Downloading Models","text":"<p><pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> - <code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code> - Download result: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"Download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre></p>"},{"location":"job_scheduling/#53-output-data","title":"5.3 Output Data","text":""},{"location":"job_scheduling/#querying-data-tables","title":"Querying Data Tables","text":"<p><pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> - Query result: <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"job_scheduling/#previewing-data","title":"Previewing Data","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> - <code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code></p>"},{"location":"job_scheduling/#downloading-data","title":"Downloading Data","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> - <code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code> - Result: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"Download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"provider_register/","title":"Component Registry","text":""},{"location":"provider_register/#1-introduction","title":"1. Introduction","text":"<p>FATE Flow has designed an algorithm component registry module to support multiple algorithm vendors, versions, and various execution modes.</p>"},{"location":"provider_register/#2-provider","title":"2. Provider","text":"<p>Definition: <code>$name:$version@device</code>, such as <code>fate:2.0.0@local</code> - name: Algorithm provider vendor - version: Algorithm version - device: Algorithm execution mode, e.g., docker, k8s, local, etc.</p>"},{"location":"provider_register/#21-registration","title":"2.1 Registration","text":"<ul> <li>Registration command:</li> </ul> <pre><code>flow provider register -c examples/provider/register.json\n</code></pre> <ul> <li> <p>Registering a local algorithm package requires providing the algorithm package path (<code>path</code>) and optionally the Python environment path (if not provided, the system environment will be used). <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"local\",\n  \"version\": \"2.0.1\",\n  \"metadata\": {\n    \"path\": \"/Users/tonly/FATE/python\",\n    \"venv\": \"/Users/tonly/opt/anaconda3/envs/fate3.8/bin/python\"\n  }\n}\n</code></pre></p> </li> <li> <p>Registering a docker-based algorithm image: <pre><code>{\n  \"name\": \"fate\",\n  \"device\": \"docker\",\n  \"version\": \"2.0.0\",\n  \"metadata\": {\n    \"base_url\": \"\",\n    \"image\": \"federatedai/fate:2.0.0\"\n  },\n  \"protocol\": \"bfia\",\n  \"components_description\": {}\n}\n</code></pre></p> </li> </ul>"},{"location":"provider_register/#22-querying","title":"2.2 Querying","text":"<ul> <li> <p>Command: <pre><code>flow provider register --name fate --version 2.0.1 --device local\n</code></pre></p> </li> <li> <p>Output: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"create_time\": 1703762542058,\n            \"device\": \"local\",\n            \"metadata\": {\n                \"path\": \"/Users/tonly/FATE/python\",\n                \"venv\": \"/Users/tonly/opt/anaconda3/envs/fate3.8/bin/python\"\n            },\n            \"name\": \"fate\",\n            \"provider_name\": \"fate:2.0.1@local\",\n            \"update_time\": 1703762542058,\n            \"version\": \"2.0.1\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p> </li> </ul>"},{"location":"provider_register/#23-deletion","title":"2.3 Deletion","text":"<p>Used for deleting a registered algorithm. - Command: <pre><code>flow provider delete --name fate --version 2.0.1 --device local\n</code></pre></p> <ul> <li>Output: <pre><code>{\n    \"code\": 0,\n    \"data\": true,\n    \"message\": \"success\"\n}\n</code></pre></li> </ul>"},{"location":"provider_register/#3-component-registry-and-discovery-mechanism","title":"3. Component Registry and Discovery Mechanism","text":"<ul> <li>Registering algorithms</li> <li>Task configuration carrying the provider parameter, see the configuration methods below</li> </ul>"},{"location":"provider_register/#4-configuration-methods","title":"4. Configuration Methods","text":""},{"location":"provider_register/#41-global-job-configuration","title":"4.1 Global Job Configuration","text":"<p><pre><code>dag:\n  conf:\n    task:\n      provider: fate:2.0.1@local\n</code></pre> All tasks under the job inherit this provider.</p>"},{"location":"provider_register/#42-global-party-task-configuration","title":"4.2 Global Party Task Configuration","text":"<p><pre><code>dag:\n  party_tasks:\n    guest_9999:\n      parties:\n      - party_id:\n        - '9999'\n        role: guest\n      conf:\n        provider: fate:2.0.1@local\n</code></pre> All tasks under guest 9999 inherit this provider.</p>"},{"location":"provider_register/#43-global-task-configuration","title":"4.3 Global Task Configuration","text":"<p><pre><code>dag:\n  tasks:\n    reader_0:\n      conf:\n        provider: fate:2.0.1@local\n      component_ref: reader\n</code></pre> All reader components across all parties inherit this provider.</p>"},{"location":"provider_register/#44-specified-task-configuration","title":"4.4 Specified Task Configuration","text":"<p><pre><code>dag:\n  party_tasks:\n    guest_9999:\n      parties:\n      - party_id:\n        - '9999'\n        role: guest\n      tasks:\n        reader_0:\n          conf:\n            provider: fate:2.0.1@local\n</code></pre> The reader component under guest 9999 specifically inherits this provider.</p>"},{"location":"quick_start/","title":"Quick Start","text":""},{"location":"quick_start/#1-environment-setup","title":"1. Environment Setup","text":"<p>You can choose from the following three deployment modes based on your requirements:</p>"},{"location":"quick_start/#11-pypi-package-installation","title":"1.1 Pypi Package Installation","text":"<p>Explanation: This mode operates in a single-machine environment.</p>"},{"location":"quick_start/#111-installation","title":"1.1.1 Installation","text":"<ul> <li>Prepare and install conda environment.</li> <li>Create a virtual environment: <pre><code># FATE requires python&gt;=3.8\nconda create -n fate_env python=3.8\nconda activate fate_env\n</code></pre></li> <li>Install FATE Flow and related dependencies: <pre><code>pip install fate_client[fate,fate_flow]==2.0.0\n</code></pre></li> </ul>"},{"location":"quick_start/#112-service-initialization","title":"1.1.2 Service Initialization","text":"<p><pre><code>fate_flow init --ip 127.0.0.1 --port 9380 --home $HOME_DIR\n</code></pre> - ip: Service running IP - port: HTTP port for the service - home: Data storage directory, including data/models/logs/job configurations/sqlite.db, etc.</p>"},{"location":"quick_start/#113-service-startstop","title":"1.1.3 Service Start/Stop","text":"<pre><code>fate_flow status/start/stop/restart\n</code></pre>"},{"location":"quick_start/#12-standalone-deployment","title":"1.2 Standalone Deployment","text":"<p>Refer to Standalone Deployment</p>"},{"location":"quick_start/#13-cluster-deployment","title":"1.3 Cluster Deployment","text":"<p>Refer to Allinone Deployment</p>"},{"location":"quick_start/#2-user-guide","title":"2. User Guide","text":"<p>FATE provides a client package including SDK, CLI, and Pipeline. If FATE Client isn't deployed in your environment, you can download it using <code>pip install fate_client</code>. The following operations are CLI-based.</p>"},{"location":"quick_start/#21-data-upload","title":"2.1 Data Upload","text":"<p>For detailed data operation guides, refer to Data Access Guide</p>"},{"location":"quick_start/#211-configuration-and-data","title":"2.1.1 Configuration and Data","text":"<ul> <li>Upload Configuration: examples-upload</li> <li>Upload Data: upload-data</li> </ul>"},{"location":"quick_start/#212-upload-guest-data","title":"2.1.2 Upload Guest Data","text":"<pre><code>flow data upload -c examples/upload/upload_guest.json\n</code></pre>"},{"location":"quick_start/#213-upload-host-data","title":"2.1.3 Upload Host Data","text":"<pre><code>flow data upload -c examples/upload/upload_host.json\n</code></pre>"},{"location":"quick_start/#22-starting-a-fate-job","title":"2.2 Starting a FATE Job","text":""},{"location":"quick_start/#221-submitting-a-job","title":"2.2.1 Submitting a Job","text":"<p>Once your data is prepared, you can submit a job to FATE Flow: - Job configuration examples are in lr-train. - Site IDs in the job configuration are \"9998\" and \"9999\". Replace them with real site IDs for cluster deployments; default configuration can be used for standalone deployments. - If you want to use your data, modify the parameters in the reader within the configuration. - Command to submit a job: <pre><code>flow job submit -c examples/lr/train_lr.yaml \n</code></pre> - Successful submission returns: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"model_id\": \"202308211911505128750\",\n        \"model_version\": \"0\"\n    },\n    \"job_id\": \"202308211911505128750\",\n    \"message\": \"success\"\n}\n</code></pre> The \"data\" here contains the output of the job, i.e., the model.</p>"},{"location":"quick_start/#222-querying-a-job","title":"2.2.2 Querying a Job","text":"<p>During job execution, you can query the job status using the query command: <pre><code>flow job query -j $job_id\n</code></pre></p>"},{"location":"quick_start/#223-stopping-a-job","title":"2.2.3 Stopping a Job","text":"<p>While the job is running, you can stop it using the stop job command: <pre><code>flow job stop -j $job_id\n</code></pre></p>"},{"location":"quick_start/#224-rerunning-a-job","title":"2.2.4 Rerunning a Job","text":"<p>If a job fails during execution, you can rerun it using the rerun command: <pre><code>flow job rerun -j $job_id\n</code></pre></p>"},{"location":"quick_start/#23-fetching-job-output","title":"2.3 Fetching Job Output","text":"<p>Job output includes data, models, and metrics.</p>"},{"location":"quick_start/#231-output-metrics","title":"2.3.1 Output Metrics","text":"<p>Querying output metrics command: <pre><code>flow output query-metric -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, with the previously submitted training DAG task, you can use <code>flow output query-metric -j 202308211911505128750 -r arbiter -p 9998 -tn lr_0</code> to query. The result looks like this: <pre><code>{\n    \"code\": 0,\n    \"data\": [\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        0.0\n                    ],\n                    \"step\": 0,\n                    \"timestamp\": 1692616428.253495\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        },\n        {\n            \"data\": [\n                {\n                    \"metric\": [\n                        -0.07785049080848694\n                    ],\n                    \"step\": 1,\n                    \"timestamp\": 1692616432.9727712\n                }\n            ],\n            \"groups\": [\n                {\n                    \"index\": null,\n                    \"name\": \"default\"\n                },\n                {\n                    \"index\": null,\n                    \"name\": \"train\"\n                }\n            ],\n            \"name\": \"lr_loss\",\n            \"step_axis\": \"iterations\",\n            \"type\": \"loss\"\n        }\n    ],\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"quick_start/#232-output-models","title":"2.3.2 Output Models","text":""},{"location":"quick_start/#2321-querying-models","title":"2.3.2.1 Querying Models","text":"<p><pre><code>flow output query-model -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For instance, with the previously submitted training DAG task, you can use <code>flow output query-model -j 202308211911505128750 -r host -p 9998 -tn lr_0</code> to query. The query result looks like this: <pre><code>{\n    \"code\": 0,\n    \"data\": {\n        \"output_model\": {\n            \"data\": {\n                \"estimator\": {\n                    \"end_epoch\": 10,\n                    \"is_converged\": false,\n                    \"lr_scheduler\": {\n                        \"lr_params\": {\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100\n                        },\n                        \"lr_scheduler\": {\n                            \"_get_lr_called_within_step\": false,\n                            \"_last_lr\": [\n                                0.07269999999999996\n                            ],\n                            \"_step_count\": 10,\n                            \"base_lrs\": [\n                                0.1\n                            ],\n                            \"end_factor\": 1.0,\n                            \"last_epoch\": 9,\n                            \"start_factor\": 0.7,\n                            \"total_iters\": 100,\n                            \"verbose\": false\n                        },\n                        \"method\": \"linear\"\n                    },\n                    \"optimizer\": {\n                        \"alpha\": 0.001,\n                        \"l1_penalty\": false,\n                        \"l2_penalty\": true,\n                        \"method\": \"sgd\",\n                        \"model_parameter\": [\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ],\n                            [\n                                0.0\n                            ]\n                        ],\n                        \"model_parameter_dtype\": \"float32\",\n                        \"optim_param\": {\n                            \"lr\": 0.1\n                        },\n                        \"optimizer\": {\n                            \"param_groups\": [\n                                {\n                                    \"dampening\": 0,\n                                    \"differentiable\": false,\n                                    \"foreach\": null,\n                                    \"initial_lr\": 0.1,\n                                    \"lr\": 0.07269999999999996,\n                                    \"maximize\": false,\n                                    \"momentum\": 0,\n                                    \"nesterov\": false,\n                                    \"params\": [\n                                        0\n                                    ],\n                                    \"weight_decay\": 0\n                                }\n                            ],\n                            \"state\": {}\n                        }\n                    },\n                    \"param\": {\n                        \"coef_\": [\n                            [\n                                -0.10828543454408646\n                            ],\n                            [\n                                -0.07341302931308746\n                            ],\n                            [\n                                -0.10850320011377335\n                            ],\n                            [\n                                -0.10066638141870499\n                            ],\n                            [\n                                -0.04595951363444328\n                            ],\n                            [\n                                -0.07001449167728424\n                            ],\n                            [\n                                -0.08949052542448044\n                            ],\n                            [\n                                -0.10958756506443024\n                            ],\n                            [\n                                -0.04012322425842285\n                            ],\n                            [\n                                0.02270071767270565\n                            ],\n                            [\n                                -0.07198350876569748\n                            ],\n                            [\n                                0.00548586156219244\n                            ],\n                            [\n                                -0.06599288433790207\n                            ],\n                            [\n                                -0.06410090625286102\n                            ],\n                            [\n                                0.016374297440052032\n                            ],\n                            [\n                                -0.01607361063361168\n                            ],\n                            [\n                                -0.011447405442595482\n                            ],\n                            [\n                                -0.04352564364671707\n                            ],\n                            [\n                                0.013161249458789825\n                            ],\n                            [\n                                0.013506329618394375\n                            ]\n                        ],\n                        \"dtype\": \"float32\",\n                        \"intercept_\": null\n                    }\n                }\n            },\n            \"meta\": {\n                \"batch_size\": null,\n                \"epochs\": 10,\n                \"init_param\": {\n                    \"fill_val\": 0.0,\n                    \"fit_intercept\": false,\n                    \"method\": \"zeros\",\n                    \"random_state\": null\n                },\n                \"label_count\": false,\n                \"learning_rate_param\": {\n                    \"method\": \"linear\",\n                    \"scheduler_params\": {\n                        \"start_factor\": 0.7,\n                        \"total_iters\": 100\n                    }\n                },\n                \"optimizer_param\": {\n                    \"alpha\": 0.001,\n                    \"method\": \"sgd\",\n                    \"optimizer_params\": {\n                        \"lr\": 0.1\n                    },\n                    \"penalty\": \"l2\"\n                },\n                \"ovr\": false\n            }\n        }\n    },\n    \"message\": \"success\"\n}\n</code></pre></p>"},{"location":"quick_start/#2322-downloading-models","title":"2.3.2.2 Downloading Models","text":"<p><pre><code>flow output download-model -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> For example, with the previously submitted training DAG task, you can use <code>flow output download-model -j 202308211911505128750 -r host -p 9998 -tn lr_0 -o ./</code> to download. The download result is shown below: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_model_202308211911505128750_host_9998_lr_0\",\n    \"message\": \"download success, please check the path: ./output_model_202308211911505128750_host_9998_lr_0\"\n}\n</code></pre></p>"},{"location":"quick_start/#233-output-data","title":"2.3.3 Output Data","text":""},{"location":"quick_start/#2331-query-data-table","title":"2.3.3.1 Query Data Table","text":"<p><pre><code>flow output query-data-table -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For instance, with the previously submitted training DAG task, you can use <code>flow output query-data-table -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> to query. The result looks like this: <pre><code>{\n    \"train_output_data\": [\n        {\n            \"name\": \"9e28049c401311ee85c716b977118319\",\n            \"namespace\": \"202308211911505128750_binning_0\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"quick_start/#2332-preview-data","title":"2.3.3.2 Preview Data","text":"<p><pre><code>flow output display-data -j $job_id -r $role -p $party_id -tn $task_name\n</code></pre> For example, with the previously submitted training DAG task, you can use <code>flow output display-data -j 202308211911505128750 -r host -p 9998 -tn binning_0</code> to preview output data.</p>"},{"location":"quick_start/#2333-download-data","title":"2.3.3.3 Download Data","text":"<p><pre><code>flow output download-data -j $job_id -r $role -p $party_id -tn $task_name -o $download_dir\n</code></pre> For example, with the previously submitted training DAG task, you can use <code>flow output download-data -j 202308211911505128750 -r guest -p 9999 -tn lr_0 -o ./</code> to download output data. The download result is as follows: <pre><code>{\n    \"code\": 0,\n    \"directory\": \"./output_data_202308211911505128750_guest_9999_lr_0\",\n    \"message\": \"download success, please check the path: ./output_data_202308211911505128750_guest_9999_lr_0\"\n}\n</code></pre></p>"},{"location":"quick_start/#3-more-documentation","title":"3. More Documentation","text":"<ul> <li>Restful-api</li> <li>CLI</li> <li>Pipeline</li> <li>FATE Quick Start</li> <li>FATE Algorithms</li> </ul>"},{"location":"system_conf/","title":"System Configuration","text":"<p>FATE Flow uses YAML to define system configurations, and the configuration file is located at: <code>conf/service_conf.yaml</code>. The specific configuration contents and their meanings are as follows:</p> Configuration Item Description Values party_id Local site ID For example, \"9999\", \"10000\" log_level Log level DEBUG:10, INFO:20, DEBUG:30, ERROR: 40 use_registry Whether to use a registry center; currently, only ZooKeeper mode is supported, and it requires correct ZooKeeper configuration. Note: If using high availability mode, ensure this configuration is set to true. true/false encrypt Encryption module See Encryption Module fateflow Configuration for the FATE Flow service, including ports, command channel service, and proxy See FateFlow Configuration database Configuration information for the database service See Database Configuration default_engines System's engine services, including computing, storage, and communication engines See Engine Configuration default_provider Component source information, including provider name, component version, and execution mode See Default Registered Algorithm Configuration federation Communication service pool See Communication Engine Pool computing Computing service pool See Computing Engine Pool storage Storage service pool See Storage Engine Pool hook_module Hook configuration, currently supports client authentication, site authentication, and authorization hooks See Hook Module Configuration authentication Authentication and authorization switches See Authentication Switch model_store Model storage configuration See Model Storage zookeeper ZooKeeper service configuration See ZooKeeper Configuration"},{"location":"system_conf/#encryption-module","title":"Encryption Module","text":"<p><pre><code>key_0:\n  module: fate_flow.hub.encrypt.password_encrypt#pwdecrypt\n  private_path: private_key.pem\n</code></pre> This encryption module is primarily used for encrypting passwords (e.g., MySQL passwords): - \"key_0\" is the key for the encryption module (you can customize the name), making it easier to reference in other configurations when multiple encryption modes coexist.   - module: The encryption module, formatted as \"encryption module\" + \"#\" + \"encryption function.\"   - private_path: The path to the encryption key. If you provide a relative path, its root directory is <code>fate_flow/conf/</code>.</p>"},{"location":"system_conf/#fateflow-configuration","title":"FateFlow Configuration","text":"<p><pre><code>host: 127.0.0.1\nhttp_port: 9380\ngrpc_port: 9360\nproxy_name: osx\nnginx:\n  host:\n  http_port:\n  grpc_port:\n</code></pre> - host: Host address. - http_port: HTTP port number. - grpc_port: gRPC port number. - proxy_name: Command channel service name, supporting osx/nginx. Detailed configurations need to be set within Communication Engine Pool. - nginx: Proxy service configuration for load balancing.</p>"},{"location":"system_conf/#database-configuration","title":"Database Configuration","text":"<p><pre><code>engine: sqlite\ndecrypt_key:\nmysql:\n  name: fate_flow\n  user: fate\n  passwd: fate\n  host: 127.0.0.1\n  port: 3306\n  max_connections: 100\n  stale_timeout: 30\nsqlite:\n  path:\n</code></pre> - engine: Database engine name. If set to \"mysql\" here, update the detailed MySQL configuration. - decrypt_key: Encryption module, selected from Encryption Module. If not configured, it's considered to not use password encryption. If used, you need to set the \"passwd\" below to ciphertext and configure the key path in Encryption Module. - mysql: MySQL service configuration. If using password encryption functionality, set the \"passwd\" in this configuration to ciphertext and configure the key path in Encryption Module. - sqlite: SQLite file path, default path is <code>fate_flow/fate_flow_sqlite.db</code>.</p>"},{"location":"system_conf/#engine-configuration","title":"Engine Configuration","text":"<pre><code>default_engines:\n  computing: standalone\n  federation: standalone\n  storage: standalone\n</code></pre> <ul> <li>computing: Computing engine, supports \"standalone\", \"eggroll\", \"spark\".</li> <li>federation: Communication engine, supports \"standalone\", \"osx\", \"rabbitmq\", \"pulsar\".</li> <li>storage: Storage engine, supports \"standalone,\" \"eggroll,\" \"hdfs.\"</li> </ul>"},{"location":"system_conf/#default-registered-algorithm-configuration","title":"Default Registered Algorithm Configuration","text":"<ul> <li>name: Algorithm name.</li> <li>version: Algorithm version. If not configured, it uses the configuration in <code>fateflow.env</code>.</li> <li>device: Algorithm launch mode, local/docker/k8s, etc.</li> </ul>"},{"location":"system_conf/#communication-engine-pool","title":"Communication Engine Pool","text":""},{"location":"system_conf/#osx","title":"OSx","text":"<pre><code>  host: 127.0.0.1\n  port: 9370\n  mode: stream\n</code></pre>"},{"location":"system_conf/#computing-engine-pool","title":"Computing Engine Pool","text":""},{"location":"system_conf/#standalone","title":"Standalone","text":"<p><pre><code>  cores: 32\n</code></pre> - cores: Total resources.</p>"},{"location":"system_conf/#eggroll","title":"Eggroll","text":"<p><pre><code>eggroll:\n  cores: 32\n  nodes: 1\n  host: 127.0.0.1\n  port: 4670\n</code></pre> - cores: Total cluster resources. - nodes: Number of node managers in the cluster. - host: eggroll cluster manager host ip - port: eggroll cluster manager port</p>"},{"location":"system_conf/#spark","title":"Spark","text":"<p><pre><code>spark:\n  home: \n  cores: 32\n</code></pre> - home: Spark home directory. If not filled, \"pyspark\" will be used as the computing engine. - cores: Total resources.</p>"},{"location":"system_conf/#storage-engine-pool","title":"Storage Engine Pool","text":"<pre><code>  hdfs:\n    name_node: hdfs://fate-cluster\n</code></pre>"},{"location":"system_conf/#hook-module-configuration","title":"Hook Module Configuration","text":"<p><pre><code>hook_module:\n  client_authentication: fate_flow.hook.flow.client_authentication\n  site_authentication: fate_flow.hook.flow.site_authentication\n  permission: fate_flow.hook.flow.permission\n</code></pre> - client_authentication: Client authentication hook. - site_authentication: Site authentication hook. - permission: Permission authentication hook.</p>"},{"location":"system_conf/#authentication-switch","title":"Authentication Switch","text":"<pre><code>authentication:\n  client: false\n  site: false\n  permission: false\n</code></pre>"},{"location":"system_conf/#model-storage","title":"Model Storage","text":"<p><pre><code>model_store:\n  engine: file\n  decrypt_key:\n  file:\n    path:\n  mysql:\n    name: fate_flow\n    user: fate\n    passwd: fate\n    host: 127.0.0.1\n    port: 3306\n    max_connections: 100\n    stale_timeout: 30\n  tencent_cos:\n    Region:\n    SecretId:\n    SecretKey:\n    Bucket:\n</code></pre> - engine: Model storage engine, supports \"file,\" \"mysql\", and \"tencent_cos\". - decrypt_key: Encryption module, needs to be selected from Encryption Module. If not configured, it is assumed to not use password encryption. If used, you need to set the \"passwd\" below accordingly to ciphertext and configure the key path in Encryption Module. - file: Model storage directory, default location is <code>fate_flow/model</code>. - mysql: MySQL service configuration; if using password encryption functionality, you need to set the \"passwd\" in this configuration to ciphertext and configure the key path in Encryption Module. - tencent_cos: Tencent Cloud key configuration.</p>"},{"location":"system_conf/#zookeeper-configuration","title":"ZooKeeper Configuration","text":"<pre><code>zookeeper:\n  hosts:\n    - 127.0.0.1:2181\n  use_acl: true\n  user: fate\n  password: fate\n</code></pre>"},{"location":"mkdocs/","title":"Build","text":""},{"location":"mkdocs/#use-docker","title":"use docker","text":"<p>At repo root, execute</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs  \n</code></pre> <p>to serve docs in http://localhost:8000</p> <p>or</p> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs build\n</code></pre> <p>to build docs to <code>site</code> folder.</p>"},{"location":"mkdocs/#manually","title":"manually","text":"<p><code>mkdocs-material</code> and servel plugins are needed to build this docs</p> <p>Fisrt, create an python virtual environment</p> <p><pre><code>python3 -m venv \"fatedocs\"\nsource fatedocs/bin/activate\npip install -U pip\n</code></pre> And then install requirements</p> <pre><code>pip install -r doc/mkdocs/requirements.txt\n</code></pre> <p>Now, use</p> <pre><code>mkdocs serve\n</code></pre> <p>at repo root to serve docs or</p> <p>use </p> <pre><code>mkdocs build\n</code></pre> <p>at repo root to build docs to folder <code>site</code></p>"},{"location":"mkdocs/#develop-guide","title":"Develop guide","text":"<p>We use mkdocs-material to build our docs.  Servel markdown extensions are really useful to write pretty documents such as  admonitions and  content-tabs.</p> <p>Servel plugins are introdused to makes mkdocs-material much powerful:</p> <ul> <li> <p>mkdocstrings      automatic documentation from sources code. We mostly use this to automatic generate     <code>params api</code> for <code>federatedml</code>.</p> </li> <li> <p>awesome-pages     for powerful nav rule</p> </li> <li> <p>i18n     for multi-languege support</p> </li> <li> <p>mkdocs-jupyter     for jupyter format support</p> </li> <li> <p>mkdocs-simple-hooks     for simple plugin-in</p> </li> </ul>"},{"location":"mkdocs/docker/","title":"Image for build FATE's documents","text":"<p>This image is modified from mkdocs-meterial with some plugins embeded.</p> <p>Usage</p> <p>Mount the folder where your mkdocs.yml resides as a volume into /docs:</p> <ul> <li>Start development server on http://localhost:8000</li> </ul> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs sagewei0/mkdocs\n</code></pre> <ul> <li>Build documentation</li> </ul> <pre><code>docker run --rm -it -v ${PWD}:/docs sagewei/mkdocs build\n</code></pre> <ul> <li>Deploy documentation to GitHub Pages</li> </ul> <pre><code>docker run --rm -it -v ~/.ssh:/root/.ssh -v ${PWD}:/docs sagewei0/mkdocs gh-deploy \n</code></pre>"},{"location":"mkdocs/theme/","title":"Index","text":"<p>Mostly copied from https://github.com/cirruslabs/cirrus-ci-docs/tree/master/theme</p>"},{"location":"swagger/","title":"API","text":""},{"location":"swagger/#swagger-api","title":"Swagger API","text":""}]}